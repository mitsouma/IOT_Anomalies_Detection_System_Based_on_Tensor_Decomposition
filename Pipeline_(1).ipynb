{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitsouma/IOT_Anomalies_Detection_System_Based_on_Tensor_Decomposition/blob/main/Pipeline_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1crCeV2R6Ns",
        "outputId": "8725b7f7-2c94-4e6d-f47c-6a124af8f3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorly\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorly) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tensorly) (1.15.2)\n",
            "Downloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorly\n",
            "Successfully installed tensorly-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install tensorly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8StKyQdSHn1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorly.decomposition import parafac\n",
        "import tensorly as tl\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorly import unfold, fold\n",
        "from tensorly.tenalg import khatri_rao\n",
        "from numpy.linalg import lstsq\n",
        "from tensorly.cp_tensor import cp_to_tensor\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "import time\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
        "import torch\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0LaR79yU9_4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt-WNgMjimtR"
      },
      "source": [
        "\"\"\"\n",
        "This pipeline is designed to detect anomalies in network traffic using a tensor-based deep learning approach.\n",
        "\n",
        "Steps and Objectives:\n",
        "---------------------\n",
        "1. **Preprocessing & Tensor Construction**:\n",
        "   - Multivariate network traffic data is aggregated over time windows.\n",
        "   - A 4D tensor is built with dimensions: [Time_Window, Src IP, Dst IP,featues].\n",
        "\n",
        "2. **Tensor Decomposition (CP)**:\n",
        "   - The tensor is decomposed using CP (CANDECOMP/PARAFAC) to extract the underlying structure (normal behavior).\n",
        "   - This reveals low-rank patterns, which capture typical traffic patterns.\n",
        "\n",
        "3. **Reconstruction & Residual Calculation**:\n",
        "   - We take the training tenssor and we compute its CP decomposition\n",
        "   - Residuals are computed as the difference between the measure of the train tensor and the projection of this measure in the latent space.\n",
        "4. **Anomaly Scoring**:\n",
        "Since our goal aim to detect DDoS and DOS attack so:\n",
        "   - Scores are aggregated per destination IP (`Dst IP`) and feature.\n",
        "   - These scores reflect the degree of deviation from normal patterns.\n",
        "\n",
        "5. **Deep Learning Classification**:\n",
        "   - The aggregated anomaly scores are used as input to a neural network.\n",
        "   - If labeled data is available, the model is trained in a supervised way to classify normal vs anomalous flows.\n",
        "   - If labels are absent, an autoencoder is trained to learn normal behavior and detect deviations.\n",
        "\n",
        "6. **Prediction**:\n",
        "   - New traffic data is processed through the same pipeline.\n",
        "   - The trained model predicts anomaly scores or binary classifications.\n",
        "\n",
        "Main Goal:\n",
        "----------\n",
        "To detect abnormal network behavior in the IOT_data  by modeling traffic patterns as tensors, identifying deviations, and classifying them using deep learning models.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1zTED3B1q4B"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9_2WKh1tReb"
      },
      "outputs": [],
      "source": [
        "tl.set_backend('pytorch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3fV3mESyd3P"
      },
      "source": [
        "**Define the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep6pD1DF0PP9",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv('/content/drive/MyDrive/BenignTraffic.pcap_Flow.csv')\n",
        "df2=pd.read_csv('/content/drive/MyDrive/BenignTraffic1.pcap_Flow.csv')\n",
        "df3=pd.read_csv('/content/drive/MyDrive/BenignTraffic2.pcap_Flow.csv')\n",
        "df4=pd.read_csv('/content/drive/MyDrive/BenignTraffic3.pcap_Flow.csv')\n",
        "df5=pd.read_csv('/content/drive/MyDrive/DDoS-HTTP_Flood-.pcap_Flow.csv')\n",
        "df6=pd.read_csv('/content/drive/MyDrive/DoS-HTTP_Flood.pcap_Flow.csv')\n",
        "df7=pd.read_csv('/content/drive/MyDrive/DoS-HTTP_Flood1.pcap_Flow.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSa9PMXLReBV"
      },
      "outputs": [],
      "source": [
        "df1['label']=0\n",
        "df2['label']=0\n",
        "df3['label']=0\n",
        "df4['label']=0\n",
        "df5['label']=1\n",
        "df5['label']=1\n",
        "df6['label']=1\n",
        "df7['label']=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUdvqL8UVzeE"
      },
      "outputs": [],
      "source": [
        "df1.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df3.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df4.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df5.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df6.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df7.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k59jI2602wF5",
        "outputId": "b3f7fa6d-c452-4996-b783-5fbe50043e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nan for :are : Flow Bytes/s      35\n",
            "Flow Packets/s    35\n",
            "dtype: int64\n",
            "nan for :are : Flow Bytes/s      35\n",
            "Flow Packets/s    35\n",
            "dtype: int64\n",
            "nan for :are : Flow Bytes/s      45\n",
            "Flow Packets/s    45\n",
            "dtype: int64\n",
            "nan for :are : Flow Bytes/s      17\n",
            "Flow Packets/s    17\n",
            "dtype: int64\n",
            "nan for :are : Flow Bytes/s      1123\n",
            "Flow Packets/s    1123\n",
            "dtype: int64\n",
            "nan for :are : Flow Bytes/s      40786\n",
            "Flow Packets/s    40786\n",
            "dtype: int64\n",
            "nan for :are : Flow Bytes/s      38735\n",
            "Flow Packets/s    38735\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Drop na\n",
        "for df in [df1,df2,df3,df4,df5,df6,df7]:\n",
        "   r=df.isna().sum()\n",
        "   print(\"nan for :are :\",r[r>0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP3XaH6Tzbmx",
        "outputId": "934ec1d5-6823-4038-ddb7-6379d10a651e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(183630, 85)\n",
            "(84526, 85)\n",
            "(91279, 85)\n",
            "(38895, 85)\n",
            "(505720, 85)\n",
            "(932513, 85)\n",
            "(710231, 85)\n"
          ]
        }
      ],
      "source": [
        "#Shape of each dataset\n",
        "print(df1.shape)\n",
        "print(df2.shape)\n",
        "print(df3.shape)\n",
        "print(df4.shape)\n",
        "print(df5.shape)\n",
        "print(df6.shape)\n",
        "print(df7.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q4JA-VT3B9U"
      },
      "outputs": [],
      "source": [
        "#Drop duplicated rows\n",
        "df1.drop_duplicates(inplace=True)\n",
        "df2.drop_duplicates(inplace=True)\n",
        "df3.drop_duplicates(inplace=True)\n",
        "df4.drop_duplicates(inplace=True)\n",
        "df5.drop_duplicates(inplace=True)\n",
        "df6.drop_duplicates(inplace=True)\n",
        "df7.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flHDjg5aVRkh"
      },
      "outputs": [],
      "source": [
        "df1.dropna(inplace=True)\n",
        "df2.dropna(inplace=True)\n",
        "df3.dropna(inplace=True)\n",
        "df4.dropna(inplace=True)\n",
        "df5.dropna(inplace=True)\n",
        "df6.dropna(inplace=True)\n",
        "df7.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lsWA_FN1Xg1"
      },
      "outputs": [],
      "source": [
        "#Convert timestamp\n",
        "df1['Timestamp']=pd.to_datetime(df1['Timestamp'])\n",
        "df2['Timestamp']=pd.to_datetime(df2['Timestamp'])\n",
        "df3['Timestamp']=pd.to_datetime(df3['Timestamp'])\n",
        "df4['Timestamp']=pd.to_datetime(df4['Timestamp'])\n",
        "df5['Timestamp']=pd.to_datetime(df5['Timestamp'])\n",
        "df6['Timestamp']=pd.to_datetime(df6['Timestamp'])\n",
        "df7['Timestamp']=pd.to_datetime(df7['Timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb-pDgCL1xmh"
      },
      "outputs": [],
      "source": [
        "#Extract days\n",
        "df1['Jour']=df1['Timestamp'].dt.date\n",
        "df2['Jour']=df2['Timestamp'].dt.date\n",
        "df3['Jour']=df3['Timestamp'].dt.date\n",
        "df4['Jour']=df4['Timestamp'].dt.date\n",
        "df5['Jour']=df5['Timestamp'].dt.date\n",
        "df6['Jour']=df6['Timestamp'].dt.date\n",
        "df7['Jour']=df7['Timestamp'].dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A__Mh_xC2WwI"
      },
      "outputs": [],
      "source": [
        "#Convert days\n",
        "df1['Jour']=pd.to_datetime(df1['Jour'])\n",
        "df2['Jour']=pd.to_datetime(df2['Jour'])\n",
        "df3['Jour']=pd.to_datetime(df3['Jour'])\n",
        "df4['Jour']=pd.to_datetime(df4['Jour'])\n",
        "df5['Jour']=pd.to_datetime(df5['Jour'])\n",
        "df6['Jour']=pd.to_datetime(df6['Jour'])\n",
        "df7['Jour']=pd.to_datetime(df7['Jour'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1XhnESrdRTo",
        "outputId": "e950f503-1960-41a8-ef28-8d4352bedfeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatetimeArray>\n",
              "['2022-09-08 00:00:00']\n",
              "Length: 1, dtype: datetime64[ns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df7['Jour'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vof25FrdmyK"
      },
      "outputs": [],
      "source": [
        "df5_day_1=df5[df5['Jour']=='2022-09-14']\n",
        "df5_day_2=df5[df5['Jour']=='2022-11-07']\n",
        "df6_day_1=df6[df6['Jour']=='2022-08-08']\n",
        "df6_day_2=df6[df6['Jour']=='2022-09-08']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21oWqcUF8QEi"
      },
      "outputs": [],
      "source": [
        "#Extract time\n",
        "df1['Heure']=df1['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df2['Heure']=df2['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df3['Heure']=df3['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df4['Heure']=df4['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df5_day_1['Heure']=df5_day_1['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df5_day_2['Heure']=df5_day_2['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df6_day_1['Heure']=df6_day_1['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df6_day_2['Heure']=df6_day_2['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "df7['Heure']=df7['Timestamp'].dt.strftime('%H:%M:%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQR3P8WG86m3"
      },
      "outputs": [],
      "source": [
        "#Create a relative time\n",
        "df1['relative_time']=df1['Timestamp']-df1['Timestamp'].min()\n",
        "df2['relative_time']=df2['Timestamp']-df2['Timestamp'].min()\n",
        "df3['relative_time']=df3['Timestamp']-df3['Timestamp'].min()\n",
        "df4['relative_time']=df4['Timestamp']-df4['Timestamp'].min()\n",
        "df5_day_1['relative_time']=df5_day_1['Timestamp']-df5_day_1['Timestamp'].min()\n",
        "df5_day_2['relative_time']=df5_day_2['Timestamp']-df5_day_2['Timestamp'].min()\n",
        "df6_day_1['relative_time']=df6_day_1['Timestamp']-df6_day_1['Timestamp'].min()\n",
        "df6_day_2['relative_time']=df6_day_2['Timestamp']-df6_day_2['Timestamp'].min()\n",
        "df7['relative_time']=df7['Timestamp']-df7['Timestamp'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ihKJeh-ReBZ"
      },
      "outputs": [],
      "source": [
        "#Normal filter\n",
        "hours = df1['relative_time'].dt.total_seconds() / 3600\n",
        "mask_3h = hours <= 1\n",
        "df_3h = df1[mask_3h]\n",
        "#Train filter\n",
        "hours_t = df4['relative_time'].dt.total_seconds() / 3600\n",
        "mask_3h_t = hours_t <= 1\n",
        "df_3h_t = df4[mask_3h_t]\n",
        "#Test filter\n",
        "hours_3h_test = df3['relative_time'].dt.total_seconds() / 3600\n",
        "mask_3h_test = hours_3h_test <= 1\n",
        "df_3h_test = df3[mask_3h_test]\n",
        "#Anomalous filter\n",
        "hours_3h_test_a = df5_day_2['relative_time'].dt.total_seconds() / 3600\n",
        "mask_3h_test_a = hours_3h_test_a <= 1\n",
        "df_3h_test_a = df5_day_2[mask_3h_test_a]\n",
        "df7_2h=df7[df7['relative_time']<pd.Timedelta(hours=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVbABgFxReBa"
      },
      "source": [
        "# DATA CONSTRUCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb6Fz4k55MeD"
      },
      "outputs": [],
      "source": [
        "#Consider for as normal_data \"Benign 1 \":\n",
        "df_normal=df_3h\n",
        "#Training data:\n",
        "df_train=pd.concat([df_3h_t,df5_day_1,df7_2h],axis=0)\n",
        "df_test=pd.concat([df_3h_test,df_3h_test_a,df6_day_2],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOCfsU_8sWo_",
        "outputId": "44bc390f-81a2-4521-b3de-814e9ebd4997"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "323"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df_normal['Dst IP'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP9XfFhWReBb"
      },
      "source": [
        "# NORMALISE SOME COLUMNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSinYaWVReBb"
      },
      "outputs": [],
      "source": [
        "df_train['Flow Packets/s']=(df_train['Flow Packets/s']-min(df_train['Flow Packets/s']))/(max(df_train['Flow Packets/s'])-min(df_train['Flow Packets/s']))\n",
        "df_train['Flow Duration']=(df_train['Flow Duration']-min(df_train['Flow Duration']))/(max(df_train['Flow Duration'])-min(df_train['Flow Duration']))\n",
        "df_train['Flow Bytes/s']=(df_train['Flow Bytes/s']-min(df_train['Flow Bytes/s']))/(max(df_train['Flow Bytes/s'])-min(df_train['Flow Bytes/s']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDb2mQIkReBb"
      },
      "outputs": [],
      "source": [
        "df_normal['Flow Bytes/s']=(df_normal['Flow Bytes/s']-min(df_normal['Flow Bytes/s']))/(max(df_normal['Flow Bytes/s'])-min(df_normal['Flow Bytes/s']))\n",
        "df_normal['Flow Duration']=(df_normal['Flow Duration']-min(df_normal['Flow Duration']))/(max(df_normal['Flow Duration'])-min(df_normal['Flow Duration']))\n",
        "df_normal['Flow Packets/s']=(df_normal['Flow Packets/s']-min(df_normal['Flow Packets/s']))/(max(df_normal['Flow Packets/s'])-min(df_normal['Flow Packets/s']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzdUOPk0ReBb"
      },
      "outputs": [],
      "source": [
        "df_test['Flow Packets/s']=(df_test['Flow Packets/s']-min(df_test['Flow Packets/s']))/max(df_test['Flow Packets/s'])\n",
        "df_test['Flow Duration']=(df_test['Flow Duration']-min(df_test['Flow Duration']))/max(df_test['Flow Duration'])\n",
        "df_test['Flow Bytes/s']=(df_test['Flow Bytes/s']-min(df_test['Flow Bytes/s']))/max(df_test['Flow Bytes/s'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiwrxPo5ReBc"
      },
      "source": [
        "# TENSOR CONSTRUCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsIamgsYReBc"
      },
      "outputs": [],
      "source": [
        "def create_graph_tensor(df, window_size=300):\n",
        "    # Détection du device (GPU si disponible)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Extraction des IPs uniques\n",
        "    src_ips = df['Src IP'].unique()\n",
        "    dst_ips = df['Dst IP'].unique()\n",
        "\n",
        "    src_ip_to_idx = {ip: idx for idx, ip in enumerate(src_ips)}\n",
        "    dst_ip_to_idx = {ip: idx for idx, ip in enumerate(dst_ips)}\n",
        "\n",
        "    # Création des fenêtres temporelles\n",
        "    df['time_window'] = df['relative_time'].astype(np.int64) // (10**9 * window_size)\n",
        "    time_windows = sorted(df['time_window'].unique())\n",
        "\n",
        "    # Création du tenseur sur CPU d'abord\n",
        "    tensor_cpu = torch.zeros((len(time_windows), 751, 849, 4), dtype=torch.float32)\n",
        "\n",
        "    for _, group in df.groupby(['time_window', 'Src IP', 'Dst IP']):\n",
        "        t_idx = np.where(time_windows == group['time_window'].iloc[0])[0][0]\n",
        "        src_idx = src_ip_to_idx[group['Src IP'].iloc[0]]\n",
        "        dst_idx = dst_ip_to_idx[group['Dst IP'].iloc[0]]\n",
        "\n",
        "        tensor_cpu[t_idx, src_idx, dst_idx, 0] = len(group)\n",
        "        tensor_cpu[t_idx, src_idx, dst_idx, 1] = group['Flow Bytes/s'].sum()\n",
        "        tensor_cpu[t_idx, src_idx, dst_idx, 2] = group['Flow Duration'].mean()\n",
        "        tensor_cpu[t_idx, src_idx, dst_idx, 3] = group['Flow Packets/s'].sum()\n",
        "\n",
        "    # Transfert du tenseur sur GPU si disponible\n",
        "    tensor = tensor_cpu.to(device)\n",
        "\n",
        "    print(\"Tensor well created : shape =\", tensor.shape)\n",
        "    print(\"Number of non-zeros =\", (tensor != 0).sum().item())\n",
        "    print(\"Number of elements =\", tensor.numel())\n",
        "    return tensor, src_ip_to_idx, dst_ip_to_idx, time_windows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVbn19AYReBc"
      },
      "source": [
        "# Tensor Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjZjgYt6vnIF"
      },
      "outputs": [],
      "source": [
        "def normalize_tensor_feature(tensor, feature_index):\n",
        "    # Extract the feature slice\n",
        "    feature_slice = tensor[:, :, :, feature_index]\n",
        "\n",
        "    # Calculate min and max\n",
        "    min_val = torch.min(feature_slice)\n",
        "    max_val = torch.max(feature_slice)\n",
        "\n",
        "    # Apply min-max normalization\n",
        "    if max_val - min_val > 0:\n",
        "        normalized_slice = (feature_slice - min_val) / (max_val - min_val)\n",
        "    else:\n",
        "        # All values are the same\n",
        "        normalized_slice = feature_slice - min_val  # results in all zeros\n",
        "\n",
        "    # Replace the original feature with the normalized one\n",
        "    tensor[:, :, :, feature_index] = normalized_slice\n",
        "\n",
        "    return tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZqxPcF3xWfE",
        "outputId": "547f3485-50df-4f92-e95e-104ac5268fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Tensor well created : shape = torch.Size([13, 751, 849, 4])\n",
            "Number of non-zeros = 10251\n",
            "Number of elements = 33155148\n",
            "Using device: cuda\n",
            "Tensor well created : shape = torch.Size([12, 751, 849, 4])\n",
            "Number of non-zeros = 26300\n",
            "Number of elements = 30604752\n",
            "Using device: cuda\n",
            "Tensor well created : shape = torch.Size([13, 751, 849, 4])\n",
            "Number of non-zeros = 20547\n",
            "Number of elements = 33155148\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Unpack the tuple into separate variables\n",
        "tensor_normal, src_ip_to_idx, dst_ip_to_idx, time_windows = create_graph_tensor(df_normal, window_size=300)\n",
        "\n",
        "# Now normalize the tensor object\n",
        "tensor_normal = normalize_tensor_feature(tensor_normal, 0)\n",
        "tensor_normal = normalize_tensor_feature(tensor_normal, 1)\n",
        "tensor_normal = normalize_tensor_feature(tensor_normal, 2)\n",
        "tensor_normal = normalize_tensor_feature(tensor_normal, 3)\n",
        "\n",
        "# If you need to update the original 'tensor_data' variable to contain the modified tensor\n",
        "# and the other elements, you can create a new tuple:\n",
        "\n",
        "# Repeat the unpacking and normalization for tensor_data_normal and tensor_data_test as well\n",
        "tensor_train, src_ip_to_idx_train, dst_ip_to_idx_train, time_windows_train = create_graph_tensor(df_train, window_size=300)\n",
        "tensor_train = normalize_tensor_feature(tensor_train, 0)\n",
        "tensor_train = normalize_tensor_feature(tensor_train, 1)\n",
        "tensor_train = normalize_tensor_feature(tensor_train, 2)\n",
        "tensor_train = normalize_tensor_feature(tensor_train, 3)\n",
        "\n",
        "tensor_test, src_ip_to_idx_test, dst_ip_to_idx_test, time_windows_test = create_graph_tensor(df_test, window_size=300)\n",
        "tensor_test = normalize_tensor_feature(tensor_test, 0)\n",
        "tensor_test = normalize_tensor_feature(tensor_test, 1)\n",
        "tensor_test = normalize_tensor_feature(tensor_test, 2)\n",
        "tensor_test = normalize_tensor_feature(tensor_test, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H63ysbBA0Fdu",
        "outputId": "6a57ca5f-8602-44f5-c92d-c1acf258767f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Rank : 1, Error : 0.8736\n",
            "✅ Rank : 2, Error : 0.8109\n",
            "✅ Rank : 3, Error : 0.7673\n",
            "✅ Rank : 4, Error : 0.7230\n",
            "✅ Rank : 5, Error : 0.6910\n",
            "✅ Rank : 6, Error : 0.6671\n",
            "✅ Rank : 7, Error : 0.6443\n",
            "✅ Rank : 8, Error : 0.6265\n",
            "✅ Rank : 9, Error : 0.6116\n",
            "✅ Rank : 10, Error : 0.5933\n",
            "✅ Rank : 11, Error : 0.5830\n",
            "✅ Rank : 12, Error : 0.5636\n",
            "✅ Rank : 13, Error : 0.5502\n",
            "✅ Rank : 14, Error : 0.5409\n",
            "✅ Rank : 15, Error : 0.5296\n",
            "✅ Rank : 16, Error : 0.5196\n",
            "✅ Rank : 17, Error : 0.5072\n",
            "✅ Rank : 18, Error : 0.4959\n",
            "✅ Rank : 19, Error : 0.4864\n",
            "✅ Rank : 20, Error : 0.4745\n",
            "✅ Rank : 21, Error : 0.4630\n",
            "✅ Rank : 22, Error : 0.4521\n",
            "✅ Rank : 23, Error : 0.4413\n",
            "✅ Rank : 24, Error : 0.4305\n",
            "✅ Rank : 25, Error : 0.4221\n",
            "✅ Rank : 26, Error : 0.4080\n",
            "✅ Rank : 27, Error : 0.3975\n",
            "✅ Rank : 28, Error : 0.3840\n",
            "✅ Rank : 29, Error : 0.3746\n",
            "✅ Rank : 30, Error : 0.3626\n",
            "✅ Rank : 31, Error : 0.3447\n",
            "✅ Rank : 32, Error : 0.3320\n",
            "✅ Rank : 33, Error : 0.3186\n",
            "✅ Rank : 34, Error : 0.3052\n",
            "✅ Rank : 35, Error : 0.2997\n",
            "✅ Rank : 36, Error : 0.2788\n",
            "✅ Rank : 37, Error : 0.2666\n",
            "✅ Rank : 38, Error : 0.2592\n",
            "✅ Rank : 39, Error : 0.2476\n",
            "✅ Rank : 40, Error : 0.2397\n",
            "✅ Rank : 41, Error : 0.2334\n",
            "✅ Rank : 42, Error : 0.2270\n",
            "✅ Rank : 43, Error : 0.2196\n",
            "✅ Rank : 44, Error : 0.2142\n",
            "✅ Rank : 45, Error : 0.2061\n",
            "✅ Rank : 46, Error : 0.1988\n",
            "✅ Rank : 47, Error : 0.1965\n",
            "✅ Rank : 48, Error : 0.1841\n",
            "✅ Rank : 49, Error : 0.1988\n",
            "✅ Rank : 50, Error : 0.1812\n",
            "✅ Rank : 51, Error : 0.1956\n",
            "✅ Rank : 52, Error : 0.1724\n",
            "✅ Rank : 53, Error : 0.1678\n",
            "✅ Rank : 54, Error : 0.1765\n",
            "✅ Rank : 55, Error : 0.1709\n",
            "✅ Rank : 56, Error : 0.1590\n",
            "✅ Rank : 57, Error : 0.1571\n",
            "✅ Rank : 58, Error : 0.1537\n",
            "✅ Rank : 59, Error : 0.1608\n",
            "✅ Rank : 60, Error : 0.1519\n",
            "✅ Rank : 61, Error : 0.1579\n",
            "✅ Rank : 62, Error : 0.1482\n",
            "✅ Rank : 63, Error : 0.1415\n",
            "✅ Rank : 64, Error : 0.1413\n",
            "✅ Rank : 65, Error : 0.1324\n",
            "✅ Rank : 66, Error : 0.1376\n",
            "✅ Rank : 67, Error : 0.1309\n",
            "✅ Rank : 68, Error : 0.1339\n",
            "✅ Rank : 69, Error : 0.1359\n",
            "✅ Rank : 70, Error : 0.1359\n",
            "✅ Rank : 71, Error : 0.1357\n",
            "✅ Rank : 72, Error : 0.1368\n",
            "✅ Rank : 73, Error : 0.1279\n",
            "✅ Rank : 74, Error : 0.1216\n",
            "✅ Rank : 75, Error : 0.1201\n",
            "✅ Rank : 76, Error : 0.1243\n",
            "✅ Rank : 77, Error : 0.1193\n",
            "✅ Rank : 78, Error : 0.1181\n",
            "✅ Rank : 79, Error : 0.1245\n",
            "✅ Rank : 80, Error : 0.1164\n",
            "✅ Rank : 81, Error : 0.1219\n",
            "✅ Rank : 82, Error : 0.1111\n",
            "✅ Rank : 83, Error : 0.1079\n",
            "✅ Rank : 84, Error : 0.1129\n",
            "✅ Rank : 85, Error : 0.1031\n",
            "✅ Rank : 86, Error : 0.1143\n",
            "✅ Rank : 87, Error : 0.1020\n",
            "✅ Rank : 88, Error : 0.1031\n",
            "✅ Rank : 89, Error : 0.1124\n",
            "✅ Rank : 90, Error : 0.1008\n",
            "✅ Rank : 91, Error : 0.1014\n",
            "✅ Rank : 92, Error : 0.1001\n",
            "✅ Rank : 93, Error : 0.0974\n",
            "✅ Rank : 94, Error : 0.0971\n",
            "✅ Rank : 95, Error : 0.1007\n",
            "✅ Rank : 96, Error : 0.1033\n",
            "✅ Rank : 97, Error : 0.0999\n",
            "✅ Rank : 98, Error : 0.0949\n",
            "✅ Rank : 99, Error : 0.0939\n",
            "✅ Rank : 100, Error : 0.0921\n",
            "✅ Rank : 101, Error : 0.0900\n",
            "✅ Rank : 102, Error : 0.0892\n",
            "✅ Rank : 103, Error : 0.0937\n",
            "✅ Rank : 104, Error : 0.0925\n",
            "✅ Rank : 105, Error : 0.0862\n",
            "✅ Rank : 106, Error : 0.0881\n",
            "✅ Rank : 107, Error : 0.0800\n",
            "✅ Rank : 108, Error : 0.0847\n",
            "✅ Rank : 109, Error : 0.0841\n",
            "✅ Rank : 110, Error : 0.0834\n",
            "✅ Rank : 111, Error : 0.0840\n",
            "✅ Rank : 112, Error : 0.0832\n",
            "✅ Rank : 113, Error : 0.0826\n",
            "✅ Rank : 114, Error : 0.0832\n",
            "✅ Rank : 115, Error : 0.0728\n",
            "✅ Rank : 116, Error : 0.0828\n",
            "✅ Rank : 117, Error : 0.0851\n",
            "✅ Rank : 118, Error : 0.0749\n",
            "✅ Rank : 119, Error : 0.0801\n",
            "✅ Rank : 120, Error : 0.0804\n",
            "✅ Rank : 121, Error : 0.0760\n",
            "✅ Rank : 122, Error : 0.0747\n",
            "✅ Rank : 123, Error : 0.0758\n",
            "✅ Rank : 124, Error : 0.0803\n",
            "✅ Rank : 125, Error : 0.0741\n",
            "✅ Rank : 126, Error : 0.0794\n",
            "✅ Rank : 127, Error : 0.0751\n",
            "✅ Rank : 128, Error : 0.0732\n",
            "✅ Rank : 129, Error : 0.0779\n",
            "✅ Rank : 130, Error : 0.0771\n",
            "✅ Rank : 131, Error : 0.0659\n",
            "✅ Rank : 132, Error : 0.0682\n",
            "✅ Rank : 133, Error : 0.0614\n",
            "✅ Rank : 134, Error : 0.0707\n",
            "✅ Rank : 135, Error : 0.0740\n",
            "✅ Rank : 136, Error : 0.0607\n",
            "✅ Rank : 137, Error : 0.0668\n",
            "✅ Rank : 138, Error : 0.0698\n",
            "✅ Rank : 139, Error : 0.0695\n",
            "✅ Rank : 140, Error : 0.0683\n",
            "✅ Rank : 141, Error : 0.0701\n",
            "✅ Rank : 142, Error : 0.0687\n",
            "✅ Rank : 143, Error : 0.0608\n",
            "✅ Rank : 144, Error : 0.0567\n",
            "✅ Rank : 145, Error : 0.0598\n",
            "✅ Rank : 146, Error : 0.0670\n",
            "✅ Rank : 147, Error : 0.0578\n",
            "✅ Rank : 148, Error : 0.0576\n",
            "✅ Rank : 149, Error : 0.0706\n",
            "✅ Rank : 150, Error : 0.0530\n",
            "✅ Rank : 151, Error : 0.0638\n",
            "✅ Rank : 152, Error : 0.0654\n",
            "✅ Rank : 153, Error : 0.0627\n",
            "✅ Rank : 154, Error : 0.0587\n",
            "✅ Rank : 155, Error : 0.0549\n",
            "✅ Rank : 156, Error : 0.0562\n",
            "✅ Rank : 157, Error : 0.0531\n",
            "✅ Rank : 158, Error : 0.0634\n",
            "✅ Rank : 159, Error : 0.0551\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialisation des listes\n",
        "factors_normal_list = []\n",
        "error_normal_list = []\n",
        "ranks_tested=[]\n",
        "\n",
        "# Décompositions CP avec pas de 1\n",
        "for rank in range(1, 160, 1):\n",
        "    # Libération mémoire GPU avant chaque décomposition\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Décomposition CP\n",
        "    factors_normal = parafac(tensor_normal, rank=rank, n_iter_max=100, init='random', verbose=False)\n",
        "    reconstruction = cp_to_tensor(factors_normal)\n",
        "\n",
        "    # Calcul de l'erreur de reconstruction\n",
        "    error = tl.norm(tensor_normal - reconstruction) / tl.norm(tensor_normal)\n",
        "\n",
        "    # Stockage des résultats\n",
        "    factors_normal_list.append(factors_normal)\n",
        "    error_normal_list.append(error.item())\n",
        "    ranks_tested.append(rank)\n",
        "\n",
        "    print(f\"✅ Rank : {rank}, Error : {error.item():.4f}\")\n",
        "\n",
        "# Libération mémoire GPU après toutes les décompositions\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Tracé de l'erreur de reconstruction\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(ranks_tested, error_normal_list, marker='o')\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Relative Error')\n",
        "plt.title('Reconstruction Error vs Rank (Tensor Normal)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK54spOBv81l"
      },
      "source": [
        "**Normal Projection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRmS10DOReBh"
      },
      "outputs": [],
      "source": [
        "def normal_space_projection(tensor_input, tensor_ref):\n",
        "    # Extraire les facteurs de la décomposition de référence\n",
        "    lambdas_ref, (A_ref, B_ref, C_ref, D_ref) = tensor_ref\n",
        "    rank = lambdas_ref.shape[0]\n",
        "\n",
        "    device = tensor_input.device\n",
        "    tensor_input = tensor_input.to(torch.float32).to(device)\n",
        "    B_ref = B_ref.to(torch.float32).to(device)\n",
        "    C_ref = C_ref.to(torch.float32).to(device)\n",
        "    D_ref = D_ref.to(torch.float32).to(device)\n",
        "    lambdas_ref = lambdas_ref.to(torch.float32).to(device)\n",
        "\n",
        "    # Étape 1 : décomposition CP de tensor_input au même rang que tensor_ref\n",
        "    cp_input = parafac(tensor_input, rank=rank, n_iter_max=100, init='random', verbose=False)\n",
        "    low_rank_tensor_input = cp_to_tensor(cp_input)  # reconstruction low-rank du tenseur input\n",
        "\n",
        "    # Étape 2 : projection de low_rank_tensor_input dans l’espace de (B, C, D)\n",
        "    # pondération des facteurs de référence\n",
        "    B_w = B_ref * lambdas_ref.view(1, -1)\n",
        "    C_w = C_ref * lambdas_ref.view(1, -1)\n",
        "    D_w = D_ref * lambdas_ref.view(1, -1)\n",
        "\n",
        "    # Khatri-Rao product pondéré\n",
        "    kr_product = tl.tenalg.khatri_rao([D_w, tl.tenalg.khatri_rao([C_w, B_w])])\n",
        "    kr_pinv = torch.linalg.pinv(kr_product.T)  # pseudo-inverse du Khatri-Rao\n",
        "\n",
        "    num_time_slices = low_rank_tensor_input.shape[0]\n",
        "    A_proj = torch.zeros((num_time_slices, rank), dtype=torch.float32, device=device)\n",
        "\n",
        "    for t in range(num_time_slices):\n",
        "        slice_t = low_rank_tensor_input[t].reshape(1, -1)  # shape: (1, features)\n",
        "        A_proj[t] = slice_t @ kr_pinv  # projection\n",
        "\n",
        "    # Étape 3 : reconstruction du tenseur projeté\n",
        "    low_rank_projected = cp_to_tensor((torch.ones(rank, device=device), [A_proj, B_ref, C_ref, D_ref]))\n",
        "\n",
        "    # Étape 4 : calcul du résidu\n",
        "    residual = low_rank_tensor_input - low_rank_projected\n",
        "\n",
        "    print(\"✅ Décomposition, projection et résidu calculés.\")\n",
        "    print(\"Norme du résidu :\", tl.norm(residual).item())\n",
        "\n",
        "    return residual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wZ8AAc2OWQLY",
        "outputId": "2986dc5c-ef35-420e-b68b-6640c4a7ac91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 18.635286331176758\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 1\n",
            "✅ Error : 0.43912604451179504\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 21.795228958129883\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 2\n",
            "✅ Error : 0.5135876536369324\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 23.779132843017578\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 3\n",
            "✅ Error : 0.5603368282318115\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 25.02140998840332\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 4\n",
            "✅ Error : 0.5896100997924805\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 26.1839542388916\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 5\n",
            "✅ Error : 0.6170045733451843\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 26.980052947998047\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 6\n",
            "✅ Error : 0.6357640027999878\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 27.566564559936523\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 7\n",
            "✅ Error : 0.6495847105979919\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 28.10154914855957\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 8\n",
            "✅ Error : 0.6621912121772766\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 28.59959602355957\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 9\n",
            "✅ Error : 0.6739273071289062\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 29.000102996826172\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 10\n",
            "✅ Error : 0.6833649277687073\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 29.465585708618164\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 11\n",
            "✅ Error : 0.6943336725234985\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 29.825408935546875\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 12\n",
            "✅ Error : 0.7028126120567322\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 30.15574836730957\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 13\n",
            "✅ Error : 0.7105967998504639\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 30.417264938354492\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 14\n",
            "✅ Error : 0.716759204864502\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 30.68008804321289\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 15\n",
            "✅ Error : 0.7229524850845337\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 30.923542022705078\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 16\n",
            "✅ Error : 0.7286892533302307\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 31.176881790161133\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 17\n",
            "✅ Error : 0.7346590161323547\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 31.48491668701172\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 18\n",
            "✅ Error : 0.741917610168457\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 31.647104263305664\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 19\n",
            "✅ Error : 0.7457394599914551\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 31.924209594726562\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 20\n",
            "✅ Error : 0.7522692084312439\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 32.09288024902344\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 21\n",
            "✅ Error : 0.7562438249588013\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 32.336978912353516\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 22\n",
            "✅ Error : 0.761995792388916\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 32.59917068481445\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 23\n",
            "✅ Error : 0.7681741714477539\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 32.77070236206055\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 24\n",
            "✅ Error : 0.7722161412239075\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 32.9490966796875\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 25\n",
            "✅ Error : 0.7764198780059814\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 33.11307907104492\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 26\n",
            "✅ Error : 0.7802839875221252\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 33.335670471191406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 27\n",
            "✅ Error : 0.7855291962623596\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 33.5053596496582\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 28\n",
            "✅ Error : 0.7895277738571167\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 33.64719772338867\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 29\n",
            "✅ Error : 0.7928701043128967\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 33.8040657043457\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 30\n",
            "✅ Error : 0.7965665459632874\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.02113723754883\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 31\n",
            "✅ Error : 0.8016816973686218\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.139495849609375\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 32\n",
            "✅ Error : 0.8044707179069519\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.29762268066406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 33\n",
            "✅ Error : 0.8081968426704407\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.449554443359375\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 34\n",
            "✅ Error : 0.8117769956588745\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.57788848876953\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 35\n",
            "✅ Error : 0.8148010969161987\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.73580551147461\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 36\n",
            "✅ Error : 0.8185222744941711\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.90531921386719\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 37\n",
            "✅ Error : 0.8225167393684387\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.02251052856445\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 38\n",
            "✅ Error : 0.8252782821655273\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.1966438293457\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 39\n",
            "✅ Error : 0.8293815851211548\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.33982467651367\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 40\n",
            "✅ Error : 0.8327555060386658\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.451988220214844\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 41\n",
            "✅ Error : 0.8353985548019409\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.61153793334961\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 42\n",
            "✅ Error : 0.8391582369804382\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.67549514770508\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 43\n",
            "✅ Error : 0.840665340423584\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.827423095703125\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 44\n",
            "✅ Error : 0.844245433807373\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 35.956382751464844\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 45\n",
            "✅ Error : 0.8472842574119568\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.089263916015625\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 46\n",
            "✅ Error : 0.8504154682159424\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.20417404174805\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 47\n",
            "✅ Error : 0.8531232476234436\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.31636047363281\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 48\n",
            "✅ Error : 0.8557668328285217\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.41950607299805\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 49\n",
            "✅ Error : 0.8581973910331726\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.54523468017578\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 50\n",
            "✅ Error : 0.8611600995063782\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.6806526184082\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 51\n",
            "✅ Error : 0.8643510937690735\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.74065017700195\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 52\n",
            "✅ Error : 0.8657649159431458\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.855892181396484\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 53\n",
            "✅ Error : 0.8684805035591125\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.970584869384766\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 54\n",
            "✅ Error : 0.8711831569671631\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.07853698730469\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 55\n",
            "✅ Error : 0.8737269639968872\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.151790618896484\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 56\n",
            "✅ Error : 0.8754531145095825\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.23396301269531\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 57\n",
            "✅ Error : 0.8773894309997559\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.332122802734375\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 58\n",
            "✅ Error : 0.8797025084495544\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.45729064941406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 59\n",
            "✅ Error : 0.8826519846916199\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.50266647338867\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 60\n",
            "✅ Error : 0.8837212324142456\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.616676330566406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 61\n",
            "✅ Error : 0.8864077925682068\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.62416076660156\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 62\n",
            "✅ Error : 0.8865841627120972\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.71306610107422\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 63\n",
            "✅ Error : 0.8886791467666626\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.79610824584961\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 64\n",
            "✅ Error : 0.8906359672546387\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.87125015258789\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 65\n",
            "✅ Error : 0.8924065828323364\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.977298736572266\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 66\n",
            "✅ Error : 0.8949055671691895\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.04759216308594\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 67\n",
            "✅ Error : 0.8965619802474976\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.04704666137695\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 68\n",
            "✅ Error : 0.8965491056442261\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.18410873413086\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 69\n",
            "✅ Error : 0.8997789025306702\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.24201583862305\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 70\n",
            "✅ Error : 0.9011434316635132\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.285457611083984\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 71\n",
            "✅ Error : 0.9021670818328857\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.376007080078125\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 72\n",
            "✅ Error : 0.9043008089065552\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.395225524902344\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 73\n",
            "✅ Error : 0.9047536849975586\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.44105911254883\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 74\n",
            "✅ Error : 0.9058337211608887\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.53281021118164\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 75\n",
            "✅ Error : 0.9079957604408264\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.571170806884766\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 76\n",
            "✅ Error : 0.90889972448349\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.652523040771484\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 77\n",
            "✅ Error : 0.9108166694641113\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.63557815551758\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 78\n",
            "✅ Error : 0.910417377948761\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.738243103027344\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 79\n",
            "✅ Error : 0.9128366112709045\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.765830993652344\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 80\n",
            "✅ Error : 0.9134867191314697\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.838905334472656\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 81\n",
            "✅ Error : 0.915208637714386\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.83744812011719\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 82\n",
            "✅ Error : 0.9151743054389954\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.954322814941406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 83\n",
            "✅ Error : 0.9179283976554871\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.01222229003906\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 84\n",
            "✅ Error : 0.9192927479743958\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.02307891845703\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 85\n",
            "✅ Error : 0.9195485711097717\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.076927185058594\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 86\n",
            "✅ Error : 0.9208174347877502\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.04506301879883\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 87\n",
            "✅ Error : 0.9200665950775146\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.13190841674805\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 88\n",
            "✅ Error : 0.9221130609512329\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.133148193359375\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 89\n",
            "✅ Error : 0.9221422672271729\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.17919158935547\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 90\n",
            "✅ Error : 0.9232272505760193\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.168434143066406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 91\n",
            "✅ Error : 0.9229737520217896\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.3274040222168\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 92\n",
            "✅ Error : 0.9267197251319885\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.25114822387695\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 93\n",
            "✅ Error : 0.9249228239059448\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.25578308105469\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 94\n",
            "✅ Error : 0.9250320792198181\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.3897819519043\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 95\n",
            "✅ Error : 0.9281896352767944\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.44417190551758\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 96\n",
            "✅ Error : 0.9294713139533997\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.34566879272461\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 97\n",
            "✅ Error : 0.9271501302719116\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.440513610839844\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 98\n",
            "✅ Error : 0.9293850660324097\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.43111038208008\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 99\n",
            "✅ Error : 0.9291635155677795\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.50337219238281\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 100\n",
            "✅ Error : 0.9308663010597229\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.502193450927734\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 101\n",
            "✅ Error : 0.9308385252952576\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.45807647705078\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 102\n",
            "✅ Error : 0.92979896068573\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.56761932373047\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 103\n",
            "✅ Error : 0.9323802590370178\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.5965461730957\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 104\n",
            "✅ Error : 0.9330618977546692\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.59465026855469\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 105\n",
            "✅ Error : 0.9330171942710876\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.65807342529297\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 106\n",
            "✅ Error : 0.9345117211341858\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.65864181518555\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 107\n",
            "✅ Error : 0.9345251321792603\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.677337646484375\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 108\n",
            "✅ Error : 0.9349656701087952\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.696136474609375\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 109\n",
            "✅ Error : 0.9354086518287659\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.72941207885742\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 110\n",
            "✅ Error : 0.9361927509307861\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.83229064941406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 111\n",
            "✅ Error : 0.9386169910430908\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.711727142333984\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 112\n",
            "✅ Error : 0.9357759952545166\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.781044006347656\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 113\n",
            "✅ Error : 0.9374094009399414\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.848052978515625\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 114\n",
            "✅ Error : 0.938988447189331\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.83488082885742\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 115\n",
            "✅ Error : 0.9386780261993408\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.81855010986328\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 116\n",
            "✅ Error : 0.9382932186126709\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.947513580322266\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 117\n",
            "✅ Error : 0.9413321614265442\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.93214416503906\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 118\n",
            "✅ Error : 0.9409700036048889\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.92616653442383\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 119\n",
            "✅ Error : 0.9408290982246399\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.9484977722168\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 120\n",
            "✅ Error : 0.9413553476333618\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.997581481933594\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 121\n",
            "✅ Error : 0.9425119757652283\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.95109558105469\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 122\n",
            "✅ Error : 0.9414165616035461\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.985862731933594\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 123\n",
            "✅ Error : 0.9422358274459839\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.13273239135742\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 124\n",
            "✅ Error : 0.9456967115402222\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.06803894042969\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 125\n",
            "✅ Error : 0.944172203540802\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.047550201416016\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 126\n",
            "✅ Error : 0.9436894059181213\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.12047576904297\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 127\n",
            "✅ Error : 0.9454078674316406\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.19643020629883\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 128\n",
            "✅ Error : 0.947197675704956\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.066226959228516\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 129\n",
            "✅ Error : 0.9441295266151428\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.23242950439453\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 130\n",
            "✅ Error : 0.9480459690093994\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.19038391113281\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 131\n",
            "✅ Error : 0.9470552206039429\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.232643127441406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 132\n",
            "✅ Error : 0.9480509757995605\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.194061279296875\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 133\n",
            "✅ Error : 0.9471418261528015\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.22772216796875\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 134\n",
            "✅ Error : 0.9479350447654724\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.253971099853516\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 135\n",
            "✅ Error : 0.9485535621643066\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.19221496582031\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 136\n",
            "✅ Error : 0.9470983147621155\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.2811393737793\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 137\n",
            "✅ Error : 0.9491937756538391\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.357601165771484\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 138\n",
            "✅ Error : 0.9509955644607544\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.373600006103516\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 139\n",
            "✅ Error : 0.9513725638389587\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.34341812133789\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 140\n",
            "✅ Error : 0.950661301612854\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.37882614135742\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 141\n",
            "✅ Error : 0.9514957070350647\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.34736251831055\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 142\n",
            "✅ Error : 0.9507542848587036\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.31996536254883\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 143\n",
            "✅ Error : 0.9501087069511414\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.441673278808594\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 144\n",
            "✅ Error : 0.952976644039154\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.4887580871582\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 145\n",
            "✅ Error : 0.9540861248970032\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.40504455566406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 146\n",
            "✅ Error : 0.9521135091781616\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.384403228759766\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 147\n",
            "✅ Error : 0.9516271352767944\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.403194427490234\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 148\n",
            "✅ Error : 0.9520699381828308\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.42554473876953\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 149\n",
            "✅ Error : 0.9525966048240662\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.46745681762695\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 150\n",
            "✅ Error : 0.9535841941833496\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.512760162353516\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 151\n",
            "✅ Error : 0.9546517133712769\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.48960494995117\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 152\n",
            "✅ Error : 0.9541060924530029\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.45205307006836\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 153\n",
            "✅ Error : 0.9532212018966675\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.488990783691406\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 154\n",
            "✅ Error : 0.9540916085243225\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.66196060180664\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 155\n",
            "✅ Error : 0.958167552947998\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.63596725463867\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 156\n",
            "✅ Error : 0.9575549960136414\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.54786682128906\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 157\n",
            "✅ Error : 0.9554790258407593\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.59178161621094\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 158\n",
            "✅ Error : 0.9565138220787048\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.621192932128906\n",
            "✅ Residual calculé.\n",
            "✅ Rank : 159\n",
            "✅ Error : 0.9572069048881531\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Relative Error')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "residuals_train_list=[]\n",
        "error_train_list=[]\n",
        "rank_list=[]\n",
        "for tensor in factors_normal_list:\n",
        "    residuals_train = normal_space_projection(tensor_train, tensor)\n",
        "    residuals_train_list.append(residuals_train)\n",
        "    error_train=tl.norm(residuals_train)/tl.norm(tensor_train)\n",
        "    error_train_list.append(error_train.item())\n",
        "    print(\"✅ Residual calculé.\")\n",
        "    rank_list.append(tensor[0].shape[0])\n",
        "    print(\"✅ Rank :\",tensor[0].shape[0])\n",
        "    print(\"✅ Error :\",error_train.item())\n",
        "\n",
        "fig=plt.figure(figsize=(12,6))\n",
        "plt.plot(rank_list,error_train_list,marker='o')\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Relative Error')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tl.norm(residuals_train_list[158])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxzqmklxZCZF",
        "outputId": "6455929e-1ddf-453f-b3a0-2d12213facd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(40.6212, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nva5k2YIReBh"
      },
      "source": [
        "# AGGREGATION_SCORING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD68F03dReBi"
      },
      "outputs": [],
      "source": [
        "def aggregation_scoring_Source(residuals, mappings, df_with_labels, window_size=300):\n",
        "    print(\"⏳ Étape 4 : Aggrégation des scores avec labels...\")\n",
        "\n",
        "    # 1. Convertir relative_time -> time_window (entier)\n",
        "    df_with_labels = df_with_labels.copy()\n",
        "    df_with_labels['time_window'] = df_with_labels['relative_time'].astype(np.int64) // (10**9 * window_size)\n",
        "\n",
        "    # 2. Créer le mapping des labels (Dst IP, time_window) -> label\n",
        "    label_map = {}\n",
        "    for _, row in df_with_labels.iterrows():\n",
        "        key = (row['Dst IP'], int(row['time_window']))\n",
        "        label = int(row['label']) if pd.notnull(row['label']) else 0\n",
        "        label_map[key] = max(label_map.get(key, 0), label)\n",
        "\n",
        "    # 3. Préparer les dimensions\n",
        "    # Move the tensor to CPU before converting to NumPy\n",
        "    residuals_np = tl.to_numpy(residuals.cpu())\n",
        "    idx_to_dst_ip = {idx: ip for ip, idx in mappings['Dst_IP'].items()}\n",
        "    idx_to_feature = {idx: feat for idx, feat in mappings['features_names'].items()}\n",
        "    time_dim, _, dst_dim, feat_dim = residuals_np.shape\n",
        "\n",
        "    # 4. Construire la liste des time_windows à partir de l’index\n",
        "    time_windows = list(range(time_dim))\n",
        "\n",
        "    # 5. Aggrégation + étiquetage\n",
        "    aggregation = {}\n",
        "    for t in range(time_dim):\n",
        "        time_window = time_windows[t]\n",
        "        for d in range(dst_dim):\n",
        "            # Check if the index 'd' exists in idx_to_dst_ip\n",
        "            if d in idx_to_dst_ip:\n",
        "                dst_ip = idx_to_dst_ip[d]\n",
        "                key = (dst_ip, time_window)\n",
        "\n",
        "                if key not in aggregation:\n",
        "                    aggregation[key] = {\n",
        "                        'Dst IP': dst_ip,\n",
        "                        'time_windows': time_window,\n",
        "                        'count': 0,\n",
        "                        'bytes': 0,\n",
        "                        'packets': 0,\n",
        "                        'duration': 0,\n",
        "                        'label': label_map.get(key, 0)  # label ajouté ici\n",
        "                    }\n",
        "\n",
        "                for f in range(feat_dim):\n",
        "                    feature_name = idx_to_feature[f].lower()\n",
        "                    score = np.sum(np.abs(residuals_np[t, :, d, f]))\n",
        "\n",
        "                    if 'count' in feature_name:\n",
        "                        aggregation[key]['count'] += score\n",
        "                    elif 'bytes' in feature_name:\n",
        "                        aggregation[key]['bytes'] += score\n",
        "                    elif 'packets' in feature_name:\n",
        "                        aggregation[key]['packets'] += score\n",
        "                    elif 'duration' in feature_name:\n",
        "                        aggregation[key]['duration'] += score\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    df_scores = pd.DataFrame(list(aggregation.values()))\n",
        "\n",
        "    #log_step(\"Étape 4\", start)\n",
        "    print(\"✅ Aggrégation des scores + labels terminée.\")\n",
        "\n",
        "    return df_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x65CBMk0ReBi"
      },
      "outputs": [],
      "source": [
        "mappings={'Dst_IP':dst_ip_to_idx_train,'features_names':dict(enumerate(['count','bytes','packets','duration']))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3naVxKNReBj"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_iqr(df, features):\n",
        "    cleaned_df = df.copy()\n",
        "    for col in features:\n",
        "        Q1 = cleaned_df[col].quantile(0.25)\n",
        "        Q3 = cleaned_df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        # Filtrer les lignes en fonction de la colonne actuelle\n",
        "        cleaned_df = cleaned_df[(cleaned_df[col] >= lower_bound) & (cleaned_df[col] <= upper_bound)]\n",
        "    return cleaned_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_score_list=[]\n",
        "rank=1\n",
        "for df in residuals_train_list:\n",
        "    df_scores_train=aggregation_scoring_Source(df,mappings, df_train, window_size=300)\n",
        "    df_score_list.append(df_scores_train)\n",
        "    print('rank , ', rank)\n",
        "    print(\"✅ Score calculé.\")\n",
        "    rank+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oyv82eYMZrTx",
        "outputId": "4d56ecc0-157d-49f6-a775-4e06253ab02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  1\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  2\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  3\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  4\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  5\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  6\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  7\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  8\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  9\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  10\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  11\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  12\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  13\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  14\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  15\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  16\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  17\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  18\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  19\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  20\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  21\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  22\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  23\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  24\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  25\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  26\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  27\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  28\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  29\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  30\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  31\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  32\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  33\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  34\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  35\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  36\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  37\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  38\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  39\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  40\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  41\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  42\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  43\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  44\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  45\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  46\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  47\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  48\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  49\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  50\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  51\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  52\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  53\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  54\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  55\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  56\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  57\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  58\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  59\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  60\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  61\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  62\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  63\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  64\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  65\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  66\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  67\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  68\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  69\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  70\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  71\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  72\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  73\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  74\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  75\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  76\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  77\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  78\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  79\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  80\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  81\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  82\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  83\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  84\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  85\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  86\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  87\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  88\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  89\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  90\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  91\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  92\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  93\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  94\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  95\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  96\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  97\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  98\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  99\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  100\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  101\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  102\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  103\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  104\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  105\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  106\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  107\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  108\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  109\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  110\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  111\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  112\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  113\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  114\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  115\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  116\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  117\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  118\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  119\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  120\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  121\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  122\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n",
            "✅ Aggrégation des scores + labels terminée.\n",
            "rank ,  123\n",
            "✅ Score calculé.\n",
            "⏳ Étape 4 : Aggrégation des scores avec labels...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-3ee2ce9f934a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresiduals_train_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf_scores_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation_scoring_Source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmappings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdf_score_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_scores_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rank , '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-288c0cec5e0f>\u001b[0m in \u001b[0;36maggregation_scoring_Source\u001b[0;34m(residuals, mappings, df_with_labels, window_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_with_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dst IP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_window'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \"\"\"\n\u001b[0;32m--> 863\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minternal_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0minternal_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m         \u001b[0;34m\"\"\"The array that Series._values returns\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vy__7T0R7jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f02c244-09c2-4199-8307-a8bd737ef1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n",
            "✅ Outliers supprimés.\n"
          ]
        }
      ],
      "source": [
        "df_cleaned_list=[]\n",
        "features=['count','bytes','packets','duration']\n",
        "for df in df_score_list:\n",
        "    removed=remove_outliers_iqr(df,features)\n",
        "    print(\"✅ Outliers supprimés.\")\n",
        "    df_cleaned=pd.concat([removed,df[df['label']==1]],axis=0)\n",
        "    df_cleaned_list.append(df_cleaned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efjMWnKGTlEn"
      },
      "outputs": [],
      "source": [
        "def build_and_train_binary_classifier(X_train, y_train, X_test, y_test, learning_rate=0.0001, batch_size=10, epochs=30):\n",
        "    input_dim = X_train.shape[1]\n",
        "\n",
        "    # Définition du modèle\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(128, activation='sigmoid'),\n",
        "        layers.Dense(80, activation='sigmoid'),\n",
        "        layers.Dense(80, activation='sigmoid'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='sigmoid'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(32, activation='sigmoid'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    ])\n",
        "\n",
        "    # Compilation\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC()]\n",
        "    )\n",
        "\n",
        "\n",
        "    # Entraînement\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ExT7zt5ReBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ab31e6-0e6f-4dc9-89ec-8318560855dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.4681 - auc: 0.4990 - loss: 0.7531 - val_accuracy: 0.6747 - val_auc: 0.5000 - val_loss: 0.6316\n",
            "Epoch 2/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6407 - auc: 0.4967 - loss: 0.6574 - val_accuracy: 0.6747 - val_auc: 0.5049 - val_loss: 0.6310\n",
            "Epoch 3/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6666 - auc: 0.4959 - loss: 0.6454 - val_accuracy: 0.6747 - val_auc: 0.5000 - val_loss: 0.6309\n",
            "Epoch 4/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6692 - auc: 0.4813 - loss: 0.6468 - val_accuracy: 0.6747 - val_auc: 0.5000 - val_loss: 0.6308\n",
            "Epoch 5/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6679 - auc: 0.4867 - loss: 0.6438 - val_accuracy: 0.6747 - val_auc: 0.5000 - val_loss: 0.6308\n",
            "Epoch 6/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6807 - auc: 0.5075 - loss: 0.6325 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6308\n",
            "Epoch 7/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6832 - auc: 0.5063 - loss: 0.6325 - val_accuracy: 0.6747 - val_auc: 0.5057 - val_loss: 0.6310\n",
            "Epoch 8/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6565 - auc: 0.5085 - loss: 0.6469 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6311\n",
            "Epoch 9/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6646 - auc: 0.4858 - loss: 0.6474 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6311\n",
            "Epoch 10/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6750 - auc: 0.5026 - loss: 0.6337 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6309\n",
            "Epoch 11/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6875 - auc: 0.4992 - loss: 0.6284 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6308\n",
            "Epoch 12/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6677 - auc: 0.4993 - loss: 0.6422 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6309\n",
            "Epoch 13/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6755 - auc: 0.5069 - loss: 0.6354 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6307\n",
            "Epoch 14/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6720 - auc: 0.5046 - loss: 0.6366 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6307\n",
            "Epoch 15/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6730 - auc: 0.4932 - loss: 0.6376 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6308\n",
            "Epoch 16/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6809 - auc: 0.5192 - loss: 0.6279 - val_accuracy: 0.6747 - val_auc: 0.5025 - val_loss: 0.6307\n",
            "Epoch 17/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6635 - auc: 0.5009 - loss: 0.6428 - val_accuracy: 0.6747 - val_auc: 0.5106 - val_loss: 0.6310\n",
            "Epoch 18/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6657 - auc: 0.5132 - loss: 0.6387 - val_accuracy: 0.6747 - val_auc: 0.5090 - val_loss: 0.6310\n",
            "Epoch 19/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6761 - auc: 0.5025 - loss: 0.6326 - val_accuracy: 0.6747 - val_auc: 0.5123 - val_loss: 0.6307\n",
            "Epoch 20/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6659 - auc: 0.4868 - loss: 0.6424 - val_accuracy: 0.6747 - val_auc: 0.5229 - val_loss: 0.6307\n",
            "Epoch 21/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6700 - auc: 0.4812 - loss: 0.6400 - val_accuracy: 0.6747 - val_auc: 0.5057 - val_loss: 0.6307\n",
            "Epoch 22/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6709 - auc: 0.4900 - loss: 0.6379 - val_accuracy: 0.6747 - val_auc: 0.5115 - val_loss: 0.6307\n",
            "Epoch 23/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6781 - auc: 0.5044 - loss: 0.6315 - val_accuracy: 0.6747 - val_auc: 0.5581 - val_loss: 0.6307\n",
            "Epoch 24/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6858 - auc: 0.5031 - loss: 0.6254 - val_accuracy: 0.6747 - val_auc: 0.5368 - val_loss: 0.6307\n",
            "Epoch 25/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6646 - auc: 0.4987 - loss: 0.6409 - val_accuracy: 0.6747 - val_auc: 0.5115 - val_loss: 0.6307\n",
            "Epoch 26/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6817 - auc: 0.4892 - loss: 0.6293 - val_accuracy: 0.6747 - val_auc: 0.5139 - val_loss: 0.6306\n",
            "Epoch 27/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6739 - auc: 0.5111 - loss: 0.6326 - val_accuracy: 0.6747 - val_auc: 0.5090 - val_loss: 0.6306\n",
            "Epoch 28/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6846 - auc: 0.5071 - loss: 0.6254 - val_accuracy: 0.6747 - val_auc: 0.5368 - val_loss: 0.6308\n",
            "Epoch 29/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6697 - auc: 0.5056 - loss: 0.6364 - val_accuracy: 0.6747 - val_auc: 0.5278 - val_loss: 0.6306\n",
            "Epoch 30/30\n",
            "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6735 - auc: 0.5117 - loss: 0.6327 - val_accuracy: 0.6747 - val_auc: 0.5556 - val_loss: 0.6306\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 20ms/step - accuracy: 0.5979 - auc_1: 0.4833 - loss: 0.6686 - val_accuracy: 0.6679 - val_auc_1: 0.5000 - val_loss: 0.6356\n",
            "Epoch 2/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6724 - auc_1: 0.4934 - loss: 0.6404 - val_accuracy: 0.6679 - val_auc_1: 0.5000 - val_loss: 0.6356\n",
            "Epoch 3/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6655 - auc_1: 0.4901 - loss: 0.6460 - val_accuracy: 0.6679 - val_auc_1: 0.5032 - val_loss: 0.6362\n",
            "Epoch 4/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6863 - auc_1: 0.4925 - loss: 0.6299 - val_accuracy: 0.6679 - val_auc_1: 0.5000 - val_loss: 0.6357\n",
            "Epoch 5/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6580 - auc_1: 0.4972 - loss: 0.6495 - val_accuracy: 0.6679 - val_auc_1: 0.5032 - val_loss: 0.6367\n",
            "Epoch 6/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6737 - auc_1: 0.5042 - loss: 0.6366 - val_accuracy: 0.6679 - val_auc_1: 0.5048 - val_loss: 0.6356\n",
            "Epoch 7/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6685 - auc_1: 0.4751 - loss: 0.6453 - val_accuracy: 0.6679 - val_auc_1: 0.5016 - val_loss: 0.6356\n",
            "Epoch 8/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6579 - auc_1: 0.5030 - loss: 0.6471 - val_accuracy: 0.6679 - val_auc_1: 0.5048 - val_loss: 0.6359\n",
            "Epoch 9/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6737 - auc_1: 0.4971 - loss: 0.6372 - val_accuracy: 0.6679 - val_auc_1: 0.5048 - val_loss: 0.6355\n",
            "Epoch 10/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6708 - auc_1: 0.5257 - loss: 0.6351 - val_accuracy: 0.6679 - val_auc_1: 0.5048 - val_loss: 0.6355\n",
            "Epoch 11/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6533 - auc_1: 0.5050 - loss: 0.6498 - val_accuracy: 0.6679 - val_auc_1: 0.5176 - val_loss: 0.6358\n",
            "Epoch 12/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6718 - auc_1: 0.5009 - loss: 0.6372 - val_accuracy: 0.6679 - val_auc_1: 0.5112 - val_loss: 0.6356\n",
            "Epoch 13/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6649 - auc_1: 0.5044 - loss: 0.6414 - val_accuracy: 0.6679 - val_auc_1: 0.5695 - val_loss: 0.6354\n",
            "Epoch 14/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6737 - auc_1: 0.4911 - loss: 0.6375 - val_accuracy: 0.6679 - val_auc_1: 0.5296 - val_loss: 0.6355\n",
            "Epoch 15/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6672 - auc_1: 0.5024 - loss: 0.6405 - val_accuracy: 0.6679 - val_auc_1: 0.5319 - val_loss: 0.6354\n",
            "Epoch 16/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6684 - auc_1: 0.5092 - loss: 0.6377 - val_accuracy: 0.6679 - val_auc_1: 0.5671 - val_loss: 0.6353\n",
            "Epoch 17/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6652 - auc_1: 0.4915 - loss: 0.6423 - val_accuracy: 0.6679 - val_auc_1: 0.5312 - val_loss: 0.6353\n",
            "Epoch 18/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6716 - auc_1: 0.5139 - loss: 0.6350 - val_accuracy: 0.6679 - val_auc_1: 0.5312 - val_loss: 0.6353\n",
            "Epoch 19/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6747 - auc_1: 0.4923 - loss: 0.6354 - val_accuracy: 0.6679 - val_auc_1: 0.5567 - val_loss: 0.6352\n",
            "Epoch 20/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6836 - auc_1: 0.4898 - loss: 0.6299 - val_accuracy: 0.6679 - val_auc_1: 0.5367 - val_loss: 0.6352\n",
            "Epoch 21/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6686 - auc_1: 0.4872 - loss: 0.6400 - val_accuracy: 0.6679 - val_auc_1: 0.5671 - val_loss: 0.6350\n",
            "Epoch 22/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6592 - auc_1: 0.5115 - loss: 0.6428 - val_accuracy: 0.6679 - val_auc_1: 0.5463 - val_loss: 0.6348\n",
            "Epoch 23/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6676 - auc_1: 0.4884 - loss: 0.6399 - val_accuracy: 0.6679 - val_auc_1: 0.5759 - val_loss: 0.6346\n",
            "Epoch 24/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6694 - auc_1: 0.5058 - loss: 0.6362 - val_accuracy: 0.6679 - val_auc_1: 0.5591 - val_loss: 0.6344\n",
            "Epoch 25/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6697 - auc_1: 0.5169 - loss: 0.6351 - val_accuracy: 0.6679 - val_auc_1: 0.5703 - val_loss: 0.6341\n",
            "Epoch 26/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6745 - auc_1: 0.5215 - loss: 0.6311 - val_accuracy: 0.6679 - val_auc_1: 0.5727 - val_loss: 0.6337\n",
            "Epoch 27/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6691 - auc_1: 0.5275 - loss: 0.6348 - val_accuracy: 0.6679 - val_auc_1: 0.5639 - val_loss: 0.6331\n",
            "Epoch 28/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6686 - auc_1: 0.4841 - loss: 0.6391 - val_accuracy: 0.6679 - val_auc_1: 0.5751 - val_loss: 0.6324\n",
            "Epoch 29/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6595 - auc_1: 0.5257 - loss: 0.6409 - val_accuracy: 0.6679 - val_auc_1: 0.5807 - val_loss: 0.6315\n",
            "Epoch 30/30\n",
            "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6641 - auc_1: 0.5421 - loss: 0.6356 - val_accuracy: 0.6679 - val_auc_1: 0.5759 - val_loss: 0.6300\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5353 - auc_2: 0.5018 - loss: 0.7061 - val_accuracy: 0.6677 - val_auc_2: 0.5000 - val_loss: 0.6358\n",
            "Epoch 2/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6545 - auc_2: 0.5077 - loss: 0.6489 - val_accuracy: 0.6677 - val_auc_2: 0.5000 - val_loss: 0.6358\n",
            "Epoch 3/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6532 - auc_2: 0.4856 - loss: 0.6510 - val_accuracy: 0.6677 - val_auc_2: 0.5000 - val_loss: 0.6365\n",
            "Epoch 4/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6654 - auc_2: 0.5023 - loss: 0.6449 - val_accuracy: 0.6677 - val_auc_2: 0.5000 - val_loss: 0.6358\n",
            "Epoch 5/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6611 - auc_2: 0.4914 - loss: 0.6480 - val_accuracy: 0.6677 - val_auc_2: 0.5016 - val_loss: 0.6357\n",
            "Epoch 6/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6780 - auc_2: 0.5016 - loss: 0.6337 - val_accuracy: 0.6677 - val_auc_2: 0.5607 - val_loss: 0.6358\n",
            "Epoch 7/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6668 - auc_2: 0.5139 - loss: 0.6427 - val_accuracy: 0.6677 - val_auc_2: 0.5000 - val_loss: 0.6357\n",
            "Epoch 8/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6645 - auc_2: 0.5082 - loss: 0.6433 - val_accuracy: 0.6677 - val_auc_2: 0.5032 - val_loss: 0.6356\n",
            "Epoch 9/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6620 - auc_2: 0.4933 - loss: 0.6463 - val_accuracy: 0.6677 - val_auc_2: 0.5032 - val_loss: 0.6356\n",
            "Epoch 10/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6724 - auc_2: 0.5207 - loss: 0.6342 - val_accuracy: 0.6677 - val_auc_2: 0.5097 - val_loss: 0.6356\n",
            "Epoch 11/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6756 - auc_2: 0.5032 - loss: 0.6354 - val_accuracy: 0.6677 - val_auc_2: 0.5089 - val_loss: 0.6355\n",
            "Epoch 12/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6715 - auc_2: 0.4807 - loss: 0.6410 - val_accuracy: 0.6677 - val_auc_2: 0.5162 - val_loss: 0.6356\n",
            "Epoch 13/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6604 - auc_2: 0.5065 - loss: 0.6454 - val_accuracy: 0.6677 - val_auc_2: 0.5485 - val_loss: 0.6354\n",
            "Epoch 14/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6694 - auc_2: 0.5082 - loss: 0.6379 - val_accuracy: 0.6677 - val_auc_2: 0.5518 - val_loss: 0.6354\n",
            "Epoch 15/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6574 - auc_2: 0.5085 - loss: 0.6460 - val_accuracy: 0.6677 - val_auc_2: 0.5356 - val_loss: 0.6353\n",
            "Epoch 16/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6512 - auc_2: 0.4872 - loss: 0.6524 - val_accuracy: 0.6677 - val_auc_2: 0.5631 - val_loss: 0.6355\n",
            "Epoch 17/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6647 - auc_2: 0.5072 - loss: 0.6419 - val_accuracy: 0.6677 - val_auc_2: 0.5510 - val_loss: 0.6351\n",
            "Epoch 18/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6692 - auc_2: 0.5007 - loss: 0.6386 - val_accuracy: 0.6677 - val_auc_2: 0.5534 - val_loss: 0.6350\n",
            "Epoch 19/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6599 - auc_2: 0.5159 - loss: 0.6430 - val_accuracy: 0.6677 - val_auc_2: 0.5510 - val_loss: 0.6348\n",
            "Epoch 20/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6662 - auc_2: 0.4861 - loss: 0.6420 - val_accuracy: 0.6677 - val_auc_2: 0.5599 - val_loss: 0.6347\n",
            "Epoch 21/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6739 - auc_2: 0.4821 - loss: 0.6376 - val_accuracy: 0.6677 - val_auc_2: 0.5534 - val_loss: 0.6345\n",
            "Epoch 22/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6666 - auc_2: 0.5092 - loss: 0.6390 - val_accuracy: 0.6677 - val_auc_2: 0.5615 - val_loss: 0.6342\n",
            "Epoch 23/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6582 - auc_2: 0.5244 - loss: 0.6421 - val_accuracy: 0.6677 - val_auc_2: 0.5704 - val_loss: 0.6339\n",
            "Epoch 24/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6629 - auc_2: 0.5061 - loss: 0.6418 - val_accuracy: 0.6677 - val_auc_2: 0.5583 - val_loss: 0.6336\n",
            "Epoch 25/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6574 - auc_2: 0.4745 - loss: 0.6496 - val_accuracy: 0.6677 - val_auc_2: 0.6303 - val_loss: 0.6331\n",
            "Epoch 26/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6726 - auc_2: 0.5293 - loss: 0.6317 - val_accuracy: 0.6677 - val_auc_2: 0.5647 - val_loss: 0.6323\n",
            "Epoch 27/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6797 - auc_2: 0.5057 - loss: 0.6297 - val_accuracy: 0.6677 - val_auc_2: 0.5809 - val_loss: 0.6316\n",
            "Epoch 28/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6604 - auc_2: 0.5430 - loss: 0.6378 - val_accuracy: 0.6677 - val_auc_2: 0.5752 - val_loss: 0.6301\n",
            "Epoch 29/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6655 - auc_2: 0.5132 - loss: 0.6385 - val_accuracy: 0.6677 - val_auc_2: 0.5809 - val_loss: 0.6284\n",
            "Epoch 30/30\n",
            "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6606 - auc_2: 0.5451 - loss: 0.6375 - val_accuracy: 0.6677 - val_auc_2: 0.5825 - val_loss: 0.6258\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.5217 - auc_3: 0.4789 - loss: 0.7160 - val_accuracy: 0.6613 - val_auc_3: 0.5000 - val_loss: 0.6404\n",
            "Epoch 2/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6437 - auc_3: 0.5074 - loss: 0.6561 - val_accuracy: 0.6613 - val_auc_3: 0.5166 - val_loss: 0.6401\n",
            "Epoch 3/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6516 - auc_3: 0.4836 - loss: 0.6576 - val_accuracy: 0.6613 - val_auc_3: 0.5151 - val_loss: 0.6402\n",
            "Epoch 4/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6450 - auc_3: 0.4963 - loss: 0.6560 - val_accuracy: 0.6613 - val_auc_3: 0.5000 - val_loss: 0.6407\n",
            "Epoch 5/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6599 - auc_3: 0.4919 - loss: 0.6498 - val_accuracy: 0.6613 - val_auc_3: 0.5563 - val_loss: 0.6401\n",
            "Epoch 6/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6633 - auc_3: 0.5029 - loss: 0.6451 - val_accuracy: 0.6613 - val_auc_3: 0.5158 - val_loss: 0.6400\n",
            "Epoch 7/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6535 - auc_3: 0.5019 - loss: 0.6496 - val_accuracy: 0.6613 - val_auc_3: 0.5158 - val_loss: 0.6400\n",
            "Epoch 8/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6575 - auc_3: 0.5051 - loss: 0.6464 - val_accuracy: 0.6613 - val_auc_3: 0.5063 - val_loss: 0.6403\n",
            "Epoch 9/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6566 - auc_3: 0.4898 - loss: 0.6534 - val_accuracy: 0.6613 - val_auc_3: 0.5063 - val_loss: 0.6402\n",
            "Epoch 10/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6664 - auc_3: 0.5200 - loss: 0.6403 - val_accuracy: 0.6613 - val_auc_3: 0.5436 - val_loss: 0.6399\n",
            "Epoch 11/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6549 - auc_3: 0.5091 - loss: 0.6481 - val_accuracy: 0.6613 - val_auc_3: 0.5246 - val_loss: 0.6399\n",
            "Epoch 12/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6657 - auc_3: 0.5007 - loss: 0.6450 - val_accuracy: 0.6613 - val_auc_3: 0.5388 - val_loss: 0.6398\n",
            "Epoch 13/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6703 - auc_3: 0.4789 - loss: 0.6434 - val_accuracy: 0.6613 - val_auc_3: 0.5190 - val_loss: 0.6398\n",
            "Epoch 14/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6610 - auc_3: 0.4816 - loss: 0.6496 - val_accuracy: 0.6613 - val_auc_3: 0.5452 - val_loss: 0.6397\n",
            "Epoch 15/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6581 - auc_3: 0.4950 - loss: 0.6476 - val_accuracy: 0.6613 - val_auc_3: 0.5293 - val_loss: 0.6397\n",
            "Epoch 16/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6465 - auc_3: 0.4867 - loss: 0.6588 - val_accuracy: 0.6613 - val_auc_3: 0.5396 - val_loss: 0.6397\n",
            "Epoch 17/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6712 - auc_3: 0.4922 - loss: 0.6395 - val_accuracy: 0.6613 - val_auc_3: 0.5713 - val_loss: 0.6395\n",
            "Epoch 18/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6551 - auc_3: 0.5147 - loss: 0.6461 - val_accuracy: 0.6613 - val_auc_3: 0.5666 - val_loss: 0.6397\n",
            "Epoch 19/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6592 - auc_3: 0.5029 - loss: 0.6465 - val_accuracy: 0.6613 - val_auc_3: 0.5475 - val_loss: 0.6393\n",
            "Epoch 20/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6601 - auc_3: 0.4841 - loss: 0.6481 - val_accuracy: 0.6613 - val_auc_3: 0.5396 - val_loss: 0.6389\n",
            "Epoch 21/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6606 - auc_3: 0.5117 - loss: 0.6427 - val_accuracy: 0.6613 - val_auc_3: 0.5475 - val_loss: 0.6387\n",
            "Epoch 22/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6713 - auc_3: 0.5185 - loss: 0.6355 - val_accuracy: 0.6613 - val_auc_3: 0.5880 - val_loss: 0.6386\n",
            "Epoch 23/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6573 - auc_3: 0.5169 - loss: 0.6439 - val_accuracy: 0.6613 - val_auc_3: 0.5769 - val_loss: 0.6378\n",
            "Epoch 24/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6453 - auc_3: 0.5044 - loss: 0.6529 - val_accuracy: 0.6613 - val_auc_3: 0.5737 - val_loss: 0.6374\n",
            "Epoch 25/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6527 - auc_3: 0.5243 - loss: 0.6477 - val_accuracy: 0.6613 - val_auc_3: 0.5737 - val_loss: 0.6361\n",
            "Epoch 26/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6569 - auc_3: 0.5357 - loss: 0.6417 - val_accuracy: 0.6613 - val_auc_3: 0.5769 - val_loss: 0.6351\n",
            "Epoch 27/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6545 - auc_3: 0.5468 - loss: 0.6423 - val_accuracy: 0.6613 - val_auc_3: 0.5824 - val_loss: 0.6335\n",
            "Epoch 28/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6536 - auc_3: 0.5415 - loss: 0.6428 - val_accuracy: 0.6613 - val_auc_3: 0.5951 - val_loss: 0.6308\n",
            "Epoch 29/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6679 - auc_3: 0.5433 - loss: 0.6344 - val_accuracy: 0.6699 - val_auc_3: 0.5895 - val_loss: 0.6270\n",
            "Epoch 30/30\n",
            "\u001b[1m435/435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6809 - auc_3: 0.5489 - loss: 0.6288 - val_accuracy: 0.6865 - val_auc_3: 0.6046 - val_loss: 0.6220\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.6670 - auc_4: 0.5101 - loss: 0.6399 - val_accuracy: 0.6692 - val_auc_4: 0.5000 - val_loss: 0.6347\n",
            "Epoch 2/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6768 - auc_4: 0.5035 - loss: 0.6339 - val_accuracy: 0.6692 - val_auc_4: 0.5359 - val_loss: 0.6349\n",
            "Epoch 3/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6600 - auc_4: 0.4980 - loss: 0.6473 - val_accuracy: 0.6692 - val_auc_4: 0.5000 - val_loss: 0.6348\n",
            "Epoch 4/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6578 - auc_4: 0.4966 - loss: 0.6508 - val_accuracy: 0.6692 - val_auc_4: 0.5023 - val_loss: 0.6350\n",
            "Epoch 5/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6707 - auc_4: 0.4764 - loss: 0.6452 - val_accuracy: 0.6692 - val_auc_4: 0.5039 - val_loss: 0.6346\n",
            "Epoch 6/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6651 - auc_4: 0.4859 - loss: 0.6463 - val_accuracy: 0.6692 - val_auc_4: 0.5351 - val_loss: 0.6346\n",
            "Epoch 7/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6619 - auc_4: 0.4838 - loss: 0.6474 - val_accuracy: 0.6692 - val_auc_4: 0.5452 - val_loss: 0.6345\n",
            "Epoch 8/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6788 - auc_4: 0.4994 - loss: 0.6337 - val_accuracy: 0.6692 - val_auc_4: 0.5312 - val_loss: 0.6349\n",
            "Epoch 9/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6647 - auc_4: 0.4903 - loss: 0.6442 - val_accuracy: 0.6692 - val_auc_4: 0.5211 - val_loss: 0.6344\n",
            "Epoch 10/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6737 - auc_4: 0.4847 - loss: 0.6374 - val_accuracy: 0.6692 - val_auc_4: 0.5234 - val_loss: 0.6347\n",
            "Epoch 11/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6700 - auc_4: 0.5060 - loss: 0.6370 - val_accuracy: 0.6692 - val_auc_4: 0.5218 - val_loss: 0.6346\n",
            "Epoch 12/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6753 - auc_4: 0.5176 - loss: 0.6320 - val_accuracy: 0.6692 - val_auc_4: 0.5250 - val_loss: 0.6342\n",
            "Epoch 13/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6614 - auc_4: 0.5097 - loss: 0.6422 - val_accuracy: 0.6692 - val_auc_4: 0.5437 - val_loss: 0.6340\n",
            "Epoch 14/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6566 - auc_4: 0.5029 - loss: 0.6465 - val_accuracy: 0.6692 - val_auc_4: 0.5562 - val_loss: 0.6340\n",
            "Epoch 15/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6724 - auc_4: 0.5138 - loss: 0.6339 - val_accuracy: 0.6692 - val_auc_4: 0.5640 - val_loss: 0.6338\n",
            "Epoch 16/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6730 - auc_4: 0.5001 - loss: 0.6354 - val_accuracy: 0.6692 - val_auc_4: 0.5741 - val_loss: 0.6335\n",
            "Epoch 17/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6612 - auc_4: 0.5120 - loss: 0.6423 - val_accuracy: 0.6692 - val_auc_4: 0.5523 - val_loss: 0.6332\n",
            "Epoch 18/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6724 - auc_4: 0.4994 - loss: 0.6356 - val_accuracy: 0.6692 - val_auc_4: 0.5632 - val_loss: 0.6328\n",
            "Epoch 19/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6712 - auc_4: 0.5204 - loss: 0.6336 - val_accuracy: 0.6692 - val_auc_4: 0.5640 - val_loss: 0.6323\n",
            "Epoch 20/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6790 - auc_4: 0.5420 - loss: 0.6259 - val_accuracy: 0.6692 - val_auc_4: 0.5601 - val_loss: 0.6317\n",
            "Epoch 21/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6701 - auc_4: 0.5170 - loss: 0.6349 - val_accuracy: 0.6692 - val_auc_4: 0.5647 - val_loss: 0.6309\n",
            "Epoch 22/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6696 - auc_4: 0.5315 - loss: 0.6327 - val_accuracy: 0.6692 - val_auc_4: 0.5718 - val_loss: 0.6300\n",
            "Epoch 23/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6680 - auc_4: 0.5323 - loss: 0.6343 - val_accuracy: 0.6692 - val_auc_4: 0.5718 - val_loss: 0.6288\n",
            "Epoch 24/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6647 - auc_4: 0.5495 - loss: 0.6340 - val_accuracy: 0.6692 - val_auc_4: 0.5741 - val_loss: 0.6274\n",
            "Epoch 25/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6794 - auc_4: 0.5554 - loss: 0.6217 - val_accuracy: 0.6692 - val_auc_4: 0.5913 - val_loss: 0.6256\n",
            "Epoch 26/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6636 - auc_4: 0.5516 - loss: 0.6327 - val_accuracy: 0.6692 - val_auc_4: 0.5881 - val_loss: 0.6239\n",
            "Epoch 27/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6703 - auc_4: 0.5563 - loss: 0.6284 - val_accuracy: 0.6692 - val_auc_4: 0.5920 - val_loss: 0.6210\n",
            "Epoch 28/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6754 - auc_4: 0.5749 - loss: 0.6276 - val_accuracy: 0.6930 - val_auc_4: 0.5913 - val_loss: 0.6167\n",
            "Epoch 29/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6854 - auc_4: 0.5727 - loss: 0.6221 - val_accuracy: 0.6981 - val_auc_4: 0.5967 - val_loss: 0.6135\n",
            "Epoch 30/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6889 - auc_4: 0.5786 - loss: 0.6236 - val_accuracy: 0.6992 - val_auc_4: 0.6084 - val_loss: 0.6107\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.6244 - auc_5: 0.5070 - loss: 0.6625 - val_accuracy: 0.6674 - val_auc_5: 0.5000 - val_loss: 0.6362\n",
            "Epoch 2/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6633 - auc_5: 0.5049 - loss: 0.6484 - val_accuracy: 0.6674 - val_auc_5: 0.5049 - val_loss: 0.6360\n",
            "Epoch 3/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6554 - auc_5: 0.4922 - loss: 0.6536 - val_accuracy: 0.6674 - val_auc_5: 0.5334 - val_loss: 0.6359\n",
            "Epoch 4/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6546 - auc_5: 0.4987 - loss: 0.6542 - val_accuracy: 0.6674 - val_auc_5: 0.5000 - val_loss: 0.6361\n",
            "Epoch 5/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6682 - auc_5: 0.5233 - loss: 0.6399 - val_accuracy: 0.6674 - val_auc_5: 0.5138 - val_loss: 0.6362\n",
            "Epoch 6/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6608 - auc_5: 0.4873 - loss: 0.6485 - val_accuracy: 0.6674 - val_auc_5: 0.5049 - val_loss: 0.6361\n",
            "Epoch 7/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6630 - auc_5: 0.5017 - loss: 0.6435 - val_accuracy: 0.6674 - val_auc_5: 0.5049 - val_loss: 0.6361\n",
            "Epoch 8/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6502 - auc_5: 0.4932 - loss: 0.6578 - val_accuracy: 0.6674 - val_auc_5: 0.5024 - val_loss: 0.6358\n",
            "Epoch 9/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6759 - auc_5: 0.5052 - loss: 0.6372 - val_accuracy: 0.6674 - val_auc_5: 0.5155 - val_loss: 0.6358\n",
            "Epoch 10/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6529 - auc_5: 0.5130 - loss: 0.6490 - val_accuracy: 0.6674 - val_auc_5: 0.5342 - val_loss: 0.6357\n",
            "Epoch 11/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6600 - auc_5: 0.5262 - loss: 0.6434 - val_accuracy: 0.6674 - val_auc_5: 0.5285 - val_loss: 0.6358\n",
            "Epoch 12/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6703 - auc_5: 0.4930 - loss: 0.6417 - val_accuracy: 0.6674 - val_auc_5: 0.5342 - val_loss: 0.6357\n",
            "Epoch 13/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6819 - auc_5: 0.5252 - loss: 0.6285 - val_accuracy: 0.6674 - val_auc_5: 0.5464 - val_loss: 0.6360\n",
            "Epoch 14/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6607 - auc_5: 0.4934 - loss: 0.6472 - val_accuracy: 0.6674 - val_auc_5: 0.5399 - val_loss: 0.6357\n",
            "Epoch 15/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6561 - auc_5: 0.5140 - loss: 0.6473 - val_accuracy: 0.6674 - val_auc_5: 0.5399 - val_loss: 0.6355\n",
            "Epoch 16/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6824 - auc_5: 0.4921 - loss: 0.6325 - val_accuracy: 0.6674 - val_auc_5: 0.5342 - val_loss: 0.6367\n",
            "Epoch 17/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6692 - auc_5: 0.5077 - loss: 0.6386 - val_accuracy: 0.6674 - val_auc_5: 0.5383 - val_loss: 0.6353\n",
            "Epoch 18/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6592 - auc_5: 0.5060 - loss: 0.6453 - val_accuracy: 0.6674 - val_auc_5: 0.5521 - val_loss: 0.6355\n",
            "Epoch 19/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6742 - auc_5: 0.5186 - loss: 0.6335 - val_accuracy: 0.6674 - val_auc_5: 0.5448 - val_loss: 0.6350\n",
            "Epoch 20/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6669 - auc_5: 0.5122 - loss: 0.6393 - val_accuracy: 0.6674 - val_auc_5: 0.5521 - val_loss: 0.6346\n",
            "Epoch 21/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6605 - auc_5: 0.5077 - loss: 0.6437 - val_accuracy: 0.6674 - val_auc_5: 0.5928 - val_loss: 0.6344\n",
            "Epoch 22/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6718 - auc_5: 0.5058 - loss: 0.6369 - val_accuracy: 0.6674 - val_auc_5: 0.5708 - val_loss: 0.6341\n",
            "Epoch 23/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6582 - auc_5: 0.5086 - loss: 0.6449 - val_accuracy: 0.6674 - val_auc_5: 0.5700 - val_loss: 0.6335\n",
            "Epoch 24/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6703 - auc_5: 0.5023 - loss: 0.6377 - val_accuracy: 0.6674 - val_auc_5: 0.5831 - val_loss: 0.6328\n",
            "Epoch 25/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6592 - auc_5: 0.5213 - loss: 0.6429 - val_accuracy: 0.6674 - val_auc_5: 0.5774 - val_loss: 0.6320\n",
            "Epoch 26/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6615 - auc_5: 0.5456 - loss: 0.6382 - val_accuracy: 0.6674 - val_auc_5: 0.5871 - val_loss: 0.6298\n",
            "Epoch 27/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6730 - auc_5: 0.5390 - loss: 0.6305 - val_accuracy: 0.6674 - val_auc_5: 0.6067 - val_loss: 0.6273\n",
            "Epoch 28/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6788 - auc_5: 0.5327 - loss: 0.6265 - val_accuracy: 0.6674 - val_auc_5: 0.5936 - val_loss: 0.6244\n",
            "Epoch 29/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6738 - auc_5: 0.5572 - loss: 0.6286 - val_accuracy: 0.6674 - val_auc_5: 0.6238 - val_loss: 0.6201\n",
            "Epoch 30/30\n",
            "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6675 - auc_5: 0.5397 - loss: 0.6388 - val_accuracy: 0.6956 - val_auc_5: 0.6547 - val_loss: 0.6158\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.4128 - auc_6: 0.4997 - loss: 0.8391 - val_accuracy: 0.6744 - val_auc_6: 0.5000 - val_loss: 0.6316\n",
            "Epoch 2/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6421 - auc_6: 0.5075 - loss: 0.6564 - val_accuracy: 0.6744 - val_auc_6: 0.5065 - val_loss: 0.6324\n",
            "Epoch 3/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6612 - auc_6: 0.4920 - loss: 0.6522 - val_accuracy: 0.6744 - val_auc_6: 0.5000 - val_loss: 0.6312\n",
            "Epoch 4/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6705 - auc_6: 0.5083 - loss: 0.6406 - val_accuracy: 0.6744 - val_auc_6: 0.5000 - val_loss: 0.6310\n",
            "Epoch 5/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6474 - auc_6: 0.5022 - loss: 0.6546 - val_accuracy: 0.6744 - val_auc_6: 0.5057 - val_loss: 0.6319\n",
            "Epoch 6/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6587 - auc_6: 0.4973 - loss: 0.6516 - val_accuracy: 0.6744 - val_auc_6: 0.5073 - val_loss: 0.6314\n",
            "Epoch 7/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6525 - auc_6: 0.5240 - loss: 0.6474 - val_accuracy: 0.6744 - val_auc_6: 0.5057 - val_loss: 0.6315\n",
            "Epoch 8/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6772 - auc_6: 0.5063 - loss: 0.6367 - val_accuracy: 0.6744 - val_auc_6: 0.5292 - val_loss: 0.6309\n",
            "Epoch 9/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6771 - auc_6: 0.4960 - loss: 0.6336 - val_accuracy: 0.6744 - val_auc_6: 0.5146 - val_loss: 0.6306\n",
            "Epoch 10/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6772 - auc_6: 0.4978 - loss: 0.6348 - val_accuracy: 0.6744 - val_auc_6: 0.5503 - val_loss: 0.6305\n",
            "Epoch 11/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6711 - auc_6: 0.4920 - loss: 0.6404 - val_accuracy: 0.6744 - val_auc_6: 0.5414 - val_loss: 0.6304\n",
            "Epoch 12/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6724 - auc_6: 0.5077 - loss: 0.6364 - val_accuracy: 0.6744 - val_auc_6: 0.5414 - val_loss: 0.6304\n",
            "Epoch 13/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6634 - auc_6: 0.5143 - loss: 0.6410 - val_accuracy: 0.6744 - val_auc_6: 0.5398 - val_loss: 0.6302\n",
            "Epoch 14/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6752 - auc_6: 0.5089 - loss: 0.6349 - val_accuracy: 0.6744 - val_auc_6: 0.5633 - val_loss: 0.6297\n",
            "Epoch 15/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6750 - auc_6: 0.5027 - loss: 0.6355 - val_accuracy: 0.6744 - val_auc_6: 0.5511 - val_loss: 0.6295\n",
            "Epoch 16/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6696 - auc_6: 0.5324 - loss: 0.6349 - val_accuracy: 0.6744 - val_auc_6: 0.5763 - val_loss: 0.6287\n",
            "Epoch 17/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6649 - auc_6: 0.5253 - loss: 0.6380 - val_accuracy: 0.6744 - val_auc_6: 0.5714 - val_loss: 0.6278\n",
            "Epoch 18/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6774 - auc_6: 0.5090 - loss: 0.6323 - val_accuracy: 0.6744 - val_auc_6: 0.5771 - val_loss: 0.6264\n",
            "Epoch 19/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6783 - auc_6: 0.5426 - loss: 0.6268 - val_accuracy: 0.6744 - val_auc_6: 0.5917 - val_loss: 0.6243\n",
            "Epoch 20/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6762 - auc_6: 0.5307 - loss: 0.6276 - val_accuracy: 0.6744 - val_auc_6: 0.5820 - val_loss: 0.6215\n",
            "Epoch 21/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6757 - auc_6: 0.5608 - loss: 0.6257 - val_accuracy: 0.6744 - val_auc_6: 0.5909 - val_loss: 0.6176\n",
            "Epoch 22/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6712 - auc_6: 0.5305 - loss: 0.6348 - val_accuracy: 0.6971 - val_auc_6: 0.6177 - val_loss: 0.6127\n",
            "Epoch 23/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6988 - auc_6: 0.5737 - loss: 0.6146 - val_accuracy: 0.7072 - val_auc_6: 0.6193 - val_loss: 0.6066\n",
            "Epoch 24/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_6: 0.5589 - loss: 0.6159 - val_accuracy: 0.7119 - val_auc_6: 0.6323 - val_loss: 0.6013\n",
            "Epoch 25/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7083 - auc_6: 0.5644 - loss: 0.6126 - val_accuracy: 0.7125 - val_auc_6: 0.6315 - val_loss: 0.5948\n",
            "Epoch 26/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7048 - auc_6: 0.5904 - loss: 0.6073 - val_accuracy: 0.7209 - val_auc_6: 0.6826 - val_loss: 0.5897\n",
            "Epoch 27/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7172 - auc_6: 0.5889 - loss: 0.5973 - val_accuracy: 0.7209 - val_auc_6: 0.6550 - val_loss: 0.5848\n",
            "Epoch 28/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7245 - auc_6: 0.5807 - loss: 0.5921 - val_accuracy: 0.7215 - val_auc_6: 0.6494 - val_loss: 0.5811\n",
            "Epoch 29/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7232 - auc_6: 0.5830 - loss: 0.5896 - val_accuracy: 0.7246 - val_auc_6: 0.6518 - val_loss: 0.5775\n",
            "Epoch 30/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7311 - auc_6: 0.6054 - loss: 0.5796 - val_accuracy: 0.7257 - val_auc_6: 0.6989 - val_loss: 0.5740\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.4308 - auc_7: 0.4891 - loss: 0.8066 - val_accuracy: 0.6759 - val_auc_7: 0.5000 - val_loss: 0.6304\n",
            "Epoch 2/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6652 - auc_7: 0.4956 - loss: 0.6440 - val_accuracy: 0.6759 - val_auc_7: 0.5000 - val_loss: 0.6302\n",
            "Epoch 3/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6666 - auc_7: 0.4911 - loss: 0.6460 - val_accuracy: 0.6759 - val_auc_7: 0.5000 - val_loss: 0.6301\n",
            "Epoch 4/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6768 - auc_7: 0.4802 - loss: 0.6392 - val_accuracy: 0.6759 - val_auc_7: 0.5137 - val_loss: 0.6302\n",
            "Epoch 5/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6617 - auc_7: 0.5168 - loss: 0.6408 - val_accuracy: 0.6759 - val_auc_7: 0.5040 - val_loss: 0.6300\n",
            "Epoch 6/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6704 - auc_7: 0.5181 - loss: 0.6350 - val_accuracy: 0.6759 - val_auc_7: 0.5032 - val_loss: 0.6304\n",
            "Epoch 7/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6683 - auc_7: 0.4957 - loss: 0.6443 - val_accuracy: 0.6759 - val_auc_7: 0.5541 - val_loss: 0.6298\n",
            "Epoch 8/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6759 - auc_7: 0.5120 - loss: 0.6356 - val_accuracy: 0.6759 - val_auc_7: 0.5452 - val_loss: 0.6297\n",
            "Epoch 9/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6849 - auc_7: 0.4959 - loss: 0.6314 - val_accuracy: 0.6759 - val_auc_7: 0.5153 - val_loss: 0.6295\n",
            "Epoch 10/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6724 - auc_7: 0.5022 - loss: 0.6367 - val_accuracy: 0.6759 - val_auc_7: 0.5614 - val_loss: 0.6295\n",
            "Epoch 11/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6674 - auc_7: 0.5074 - loss: 0.6410 - val_accuracy: 0.6759 - val_auc_7: 0.5501 - val_loss: 0.6294\n",
            "Epoch 12/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6844 - auc_7: 0.5256 - loss: 0.6256 - val_accuracy: 0.6759 - val_auc_7: 0.5468 - val_loss: 0.6292\n",
            "Epoch 13/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6701 - auc_7: 0.5055 - loss: 0.6383 - val_accuracy: 0.6759 - val_auc_7: 0.5703 - val_loss: 0.6290\n",
            "Epoch 14/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6635 - auc_7: 0.5216 - loss: 0.6416 - val_accuracy: 0.6759 - val_auc_7: 0.5452 - val_loss: 0.6288\n",
            "Epoch 15/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6708 - auc_7: 0.5066 - loss: 0.6366 - val_accuracy: 0.6759 - val_auc_7: 0.5808 - val_loss: 0.6282\n",
            "Epoch 16/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6663 - auc_7: 0.5283 - loss: 0.6371 - val_accuracy: 0.6759 - val_auc_7: 0.5574 - val_loss: 0.6275\n",
            "Epoch 17/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6690 - auc_7: 0.5152 - loss: 0.6369 - val_accuracy: 0.6759 - val_auc_7: 0.5808 - val_loss: 0.6267\n",
            "Epoch 18/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6717 - auc_7: 0.5045 - loss: 0.6373 - val_accuracy: 0.6759 - val_auc_7: 0.5905 - val_loss: 0.6259\n",
            "Epoch 19/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6655 - auc_7: 0.5191 - loss: 0.6390 - val_accuracy: 0.6759 - val_auc_7: 0.5808 - val_loss: 0.6244\n",
            "Epoch 20/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6850 - auc_7: 0.5540 - loss: 0.6177 - val_accuracy: 0.6759 - val_auc_7: 0.5848 - val_loss: 0.6218\n",
            "Epoch 21/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6737 - auc_7: 0.5365 - loss: 0.6299 - val_accuracy: 0.6759 - val_auc_7: 0.5848 - val_loss: 0.6190\n",
            "Epoch 22/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6752 - auc_7: 0.5699 - loss: 0.6230 - val_accuracy: 0.6895 - val_auc_7: 0.5985 - val_loss: 0.6144\n",
            "Epoch 23/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7027 - auc_7: 0.5729 - loss: 0.6067 - val_accuracy: 0.7026 - val_auc_7: 0.6341 - val_loss: 0.6103\n",
            "Epoch 24/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6967 - auc_7: 0.5999 - loss: 0.6133 - val_accuracy: 0.7068 - val_auc_7: 0.6309 - val_loss: 0.6043\n",
            "Epoch 25/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7014 - auc_7: 0.5855 - loss: 0.6141 - val_accuracy: 0.7079 - val_auc_7: 0.6333 - val_loss: 0.5993\n",
            "Epoch 26/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7125 - auc_7: 0.5711 - loss: 0.6071 - val_accuracy: 0.7131 - val_auc_7: 0.6551 - val_loss: 0.5933\n",
            "Epoch 27/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7175 - auc_7: 0.5810 - loss: 0.6030 - val_accuracy: 0.7115 - val_auc_7: 0.6349 - val_loss: 0.5925\n",
            "Epoch 28/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7138 - auc_7: 0.6008 - loss: 0.5978 - val_accuracy: 0.7209 - val_auc_7: 0.6357 - val_loss: 0.5849\n",
            "Epoch 29/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7316 - auc_7: 0.5990 - loss: 0.5809 - val_accuracy: 0.7236 - val_auc_7: 0.7364 - val_loss: 0.5808\n",
            "Epoch 30/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7141 - auc_7: 0.5661 - loss: 0.5980 - val_accuracy: 0.7236 - val_auc_7: 0.6914 - val_loss: 0.5794\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.4692 - auc_8: 0.5173 - loss: 0.7592 - val_accuracy: 0.6814 - val_auc_8: 0.5000 - val_loss: 0.6259\n",
            "Epoch 2/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6810 - auc_8: 0.4937 - loss: 0.6375 - val_accuracy: 0.6814 - val_auc_8: 0.5000 - val_loss: 0.6257\n",
            "Epoch 3/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6654 - auc_8: 0.5145 - loss: 0.6438 - val_accuracy: 0.6814 - val_auc_8: 0.5000 - val_loss: 0.6263\n",
            "Epoch 4/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6708 - auc_8: 0.4911 - loss: 0.6454 - val_accuracy: 0.6814 - val_auc_8: 0.5083 - val_loss: 0.6266\n",
            "Epoch 5/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6707 - auc_8: 0.5016 - loss: 0.6433 - val_accuracy: 0.6814 - val_auc_8: 0.5074 - val_loss: 0.6259\n",
            "Epoch 6/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6813 - auc_8: 0.5185 - loss: 0.6306 - val_accuracy: 0.6814 - val_auc_8: 0.5083 - val_loss: 0.6255\n",
            "Epoch 7/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6943 - auc_8: 0.4842 - loss: 0.6284 - val_accuracy: 0.6814 - val_auc_8: 0.5380 - val_loss: 0.6256\n",
            "Epoch 8/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6817 - auc_8: 0.4899 - loss: 0.6362 - val_accuracy: 0.6814 - val_auc_8: 0.5132 - val_loss: 0.6255\n",
            "Epoch 9/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6773 - auc_8: 0.5145 - loss: 0.6314 - val_accuracy: 0.6814 - val_auc_8: 0.5206 - val_loss: 0.6253\n",
            "Epoch 10/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6658 - auc_8: 0.4887 - loss: 0.6443 - val_accuracy: 0.6814 - val_auc_8: 0.5206 - val_loss: 0.6255\n",
            "Epoch 11/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6830 - auc_8: 0.5068 - loss: 0.6288 - val_accuracy: 0.6814 - val_auc_8: 0.5388 - val_loss: 0.6251\n",
            "Epoch 12/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6721 - auc_8: 0.5052 - loss: 0.6371 - val_accuracy: 0.6814 - val_auc_8: 0.5429 - val_loss: 0.6254\n",
            "Epoch 13/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6729 - auc_8: 0.4874 - loss: 0.6398 - val_accuracy: 0.6814 - val_auc_8: 0.5594 - val_loss: 0.6248\n",
            "Epoch 14/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6703 - auc_8: 0.5145 - loss: 0.6379 - val_accuracy: 0.6814 - val_auc_8: 0.5545 - val_loss: 0.6247\n",
            "Epoch 15/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6844 - auc_8: 0.5105 - loss: 0.6271 - val_accuracy: 0.6814 - val_auc_8: 0.5619 - val_loss: 0.6242\n",
            "Epoch 16/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6789 - auc_8: 0.5064 - loss: 0.6311 - val_accuracy: 0.6814 - val_auc_8: 0.5809 - val_loss: 0.6236\n",
            "Epoch 17/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6711 - auc_8: 0.5322 - loss: 0.6332 - val_accuracy: 0.6814 - val_auc_8: 0.5965 - val_loss: 0.6234\n",
            "Epoch 18/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6884 - auc_8: 0.5077 - loss: 0.6239 - val_accuracy: 0.6814 - val_auc_8: 0.5883 - val_loss: 0.6218\n",
            "Epoch 19/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6832 - auc_8: 0.5266 - loss: 0.6248 - val_accuracy: 0.6814 - val_auc_8: 0.5833 - val_loss: 0.6202\n",
            "Epoch 20/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6764 - auc_8: 0.5362 - loss: 0.6274 - val_accuracy: 0.6814 - val_auc_8: 0.5858 - val_loss: 0.6179\n",
            "Epoch 21/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6816 - auc_8: 0.5501 - loss: 0.6218 - val_accuracy: 0.6814 - val_auc_8: 0.6254 - val_loss: 0.6135\n",
            "Epoch 22/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6808 - auc_8: 0.5492 - loss: 0.6236 - val_accuracy: 0.6924 - val_auc_8: 0.6543 - val_loss: 0.6086\n",
            "Epoch 23/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6928 - auc_8: 0.5690 - loss: 0.6154 - val_accuracy: 0.7087 - val_auc_8: 0.6617 - val_loss: 0.6022\n",
            "Epoch 24/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7103 - auc_8: 0.5713 - loss: 0.6065 - val_accuracy: 0.7171 - val_auc_8: 0.6518 - val_loss: 0.5953\n",
            "Epoch 25/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7141 - auc_8: 0.5708 - loss: 0.6025 - val_accuracy: 0.7198 - val_auc_8: 0.6444 - val_loss: 0.5889\n",
            "Epoch 26/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7229 - auc_8: 0.5941 - loss: 0.5914 - val_accuracy: 0.7219 - val_auc_8: 0.7162 - val_loss: 0.5828\n",
            "Epoch 27/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7274 - auc_8: 0.6062 - loss: 0.5847 - val_accuracy: 0.7277 - val_auc_8: 0.6584 - val_loss: 0.5772\n",
            "Epoch 28/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7219 - auc_8: 0.5718 - loss: 0.5954 - val_accuracy: 0.7277 - val_auc_8: 0.6733 - val_loss: 0.5746\n",
            "Epoch 29/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7331 - auc_8: 0.6045 - loss: 0.5777 - val_accuracy: 0.7287 - val_auc_8: 0.7038 - val_loss: 0.5708\n",
            "Epoch 30/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7240 - auc_8: 0.5915 - loss: 0.5884 - val_accuracy: 0.7277 - val_auc_8: 0.6906 - val_loss: 0.5749\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6169 - auc_9: 0.4964 - loss: 0.6602 - val_accuracy: 0.6887 - val_auc_9: 0.5000 - val_loss: 0.6202\n",
            "Epoch 2/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6830 - auc_9: 0.4987 - loss: 0.6343 - val_accuracy: 0.6887 - val_auc_9: 0.5000 - val_loss: 0.6201\n",
            "Epoch 3/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6809 - auc_9: 0.5303 - loss: 0.6274 - val_accuracy: 0.6887 - val_auc_9: 0.5000 - val_loss: 0.6210\n",
            "Epoch 4/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6967 - auc_9: 0.5244 - loss: 0.6180 - val_accuracy: 0.6887 - val_auc_9: 0.5221 - val_loss: 0.6201\n",
            "Epoch 5/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6870 - auc_9: 0.5052 - loss: 0.6278 - val_accuracy: 0.6887 - val_auc_9: 0.5000 - val_loss: 0.6202\n",
            "Epoch 6/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6965 - auc_9: 0.4794 - loss: 0.6261 - val_accuracy: 0.6887 - val_auc_9: 0.5255 - val_loss: 0.6201\n",
            "Epoch 7/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6815 - auc_9: 0.4939 - loss: 0.6327 - val_accuracy: 0.6887 - val_auc_9: 0.5433 - val_loss: 0.6203\n",
            "Epoch 8/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6888 - auc_9: 0.5004 - loss: 0.6261 - val_accuracy: 0.6887 - val_auc_9: 0.5000 - val_loss: 0.6201\n",
            "Epoch 9/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6911 - auc_9: 0.4912 - loss: 0.6244 - val_accuracy: 0.6887 - val_auc_9: 0.5000 - val_loss: 0.6201\n",
            "Epoch 10/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6957 - auc_9: 0.5112 - loss: 0.6186 - val_accuracy: 0.6887 - val_auc_9: 0.5543 - val_loss: 0.6202\n",
            "Epoch 11/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6790 - auc_9: 0.5098 - loss: 0.6308 - val_accuracy: 0.6887 - val_auc_9: 0.5441 - val_loss: 0.6200\n",
            "Epoch 12/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6710 - auc_9: 0.4768 - loss: 0.6422 - val_accuracy: 0.6887 - val_auc_9: 0.5102 - val_loss: 0.6202\n",
            "Epoch 13/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6852 - auc_9: 0.4919 - loss: 0.6297 - val_accuracy: 0.6887 - val_auc_9: 0.5458 - val_loss: 0.6199\n",
            "Epoch 14/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6867 - auc_9: 0.5111 - loss: 0.6244 - val_accuracy: 0.6887 - val_auc_9: 0.5238 - val_loss: 0.6198\n",
            "Epoch 15/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6817 - auc_9: 0.5111 - loss: 0.6278 - val_accuracy: 0.6887 - val_auc_9: 0.5543 - val_loss: 0.6198\n",
            "Epoch 16/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7022 - auc_9: 0.5046 - loss: 0.6134 - val_accuracy: 0.6887 - val_auc_9: 0.5662 - val_loss: 0.6197\n",
            "Epoch 17/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6987 - auc_9: 0.4872 - loss: 0.6177 - val_accuracy: 0.6887 - val_auc_9: 0.5654 - val_loss: 0.6198\n",
            "Epoch 18/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6896 - auc_9: 0.4899 - loss: 0.6235 - val_accuracy: 0.6887 - val_auc_9: 0.5730 - val_loss: 0.6195\n",
            "Epoch 19/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6861 - auc_9: 0.4880 - loss: 0.6268 - val_accuracy: 0.6887 - val_auc_9: 0.5552 - val_loss: 0.6193\n",
            "Epoch 20/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7022 - auc_9: 0.5090 - loss: 0.6109 - val_accuracy: 0.6887 - val_auc_9: 0.5696 - val_loss: 0.6193\n",
            "Epoch 21/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6851 - auc_9: 0.5291 - loss: 0.6221 - val_accuracy: 0.6887 - val_auc_9: 0.5688 - val_loss: 0.6188\n",
            "Epoch 22/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6968 - auc_9: 0.5361 - loss: 0.6129 - val_accuracy: 0.6887 - val_auc_9: 0.5739 - val_loss: 0.6182\n",
            "Epoch 23/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6815 - auc_9: 0.5199 - loss: 0.6255 - val_accuracy: 0.6887 - val_auc_9: 0.5849 - val_loss: 0.6176\n",
            "Epoch 24/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6892 - auc_9: 0.5509 - loss: 0.6167 - val_accuracy: 0.6887 - val_auc_9: 0.5883 - val_loss: 0.6165\n",
            "Epoch 25/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6824 - auc_9: 0.5122 - loss: 0.6275 - val_accuracy: 0.6887 - val_auc_9: 0.5891 - val_loss: 0.6153\n",
            "Epoch 26/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6731 - auc_9: 0.5112 - loss: 0.6341 - val_accuracy: 0.6887 - val_auc_9: 0.6316 - val_loss: 0.6133\n",
            "Epoch 27/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6934 - auc_9: 0.5450 - loss: 0.6130 - val_accuracy: 0.6887 - val_auc_9: 0.6019 - val_loss: 0.6098\n",
            "Epoch 28/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6842 - auc_9: 0.5462 - loss: 0.6198 - val_accuracy: 0.6887 - val_auc_9: 0.6163 - val_loss: 0.6056\n",
            "Epoch 29/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6871 - auc_9: 0.5725 - loss: 0.6123 - val_accuracy: 0.6887 - val_auc_9: 0.6808 - val_loss: 0.6001\n",
            "Epoch 30/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7020 - auc_9: 0.5362 - loss: 0.6062 - val_accuracy: 0.7246 - val_auc_9: 0.6647 - val_loss: 0.5936\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6808 - auc_10: 0.4917 - loss: 0.6545 - val_accuracy: 0.6878 - val_auc_10: 0.5000 - val_loss: 0.6210\n",
            "Epoch 2/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6795 - auc_10: 0.4858 - loss: 0.6396 - val_accuracy: 0.6878 - val_auc_10: 0.5000 - val_loss: 0.6209\n",
            "Epoch 3/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6824 - auc_10: 0.5043 - loss: 0.6324 - val_accuracy: 0.6878 - val_auc_10: 0.5000 - val_loss: 0.6210\n",
            "Epoch 4/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6884 - auc_10: 0.5197 - loss: 0.6246 - val_accuracy: 0.6878 - val_auc_10: 0.5000 - val_loss: 0.6209\n",
            "Epoch 5/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6933 - auc_10: 0.5182 - loss: 0.6203 - val_accuracy: 0.6878 - val_auc_10: 0.5000 - val_loss: 0.6208\n",
            "Epoch 6/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6897 - auc_10: 0.4763 - loss: 0.6327 - val_accuracy: 0.6878 - val_auc_10: 0.5150 - val_loss: 0.6208\n",
            "Epoch 7/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6965 - auc_10: 0.5013 - loss: 0.6216 - val_accuracy: 0.6878 - val_auc_10: 0.5424 - val_loss: 0.6209\n",
            "Epoch 8/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6934 - auc_10: 0.5140 - loss: 0.6208 - val_accuracy: 0.6878 - val_auc_10: 0.5058 - val_loss: 0.6210\n",
            "Epoch 9/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7063 - auc_10: 0.4925 - loss: 0.6149 - val_accuracy: 0.6878 - val_auc_10: 0.5449 - val_loss: 0.6214\n",
            "Epoch 10/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6783 - auc_10: 0.5154 - loss: 0.6311 - val_accuracy: 0.6878 - val_auc_10: 0.5058 - val_loss: 0.6206\n",
            "Epoch 11/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6753 - auc_10: 0.4964 - loss: 0.6367 - val_accuracy: 0.6878 - val_auc_10: 0.5058 - val_loss: 0.6206\n",
            "Epoch 12/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6880 - auc_10: 0.5048 - loss: 0.6258 - val_accuracy: 0.6878 - val_auc_10: 0.5166 - val_loss: 0.6205\n",
            "Epoch 13/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6899 - auc_10: 0.4709 - loss: 0.6295 - val_accuracy: 0.6878 - val_auc_10: 0.5183 - val_loss: 0.6204\n",
            "Epoch 14/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6858 - auc_10: 0.5042 - loss: 0.6270 - val_accuracy: 0.6878 - val_auc_10: 0.5922 - val_loss: 0.6205\n",
            "Epoch 15/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6909 - auc_10: 0.4855 - loss: 0.6247 - val_accuracy: 0.6878 - val_auc_10: 0.5797 - val_loss: 0.6202\n",
            "Epoch 16/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6783 - auc_10: 0.4904 - loss: 0.6342 - val_accuracy: 0.6878 - val_auc_10: 0.5424 - val_loss: 0.6201\n",
            "Epoch 17/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6877 - auc_10: 0.4925 - loss: 0.6265 - val_accuracy: 0.6878 - val_auc_10: 0.5449 - val_loss: 0.6198\n",
            "Epoch 18/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6946 - auc_10: 0.5000 - loss: 0.6191 - val_accuracy: 0.6878 - val_auc_10: 0.5540 - val_loss: 0.6195\n",
            "Epoch 19/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6867 - auc_10: 0.4738 - loss: 0.6292 - val_accuracy: 0.6878 - val_auc_10: 0.5963 - val_loss: 0.6191\n",
            "Epoch 20/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6984 - auc_10: 0.5170 - loss: 0.6139 - val_accuracy: 0.6878 - val_auc_10: 0.5689 - val_loss: 0.6184\n",
            "Epoch 21/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6889 - auc_10: 0.5433 - loss: 0.6178 - val_accuracy: 0.6878 - val_auc_10: 0.5739 - val_loss: 0.6177\n",
            "Epoch 22/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6843 - auc_10: 0.5302 - loss: 0.6231 - val_accuracy: 0.6878 - val_auc_10: 0.5822 - val_loss: 0.6161\n",
            "Epoch 23/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6984 - auc_10: 0.5061 - loss: 0.6146 - val_accuracy: 0.6878 - val_auc_10: 0.6013 - val_loss: 0.6143\n",
            "Epoch 24/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6766 - auc_10: 0.5245 - loss: 0.6286 - val_accuracy: 0.6878 - val_auc_10: 0.6213 - val_loss: 0.6119\n",
            "Epoch 25/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6788 - auc_10: 0.5571 - loss: 0.6227 - val_accuracy: 0.6878 - val_auc_10: 0.6038 - val_loss: 0.6077\n",
            "Epoch 26/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6995 - auc_10: 0.5635 - loss: 0.6054 - val_accuracy: 0.6878 - val_auc_10: 0.6337 - val_loss: 0.6026\n",
            "Epoch 27/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7124 - auc_10: 0.5911 - loss: 0.5946 - val_accuracy: 0.7204 - val_auc_10: 0.6321 - val_loss: 0.5958\n",
            "Epoch 28/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7225 - auc_10: 0.5911 - loss: 0.5902 - val_accuracy: 0.7272 - val_auc_10: 0.6836 - val_loss: 0.5905\n",
            "Epoch 29/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7384 - auc_10: 0.6088 - loss: 0.5775 - val_accuracy: 0.7287 - val_auc_10: 0.6827 - val_loss: 0.5836\n",
            "Epoch 30/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7145 - auc_10: 0.6078 - loss: 0.5996 - val_accuracy: 0.7293 - val_auc_10: 0.7110 - val_loss: 0.5790\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6954 - auc_11: 0.4908 - loss: 0.6302 - val_accuracy: 0.6992 - val_auc_11: 0.5000 - val_loss: 0.6117\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7035 - auc_11: 0.5003 - loss: 0.6180 - val_accuracy: 0.6992 - val_auc_11: 0.5000 - val_loss: 0.6115\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7134 - auc_11: 0.5275 - loss: 0.6022 - val_accuracy: 0.6992 - val_auc_11: 0.5000 - val_loss: 0.6121\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6986 - auc_11: 0.4894 - loss: 0.6222 - val_accuracy: 0.6992 - val_auc_11: 0.5000 - val_loss: 0.6114\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6907 - auc_11: 0.5037 - loss: 0.6261 - val_accuracy: 0.6992 - val_auc_11: 0.5060 - val_loss: 0.6117\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7054 - auc_11: 0.4987 - loss: 0.6124 - val_accuracy: 0.6992 - val_auc_11: 0.5060 - val_loss: 0.6114\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7013 - auc_11: 0.5047 - loss: 0.6142 - val_accuracy: 0.6992 - val_auc_11: 0.5060 - val_loss: 0.6114\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - auc_11: 0.4979 - loss: 0.6093 - val_accuracy: 0.6992 - val_auc_11: 0.5060 - val_loss: 0.6114\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7016 - auc_11: 0.4802 - loss: 0.6179 - val_accuracy: 0.6992 - val_auc_11: 0.5060 - val_loss: 0.6114\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7076 - auc_11: 0.5026 - loss: 0.6086 - val_accuracy: 0.6992 - val_auc_11: 0.5402 - val_loss: 0.6113\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6981 - auc_11: 0.4980 - loss: 0.6170 - val_accuracy: 0.6992 - val_auc_11: 0.5530 - val_loss: 0.6112\n",
            "Epoch 12/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6947 - auc_11: 0.5215 - loss: 0.6169 - val_accuracy: 0.6992 - val_auc_11: 0.5197 - val_loss: 0.6111\n",
            "Epoch 13/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7049 - auc_11: 0.5020 - loss: 0.6108 - val_accuracy: 0.6992 - val_auc_11: 0.5162 - val_loss: 0.6113\n",
            "Epoch 14/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6925 - auc_11: 0.4939 - loss: 0.6223 - val_accuracy: 0.6992 - val_auc_11: 0.5513 - val_loss: 0.6109\n",
            "Epoch 15/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7046 - auc_11: 0.5033 - loss: 0.6108 - val_accuracy: 0.6992 - val_auc_11: 0.5504 - val_loss: 0.6111\n",
            "Epoch 16/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6949 - auc_11: 0.5186 - loss: 0.6154 - val_accuracy: 0.6992 - val_auc_11: 0.5530 - val_loss: 0.6108\n",
            "Epoch 17/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6995 - auc_11: 0.5029 - loss: 0.6148 - val_accuracy: 0.6992 - val_auc_11: 0.5624 - val_loss: 0.6105\n",
            "Epoch 18/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6960 - auc_11: 0.5166 - loss: 0.6159 - val_accuracy: 0.6992 - val_auc_11: 0.5718 - val_loss: 0.6100\n",
            "Epoch 19/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6874 - auc_11: 0.4961 - loss: 0.6252 - val_accuracy: 0.6992 - val_auc_11: 0.5761 - val_loss: 0.6096\n",
            "Epoch 20/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6959 - auc_11: 0.5198 - loss: 0.6152 - val_accuracy: 0.6992 - val_auc_11: 0.5906 - val_loss: 0.6089\n",
            "Epoch 21/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6991 - auc_11: 0.5517 - loss: 0.6085 - val_accuracy: 0.6992 - val_auc_11: 0.6675 - val_loss: 0.6081\n",
            "Epoch 22/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6978 - auc_11: 0.5280 - loss: 0.6123 - val_accuracy: 0.6992 - val_auc_11: 0.5915 - val_loss: 0.6069\n",
            "Epoch 23/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7028 - auc_11: 0.5596 - loss: 0.6038 - val_accuracy: 0.6992 - val_auc_11: 0.5966 - val_loss: 0.6046\n",
            "Epoch 24/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6890 - auc_11: 0.5395 - loss: 0.6179 - val_accuracy: 0.6992 - val_auc_11: 0.6009 - val_loss: 0.6022\n",
            "Epoch 25/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6969 - auc_11: 0.5460 - loss: 0.6100 - val_accuracy: 0.6992 - val_auc_11: 0.6188 - val_loss: 0.5989\n",
            "Epoch 26/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7091 - auc_11: 0.5764 - loss: 0.5938 - val_accuracy: 0.6992 - val_auc_11: 0.6667 - val_loss: 0.5940\n",
            "Epoch 27/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7119 - auc_11: 0.5668 - loss: 0.5925 - val_accuracy: 0.6992 - val_auc_11: 0.7834 - val_loss: 0.5884\n",
            "Epoch 28/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7066 - auc_11: 0.5910 - loss: 0.5973 - val_accuracy: 0.7311 - val_auc_11: 0.6726 - val_loss: 0.5819\n",
            "Epoch 29/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7220 - auc_11: 0.5943 - loss: 0.5904 - val_accuracy: 0.7383 - val_auc_11: 0.7709 - val_loss: 0.5751\n",
            "Epoch 30/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7163 - auc_11: 0.5964 - loss: 0.5993 - val_accuracy: 0.7429 - val_auc_11: 0.6769 - val_loss: 0.5692\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6283 - auc_12: 0.5198 - loss: 0.6551 - val_accuracy: 0.6950 - val_auc_12: 0.5230 - val_loss: 0.6150\n",
            "Epoch 2/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6947 - auc_12: 0.4847 - loss: 0.6293 - val_accuracy: 0.6950 - val_auc_12: 0.5000 - val_loss: 0.6150\n",
            "Epoch 3/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6863 - auc_12: 0.4958 - loss: 0.6341 - val_accuracy: 0.6950 - val_auc_12: 0.5062 - val_loss: 0.6152\n",
            "Epoch 4/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6799 - auc_12: 0.5020 - loss: 0.6353 - val_accuracy: 0.6950 - val_auc_12: 0.5186 - val_loss: 0.6149\n",
            "Epoch 5/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7006 - auc_12: 0.5128 - loss: 0.6172 - val_accuracy: 0.6950 - val_auc_12: 0.5000 - val_loss: 0.6148\n",
            "Epoch 6/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6900 - auc_12: 0.4891 - loss: 0.6290 - val_accuracy: 0.6950 - val_auc_12: 0.5000 - val_loss: 0.6150\n",
            "Epoch 7/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6802 - auc_12: 0.5021 - loss: 0.6338 - val_accuracy: 0.6950 - val_auc_12: 0.5062 - val_loss: 0.6151\n",
            "Epoch 8/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6901 - auc_12: 0.4948 - loss: 0.6299 - val_accuracy: 0.6950 - val_auc_12: 0.5141 - val_loss: 0.6148\n",
            "Epoch 9/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6904 - auc_12: 0.4834 - loss: 0.6307 - val_accuracy: 0.6950 - val_auc_12: 0.5088 - val_loss: 0.6150\n",
            "Epoch 10/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_12: 0.5222 - loss: 0.6110 - val_accuracy: 0.6950 - val_auc_12: 0.5247 - val_loss: 0.6147\n",
            "Epoch 11/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7009 - auc_12: 0.4884 - loss: 0.6188 - val_accuracy: 0.6950 - val_auc_12: 0.6042 - val_loss: 0.6148\n",
            "Epoch 12/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7028 - auc_12: 0.4649 - loss: 0.6204 - val_accuracy: 0.6950 - val_auc_12: 0.5512 - val_loss: 0.6143\n",
            "Epoch 13/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6890 - auc_12: 0.4996 - loss: 0.6259 - val_accuracy: 0.6950 - val_auc_12: 0.5724 - val_loss: 0.6142\n",
            "Epoch 14/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6883 - auc_12: 0.4904 - loss: 0.6279 - val_accuracy: 0.6950 - val_auc_12: 0.5919 - val_loss: 0.6140\n",
            "Epoch 15/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6963 - auc_12: 0.5207 - loss: 0.6167 - val_accuracy: 0.6950 - val_auc_12: 0.5724 - val_loss: 0.6137\n",
            "Epoch 16/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6912 - auc_12: 0.5159 - loss: 0.6206 - val_accuracy: 0.6950 - val_auc_12: 0.5663 - val_loss: 0.6133\n",
            "Epoch 17/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_12: 0.5080 - loss: 0.6155 - val_accuracy: 0.6950 - val_auc_12: 0.6025 - val_loss: 0.6128\n",
            "Epoch 18/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_12: 0.5271 - loss: 0.6117 - val_accuracy: 0.6950 - val_auc_12: 0.5822 - val_loss: 0.6122\n",
            "Epoch 19/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6976 - auc_12: 0.5196 - loss: 0.6140 - val_accuracy: 0.6950 - val_auc_12: 0.5866 - val_loss: 0.6114\n",
            "Epoch 20/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7081 - auc_12: 0.5118 - loss: 0.6062 - val_accuracy: 0.6950 - val_auc_12: 0.6016 - val_loss: 0.6097\n",
            "Epoch 21/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6985 - auc_12: 0.5381 - loss: 0.6107 - val_accuracy: 0.6950 - val_auc_12: 0.6016 - val_loss: 0.6076\n",
            "Epoch 22/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6972 - auc_12: 0.5530 - loss: 0.6089 - val_accuracy: 0.6950 - val_auc_12: 0.6254 - val_loss: 0.6043\n",
            "Epoch 23/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7030 - auc_12: 0.5301 - loss: 0.6070 - val_accuracy: 0.6950 - val_auc_12: 0.6634 - val_loss: 0.6002\n",
            "Epoch 24/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6967 - auc_12: 0.5577 - loss: 0.6091 - val_accuracy: 0.6950 - val_auc_12: 0.6431 - val_loss: 0.5945\n",
            "Epoch 25/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7193 - auc_12: 0.5699 - loss: 0.5917 - val_accuracy: 0.7284 - val_auc_12: 0.6458 - val_loss: 0.5881\n",
            "Epoch 26/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7180 - auc_12: 0.5826 - loss: 0.5969 - val_accuracy: 0.7349 - val_auc_12: 0.6678 - val_loss: 0.5803\n",
            "Epoch 27/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7256 - auc_12: 0.6248 - loss: 0.5854 - val_accuracy: 0.7376 - val_auc_12: 0.6564 - val_loss: 0.5731\n",
            "Epoch 28/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7398 - auc_12: 0.5723 - loss: 0.5838 - val_accuracy: 0.7392 - val_auc_12: 0.6979 - val_loss: 0.5668\n",
            "Epoch 29/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7413 - auc_12: 0.6138 - loss: 0.5744 - val_accuracy: 0.7441 - val_auc_12: 0.7597 - val_loss: 0.5590\n",
            "Epoch 30/30\n",
            "\u001b[1m433/433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7497 - auc_12: 0.6298 - loss: 0.5629 - val_accuracy: 0.7457 - val_auc_12: 0.7420 - val_loss: 0.5540\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6583 - auc_13: 0.5054 - loss: 0.6380 - val_accuracy: 0.6956 - val_auc_13: 0.5000 - val_loss: 0.6146\n",
            "Epoch 2/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6854 - auc_13: 0.4917 - loss: 0.6346 - val_accuracy: 0.6956 - val_auc_13: 0.5043 - val_loss: 0.6147\n",
            "Epoch 3/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6969 - auc_13: 0.5070 - loss: 0.6209 - val_accuracy: 0.6956 - val_auc_13: 0.5000 - val_loss: 0.6145\n",
            "Epoch 4/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7015 - auc_13: 0.4898 - loss: 0.6195 - val_accuracy: 0.6956 - val_auc_13: 0.5000 - val_loss: 0.6145\n",
            "Epoch 5/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6835 - auc_13: 0.4757 - loss: 0.6363 - val_accuracy: 0.6956 - val_auc_13: 0.5000 - val_loss: 0.6147\n",
            "Epoch 6/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6964 - auc_13: 0.5069 - loss: 0.6184 - val_accuracy: 0.6956 - val_auc_13: 0.5043 - val_loss: 0.6145\n",
            "Epoch 7/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6864 - auc_13: 0.4982 - loss: 0.6292 - val_accuracy: 0.6956 - val_auc_13: 0.5000 - val_loss: 0.6144\n",
            "Epoch 8/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6927 - auc_13: 0.4888 - loss: 0.6257 - val_accuracy: 0.6956 - val_auc_13: 0.5214 - val_loss: 0.6144\n",
            "Epoch 9/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6905 - auc_13: 0.4907 - loss: 0.6264 - val_accuracy: 0.6956 - val_auc_13: 0.5214 - val_loss: 0.6144\n",
            "Epoch 10/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6902 - auc_13: 0.4864 - loss: 0.6265 - val_accuracy: 0.6956 - val_auc_13: 0.5497 - val_loss: 0.6143\n",
            "Epoch 11/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7080 - auc_13: 0.4917 - loss: 0.6116 - val_accuracy: 0.6956 - val_auc_13: 0.5043 - val_loss: 0.6146\n",
            "Epoch 12/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6947 - auc_13: 0.5010 - loss: 0.6195 - val_accuracy: 0.6956 - val_auc_13: 0.5172 - val_loss: 0.6142\n",
            "Epoch 13/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7018 - auc_13: 0.4761 - loss: 0.6174 - val_accuracy: 0.6956 - val_auc_13: 0.5489 - val_loss: 0.6140\n",
            "Epoch 14/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6929 - auc_13: 0.5048 - loss: 0.6208 - val_accuracy: 0.6956 - val_auc_13: 0.5789 - val_loss: 0.6139\n",
            "Epoch 15/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6883 - auc_13: 0.4981 - loss: 0.6247 - val_accuracy: 0.6956 - val_auc_13: 0.5515 - val_loss: 0.6137\n",
            "Epoch 16/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6981 - auc_13: 0.5195 - loss: 0.6149 - val_accuracy: 0.6956 - val_auc_13: 0.5995 - val_loss: 0.6135\n",
            "Epoch 17/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6888 - auc_13: 0.4971 - loss: 0.6242 - val_accuracy: 0.6956 - val_auc_13: 0.5635 - val_loss: 0.6132\n",
            "Epoch 18/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7049 - auc_13: 0.5247 - loss: 0.6068 - val_accuracy: 0.6956 - val_auc_13: 0.5823 - val_loss: 0.6128\n",
            "Epoch 19/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6993 - auc_13: 0.5114 - loss: 0.6136 - val_accuracy: 0.6956 - val_auc_13: 0.5995 - val_loss: 0.6122\n",
            "Epoch 20/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6978 - auc_13: 0.4854 - loss: 0.6180 - val_accuracy: 0.6956 - val_auc_13: 0.5918 - val_loss: 0.6113\n",
            "Epoch 21/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7005 - auc_13: 0.5269 - loss: 0.6105 - val_accuracy: 0.6956 - val_auc_13: 0.5918 - val_loss: 0.6097\n",
            "Epoch 22/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6962 - auc_13: 0.5267 - loss: 0.6146 - val_accuracy: 0.6956 - val_auc_13: 0.6209 - val_loss: 0.6079\n",
            "Epoch 23/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6821 - auc_13: 0.5396 - loss: 0.6235 - val_accuracy: 0.6956 - val_auc_13: 0.6484 - val_loss: 0.6051\n",
            "Epoch 24/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6988 - auc_13: 0.5573 - loss: 0.6061 - val_accuracy: 0.6956 - val_auc_13: 0.6372 - val_loss: 0.6005\n",
            "Epoch 25/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7097 - auc_13: 0.5589 - loss: 0.5967 - val_accuracy: 0.6956 - val_auc_13: 0.6750 - val_loss: 0.5942\n",
            "Epoch 26/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6996 - auc_13: 0.5728 - loss: 0.6050 - val_accuracy: 0.7258 - val_auc_13: 0.6424 - val_loss: 0.5869\n",
            "Epoch 27/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7194 - auc_13: 0.5890 - loss: 0.5934 - val_accuracy: 0.7347 - val_auc_13: 0.6707 - val_loss: 0.5792\n",
            "Epoch 28/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7281 - auc_13: 0.5896 - loss: 0.5893 - val_accuracy: 0.7373 - val_auc_13: 0.6750 - val_loss: 0.5728\n",
            "Epoch 29/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7333 - auc_13: 0.5956 - loss: 0.5844 - val_accuracy: 0.7452 - val_auc_13: 0.7256 - val_loss: 0.5639\n",
            "Epoch 30/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7361 - auc_13: 0.6050 - loss: 0.5802 - val_accuracy: 0.7478 - val_auc_13: 0.7632 - val_loss: 0.5577\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.6955 - auc_14: 0.4989 - loss: 0.6654 - val_accuracy: 0.6962 - val_auc_14: 0.5000 - val_loss: 0.6140\n",
            "Epoch 2/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6971 - auc_14: 0.5081 - loss: 0.6204 - val_accuracy: 0.6962 - val_auc_14: 0.5523 - val_loss: 0.6141\n",
            "Epoch 3/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6912 - auc_14: 0.4961 - loss: 0.6267 - val_accuracy: 0.6962 - val_auc_14: 0.5000 - val_loss: 0.6140\n",
            "Epoch 4/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6994 - auc_14: 0.4831 - loss: 0.6216 - val_accuracy: 0.6962 - val_auc_14: 0.5000 - val_loss: 0.6139\n",
            "Epoch 5/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7030 - auc_14: 0.5183 - loss: 0.6132 - val_accuracy: 0.6962 - val_auc_14: 0.5077 - val_loss: 0.6140\n",
            "Epoch 6/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6920 - auc_14: 0.5182 - loss: 0.6201 - val_accuracy: 0.6962 - val_auc_14: 0.5077 - val_loss: 0.6140\n",
            "Epoch 7/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6956 - auc_14: 0.4991 - loss: 0.6200 - val_accuracy: 0.6962 - val_auc_14: 0.5266 - val_loss: 0.6139\n",
            "Epoch 8/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6747 - auc_14: 0.4887 - loss: 0.6382 - val_accuracy: 0.6962 - val_auc_14: 0.5000 - val_loss: 0.6144\n",
            "Epoch 9/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6904 - auc_14: 0.5166 - loss: 0.6213 - val_accuracy: 0.6962 - val_auc_14: 0.5077 - val_loss: 0.6139\n",
            "Epoch 10/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6848 - auc_14: 0.5058 - loss: 0.6262 - val_accuracy: 0.6962 - val_auc_14: 0.5532 - val_loss: 0.6137\n",
            "Epoch 11/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7054 - auc_14: 0.5237 - loss: 0.6080 - val_accuracy: 0.6962 - val_auc_14: 0.5309 - val_loss: 0.6139\n",
            "Epoch 12/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6943 - auc_14: 0.4783 - loss: 0.6230 - val_accuracy: 0.6962 - val_auc_14: 0.5720 - val_loss: 0.6136\n",
            "Epoch 13/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6935 - auc_14: 0.4898 - loss: 0.6220 - val_accuracy: 0.6962 - val_auc_14: 0.5206 - val_loss: 0.6135\n",
            "Epoch 14/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6952 - auc_14: 0.5238 - loss: 0.6159 - val_accuracy: 0.6962 - val_auc_14: 0.5480 - val_loss: 0.6136\n",
            "Epoch 15/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6957 - auc_14: 0.4845 - loss: 0.6201 - val_accuracy: 0.6962 - val_auc_14: 0.5532 - val_loss: 0.6132\n",
            "Epoch 16/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7026 - auc_14: 0.4802 - loss: 0.6145 - val_accuracy: 0.6962 - val_auc_14: 0.5532 - val_loss: 0.6131\n",
            "Epoch 17/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6967 - auc_14: 0.4986 - loss: 0.6173 - val_accuracy: 0.6962 - val_auc_14: 0.5935 - val_loss: 0.6128\n",
            "Epoch 18/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6926 - auc_14: 0.4865 - loss: 0.6223 - val_accuracy: 0.6962 - val_auc_14: 0.5789 - val_loss: 0.6123\n",
            "Epoch 19/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6869 - auc_14: 0.5170 - loss: 0.6225 - val_accuracy: 0.6962 - val_auc_14: 0.5952 - val_loss: 0.6118\n",
            "Epoch 20/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6832 - auc_14: 0.5351 - loss: 0.6231 - val_accuracy: 0.6962 - val_auc_14: 0.5789 - val_loss: 0.6109\n",
            "Epoch 21/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6902 - auc_14: 0.5086 - loss: 0.6210 - val_accuracy: 0.6962 - val_auc_14: 0.5995 - val_loss: 0.6099\n",
            "Epoch 22/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7007 - auc_14: 0.5065 - loss: 0.6123 - val_accuracy: 0.6962 - val_auc_14: 0.5935 - val_loss: 0.6084\n",
            "Epoch 23/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6925 - auc_14: 0.5360 - loss: 0.6149 - val_accuracy: 0.6962 - val_auc_14: 0.5969 - val_loss: 0.6064\n",
            "Epoch 24/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6905 - auc_14: 0.5352 - loss: 0.6167 - val_accuracy: 0.6962 - val_auc_14: 0.6827 - val_loss: 0.6038\n",
            "Epoch 25/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6869 - auc_14: 0.5647 - loss: 0.6151 - val_accuracy: 0.6962 - val_auc_14: 0.6304 - val_loss: 0.6002\n",
            "Epoch 26/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7083 - auc_14: 0.5850 - loss: 0.5925 - val_accuracy: 0.6962 - val_auc_14: 0.7247 - val_loss: 0.5960\n",
            "Epoch 27/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7009 - auc_14: 0.5868 - loss: 0.5975 - val_accuracy: 0.6962 - val_auc_14: 0.6372 - val_loss: 0.5902\n",
            "Epoch 28/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7058 - auc_14: 0.5867 - loss: 0.5997 - val_accuracy: 0.7295 - val_auc_14: 0.6887 - val_loss: 0.5844\n",
            "Epoch 29/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7227 - auc_14: 0.6044 - loss: 0.5866 - val_accuracy: 0.7394 - val_auc_14: 0.7427 - val_loss: 0.5784\n",
            "Epoch 30/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7158 - auc_14: 0.6113 - loss: 0.5947 - val_accuracy: 0.7421 - val_auc_14: 0.6955 - val_loss: 0.5729\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5748 - auc_15: 0.5035 - loss: 0.6829 - val_accuracy: 0.6967 - val_auc_15: 0.5017 - val_loss: 0.6136\n",
            "Epoch 2/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6813 - auc_15: 0.5075 - loss: 0.6328 - val_accuracy: 0.6967 - val_auc_15: 0.5196 - val_loss: 0.6136\n",
            "Epoch 3/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6880 - auc_15: 0.5069 - loss: 0.6277 - val_accuracy: 0.6967 - val_auc_15: 0.5000 - val_loss: 0.6136\n",
            "Epoch 4/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6877 - auc_15: 0.5026 - loss: 0.6288 - val_accuracy: 0.6967 - val_auc_15: 0.5196 - val_loss: 0.6143\n",
            "Epoch 5/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7007 - auc_15: 0.5066 - loss: 0.6206 - val_accuracy: 0.6967 - val_auc_15: 0.5239 - val_loss: 0.6134\n",
            "Epoch 6/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7019 - auc_15: 0.4897 - loss: 0.6207 - val_accuracy: 0.6967 - val_auc_15: 0.5222 - val_loss: 0.6133\n",
            "Epoch 7/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6865 - auc_15: 0.4888 - loss: 0.6331 - val_accuracy: 0.6967 - val_auc_15: 0.5529 - val_loss: 0.6134\n",
            "Epoch 8/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6929 - auc_15: 0.5073 - loss: 0.6213 - val_accuracy: 0.6967 - val_auc_15: 0.5230 - val_loss: 0.6131\n",
            "Epoch 9/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6946 - auc_15: 0.4988 - loss: 0.6244 - val_accuracy: 0.6967 - val_auc_15: 0.6084 - val_loss: 0.6131\n",
            "Epoch 10/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6849 - auc_15: 0.5247 - loss: 0.6266 - val_accuracy: 0.6967 - val_auc_15: 0.5444 - val_loss: 0.6134\n",
            "Epoch 11/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7054 - auc_15: 0.5100 - loss: 0.6111 - val_accuracy: 0.6967 - val_auc_15: 0.5563 - val_loss: 0.6125\n",
            "Epoch 12/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6900 - auc_15: 0.5208 - loss: 0.6224 - val_accuracy: 0.6967 - val_auc_15: 0.5529 - val_loss: 0.6122\n",
            "Epoch 13/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6936 - auc_15: 0.4966 - loss: 0.6225 - val_accuracy: 0.6967 - val_auc_15: 0.5751 - val_loss: 0.6120\n",
            "Epoch 14/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7027 - auc_15: 0.5186 - loss: 0.6107 - val_accuracy: 0.6967 - val_auc_15: 0.5751 - val_loss: 0.6111\n",
            "Epoch 15/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6854 - auc_15: 0.5054 - loss: 0.6273 - val_accuracy: 0.6967 - val_auc_15: 0.5939 - val_loss: 0.6103\n",
            "Epoch 16/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6833 - auc_15: 0.5354 - loss: 0.6241 - val_accuracy: 0.6967 - val_auc_15: 0.6365 - val_loss: 0.6096\n",
            "Epoch 17/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6895 - auc_15: 0.5383 - loss: 0.6183 - val_accuracy: 0.6967 - val_auc_15: 0.6032 - val_loss: 0.6076\n",
            "Epoch 18/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6969 - auc_15: 0.5469 - loss: 0.6112 - val_accuracy: 0.6967 - val_auc_15: 0.6331 - val_loss: 0.6046\n",
            "Epoch 19/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7063 - auc_15: 0.5262 - loss: 0.6054 - val_accuracy: 0.6967 - val_auc_15: 0.6433 - val_loss: 0.6008\n",
            "Epoch 20/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7095 - auc_15: 0.5692 - loss: 0.5959 - val_accuracy: 0.6967 - val_auc_15: 0.6826 - val_loss: 0.5957\n",
            "Epoch 21/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6982 - auc_15: 0.5804 - loss: 0.6040 - val_accuracy: 0.7148 - val_auc_15: 0.7142 - val_loss: 0.5887\n",
            "Epoch 22/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7071 - auc_15: 0.5768 - loss: 0.6035 - val_accuracy: 0.7308 - val_auc_15: 0.6877 - val_loss: 0.5803\n",
            "Epoch 23/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7269 - auc_15: 0.5845 - loss: 0.5932 - val_accuracy: 0.7402 - val_auc_15: 0.6809 - val_loss: 0.5712\n",
            "Epoch 24/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7309 - auc_15: 0.6062 - loss: 0.5852 - val_accuracy: 0.7422 - val_auc_15: 0.7643 - val_loss: 0.5634\n",
            "Epoch 25/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7426 - auc_15: 0.5785 - loss: 0.5808 - val_accuracy: 0.7453 - val_auc_15: 0.6826 - val_loss: 0.5589\n",
            "Epoch 26/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7451 - auc_15: 0.5973 - loss: 0.5709 - val_accuracy: 0.7536 - val_auc_15: 0.6980 - val_loss: 0.5503\n",
            "Epoch 27/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7447 - auc_15: 0.5983 - loss: 0.5705 - val_accuracy: 0.7536 - val_auc_15: 0.7617 - val_loss: 0.5454\n",
            "Epoch 28/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7398 - auc_15: 0.5917 - loss: 0.5735 - val_accuracy: 0.7547 - val_auc_15: 0.7014 - val_loss: 0.5426\n",
            "Epoch 29/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7465 - auc_15: 0.6125 - loss: 0.5635 - val_accuracy: 0.7593 - val_auc_15: 0.7608 - val_loss: 0.5364\n",
            "Epoch 30/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7541 - auc_15: 0.6252 - loss: 0.5534 - val_accuracy: 0.7593 - val_auc_15: 0.7227 - val_loss: 0.5333\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6700 - auc_16: 0.4891 - loss: 0.6422 - val_accuracy: 0.6988 - val_auc_16: 0.5000 - val_loss: 0.6128\n",
            "Epoch 2/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6952 - auc_16: 0.4937 - loss: 0.6264 - val_accuracy: 0.6988 - val_auc_16: 0.5129 - val_loss: 0.6121\n",
            "Epoch 3/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6965 - auc_16: 0.4948 - loss: 0.6225 - val_accuracy: 0.6988 - val_auc_16: 0.6821 - val_loss: 0.6118\n",
            "Epoch 4/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7006 - auc_16: 0.4857 - loss: 0.6211 - val_accuracy: 0.6988 - val_auc_16: 0.5000 - val_loss: 0.6118\n",
            "Epoch 5/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7001 - auc_16: 0.4993 - loss: 0.6182 - val_accuracy: 0.6988 - val_auc_16: 0.5034 - val_loss: 0.6118\n",
            "Epoch 6/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7054 - auc_16: 0.4929 - loss: 0.6142 - val_accuracy: 0.6988 - val_auc_16: 0.5000 - val_loss: 0.6119\n",
            "Epoch 7/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7014 - auc_16: 0.5073 - loss: 0.6150 - val_accuracy: 0.6988 - val_auc_16: 0.5034 - val_loss: 0.6117\n",
            "Epoch 8/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7082 - auc_16: 0.5053 - loss: 0.6099 - val_accuracy: 0.6988 - val_auc_16: 0.5490 - val_loss: 0.6120\n",
            "Epoch 9/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6927 - auc_16: 0.4832 - loss: 0.6262 - val_accuracy: 0.6988 - val_auc_16: 0.5739 - val_loss: 0.6115\n",
            "Epoch 10/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6919 - auc_16: 0.4917 - loss: 0.6244 - val_accuracy: 0.6988 - val_auc_16: 0.5576 - val_loss: 0.6115\n",
            "Epoch 11/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6984 - auc_16: 0.4991 - loss: 0.6171 - val_accuracy: 0.6988 - val_auc_16: 0.5481 - val_loss: 0.6112\n",
            "Epoch 12/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7019 - auc_16: 0.5146 - loss: 0.6121 - val_accuracy: 0.6988 - val_auc_16: 0.5558 - val_loss: 0.6110\n",
            "Epoch 13/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6917 - auc_16: 0.5061 - loss: 0.6211 - val_accuracy: 0.6988 - val_auc_16: 0.5515 - val_loss: 0.6108\n",
            "Epoch 14/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6899 - auc_16: 0.5165 - loss: 0.6210 - val_accuracy: 0.6988 - val_auc_16: 0.6186 - val_loss: 0.6104\n",
            "Epoch 15/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_16: 0.5109 - loss: 0.6091 - val_accuracy: 0.6988 - val_auc_16: 0.5893 - val_loss: 0.6104\n",
            "Epoch 16/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6941 - auc_16: 0.5146 - loss: 0.6184 - val_accuracy: 0.6988 - val_auc_16: 0.6074 - val_loss: 0.6091\n",
            "Epoch 17/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7039 - auc_16: 0.5214 - loss: 0.6086 - val_accuracy: 0.6988 - val_auc_16: 0.6314 - val_loss: 0.6078\n",
            "Epoch 18/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6974 - auc_16: 0.5514 - loss: 0.6090 - val_accuracy: 0.6988 - val_auc_16: 0.6005 - val_loss: 0.6054\n",
            "Epoch 19/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7004 - auc_16: 0.5414 - loss: 0.6087 - val_accuracy: 0.6988 - val_auc_16: 0.6082 - val_loss: 0.6020\n",
            "Epoch 20/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7001 - auc_16: 0.5579 - loss: 0.6041 - val_accuracy: 0.6988 - val_auc_16: 0.6357 - val_loss: 0.5972\n",
            "Epoch 21/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6944 - auc_16: 0.5486 - loss: 0.6110 - val_accuracy: 0.6988 - val_auc_16: 0.6658 - val_loss: 0.5905\n",
            "Epoch 22/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7064 - auc_16: 0.5917 - loss: 0.5957 - val_accuracy: 0.7288 - val_auc_16: 0.6830 - val_loss: 0.5821\n",
            "Epoch 23/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7219 - auc_16: 0.6238 - loss: 0.5838 - val_accuracy: 0.7407 - val_auc_16: 0.6924 - val_loss: 0.5729\n",
            "Epoch 24/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7410 - auc_16: 0.6056 - loss: 0.5758 - val_accuracy: 0.7479 - val_auc_16: 0.7285 - val_loss: 0.5644\n",
            "Epoch 25/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7391 - auc_16: 0.6078 - loss: 0.5779 - val_accuracy: 0.7505 - val_auc_16: 0.7302 - val_loss: 0.5586\n",
            "Epoch 26/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7422 - auc_16: 0.6195 - loss: 0.5753 - val_accuracy: 0.7526 - val_auc_16: 0.7174 - val_loss: 0.5523\n",
            "Epoch 27/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7444 - auc_16: 0.6279 - loss: 0.5707 - val_accuracy: 0.7562 - val_auc_16: 0.7787 - val_loss: 0.5451\n",
            "Epoch 28/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7465 - auc_16: 0.6335 - loss: 0.5657 - val_accuracy: 0.7583 - val_auc_16: 0.7337 - val_loss: 0.5396\n",
            "Epoch 29/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7681 - auc_16: 0.6406 - loss: 0.5406 - val_accuracy: 0.7588 - val_auc_16: 0.7663 - val_loss: 0.5360\n",
            "Epoch 30/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7638 - auc_16: 0.6418 - loss: 0.5411 - val_accuracy: 0.7635 - val_auc_16: 0.7500 - val_loss: 0.5309\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.6537 - auc_17: 0.4804 - loss: 0.6492 - val_accuracy: 0.6952 - val_auc_17: 0.5000 - val_loss: 0.6150\n",
            "Epoch 2/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7006 - auc_17: 0.5138 - loss: 0.6185 - val_accuracy: 0.6952 - val_auc_17: 0.5000 - val_loss: 0.6148\n",
            "Epoch 3/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6809 - auc_17: 0.5012 - loss: 0.6356 - val_accuracy: 0.6952 - val_auc_17: 0.5477 - val_loss: 0.6147\n",
            "Epoch 4/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6866 - auc_17: 0.4940 - loss: 0.6321 - val_accuracy: 0.6952 - val_auc_17: 0.5339 - val_loss: 0.6151\n",
            "Epoch 5/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6816 - auc_17: 0.4845 - loss: 0.6386 - val_accuracy: 0.6952 - val_auc_17: 0.5061 - val_loss: 0.6153\n",
            "Epoch 6/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6781 - auc_17: 0.4947 - loss: 0.6410 - val_accuracy: 0.6952 - val_auc_17: 0.5061 - val_loss: 0.6149\n",
            "Epoch 7/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6743 - auc_17: 0.5079 - loss: 0.6373 - val_accuracy: 0.6952 - val_auc_17: 0.5095 - val_loss: 0.6148\n",
            "Epoch 8/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6801 - auc_17: 0.5068 - loss: 0.6330 - val_accuracy: 0.6952 - val_auc_17: 0.5252 - val_loss: 0.6154\n",
            "Epoch 9/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6962 - auc_17: 0.5323 - loss: 0.6144 - val_accuracy: 0.6952 - val_auc_17: 0.5278 - val_loss: 0.6144\n",
            "Epoch 10/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6937 - auc_17: 0.4712 - loss: 0.6266 - val_accuracy: 0.6952 - val_auc_17: 0.5460 - val_loss: 0.6142\n",
            "Epoch 11/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6969 - auc_17: 0.5177 - loss: 0.6171 - val_accuracy: 0.6952 - val_auc_17: 0.5894 - val_loss: 0.6140\n",
            "Epoch 12/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6902 - auc_17: 0.5107 - loss: 0.6228 - val_accuracy: 0.6952 - val_auc_17: 0.5747 - val_loss: 0.6138\n",
            "Epoch 13/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7066 - auc_17: 0.5070 - loss: 0.6096 - val_accuracy: 0.6952 - val_auc_17: 0.6128 - val_loss: 0.6134\n",
            "Epoch 14/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6942 - auc_17: 0.5006 - loss: 0.6210 - val_accuracy: 0.6952 - val_auc_17: 0.5773 - val_loss: 0.6130\n",
            "Epoch 15/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6921 - auc_17: 0.5089 - loss: 0.6213 - val_accuracy: 0.6952 - val_auc_17: 0.6146 - val_loss: 0.6124\n",
            "Epoch 16/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7004 - auc_17: 0.5217 - loss: 0.6128 - val_accuracy: 0.6952 - val_auc_17: 0.6606 - val_loss: 0.6122\n",
            "Epoch 17/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6951 - auc_17: 0.5189 - loss: 0.6178 - val_accuracy: 0.6952 - val_auc_17: 0.6510 - val_loss: 0.6100\n",
            "Epoch 18/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6963 - auc_17: 0.5231 - loss: 0.6148 - val_accuracy: 0.6952 - val_auc_17: 0.6988 - val_loss: 0.6078\n",
            "Epoch 19/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6970 - auc_17: 0.5245 - loss: 0.6144 - val_accuracy: 0.6952 - val_auc_17: 0.6406 - val_loss: 0.6046\n",
            "Epoch 20/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6979 - auc_17: 0.5494 - loss: 0.6078 - val_accuracy: 0.6952 - val_auc_17: 0.6493 - val_loss: 0.5998\n",
            "Epoch 21/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6943 - auc_17: 0.5714 - loss: 0.6086 - val_accuracy: 0.6952 - val_auc_17: 0.7222 - val_loss: 0.5930\n",
            "Epoch 22/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6975 - auc_17: 0.5791 - loss: 0.6088 - val_accuracy: 0.7249 - val_auc_17: 0.6589 - val_loss: 0.5842\n",
            "Epoch 23/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7148 - auc_17: 0.5871 - loss: 0.5994 - val_accuracy: 0.7397 - val_auc_17: 0.7700 - val_loss: 0.5753\n",
            "Epoch 24/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7349 - auc_17: 0.6273 - loss: 0.5783 - val_accuracy: 0.7444 - val_auc_17: 0.6823 - val_loss: 0.5647\n",
            "Epoch 25/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7352 - auc_17: 0.5950 - loss: 0.5841 - val_accuracy: 0.7540 - val_auc_17: 0.7752 - val_loss: 0.5551\n",
            "Epoch 26/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7452 - auc_17: 0.6239 - loss: 0.5699 - val_accuracy: 0.7540 - val_auc_17: 0.7837 - val_loss: 0.5476\n",
            "Epoch 27/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7482 - auc_17: 0.6168 - loss: 0.5684 - val_accuracy: 0.7603 - val_auc_17: 0.7465 - val_loss: 0.5408\n",
            "Epoch 28/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7526 - auc_17: 0.6469 - loss: 0.5572 - val_accuracy: 0.7603 - val_auc_17: 0.7283 - val_loss: 0.5390\n",
            "Epoch 29/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7562 - auc_17: 0.6251 - loss: 0.5547 - val_accuracy: 0.7661 - val_auc_17: 0.7318 - val_loss: 0.5303\n",
            "Epoch 30/30\n",
            "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7700 - auc_17: 0.6468 - loss: 0.5353 - val_accuracy: 0.7672 - val_auc_17: 0.7587 - val_loss: 0.5268\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6824 - auc_18: 0.5024 - loss: 0.6384 - val_accuracy: 0.6926 - val_auc_18: 0.5000 - val_loss: 0.6170\n",
            "Epoch 2/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6915 - auc_18: 0.4956 - loss: 0.6310 - val_accuracy: 0.6926 - val_auc_18: 0.5515 - val_loss: 0.6171\n",
            "Epoch 3/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6824 - auc_18: 0.4836 - loss: 0.6395 - val_accuracy: 0.6926 - val_auc_18: 0.5095 - val_loss: 0.6169\n",
            "Epoch 4/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6950 - auc_18: 0.4992 - loss: 0.6259 - val_accuracy: 0.6926 - val_auc_18: 0.5584 - val_loss: 0.6170\n",
            "Epoch 5/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6772 - auc_18: 0.5063 - loss: 0.6346 - val_accuracy: 0.6926 - val_auc_18: 0.5026 - val_loss: 0.6168\n",
            "Epoch 6/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6893 - auc_18: 0.4845 - loss: 0.6323 - val_accuracy: 0.6926 - val_auc_18: 0.5679 - val_loss: 0.6168\n",
            "Epoch 7/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6819 - auc_18: 0.4898 - loss: 0.6358 - val_accuracy: 0.6926 - val_auc_18: 0.5172 - val_loss: 0.6168\n",
            "Epoch 8/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6933 - auc_18: 0.4885 - loss: 0.6273 - val_accuracy: 0.6926 - val_auc_18: 0.5137 - val_loss: 0.6166\n",
            "Epoch 9/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6831 - auc_18: 0.4734 - loss: 0.6378 - val_accuracy: 0.6926 - val_auc_18: 0.5455 - val_loss: 0.6165\n",
            "Epoch 10/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6882 - auc_18: 0.4871 - loss: 0.6283 - val_accuracy: 0.6926 - val_auc_18: 0.5326 - val_loss: 0.6164\n",
            "Epoch 11/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6870 - auc_18: 0.4815 - loss: 0.6331 - val_accuracy: 0.6926 - val_auc_18: 0.5498 - val_loss: 0.6162\n",
            "Epoch 12/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6945 - auc_18: 0.5132 - loss: 0.6193 - val_accuracy: 0.6926 - val_auc_18: 0.5515 - val_loss: 0.6160\n",
            "Epoch 13/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6951 - auc_18: 0.5046 - loss: 0.6195 - val_accuracy: 0.6926 - val_auc_18: 0.5524 - val_loss: 0.6157\n",
            "Epoch 14/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6966 - auc_18: 0.5048 - loss: 0.6183 - val_accuracy: 0.6926 - val_auc_18: 0.6813 - val_loss: 0.6153\n",
            "Epoch 15/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6928 - auc_18: 0.5152 - loss: 0.6203 - val_accuracy: 0.6926 - val_auc_18: 0.5885 - val_loss: 0.6148\n",
            "Epoch 16/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6964 - auc_18: 0.5147 - loss: 0.6168 - val_accuracy: 0.6926 - val_auc_18: 0.5833 - val_loss: 0.6139\n",
            "Epoch 17/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7041 - auc_18: 0.5410 - loss: 0.6052 - val_accuracy: 0.6926 - val_auc_18: 0.5928 - val_loss: 0.6126\n",
            "Epoch 18/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6919 - auc_18: 0.5194 - loss: 0.6196 - val_accuracy: 0.6926 - val_auc_18: 0.6117 - val_loss: 0.6107\n",
            "Epoch 19/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6773 - auc_18: 0.5618 - loss: 0.6245 - val_accuracy: 0.6926 - val_auc_18: 0.6186 - val_loss: 0.6070\n",
            "Epoch 20/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6902 - auc_18: 0.5430 - loss: 0.6165 - val_accuracy: 0.6926 - val_auc_18: 0.6357 - val_loss: 0.6027\n",
            "Epoch 21/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6951 - auc_18: 0.5739 - loss: 0.6095 - val_accuracy: 0.6926 - val_auc_18: 0.6890 - val_loss: 0.5965\n",
            "Epoch 22/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7045 - auc_18: 0.5729 - loss: 0.6025 - val_accuracy: 0.7242 - val_auc_18: 0.6933 - val_loss: 0.5871\n",
            "Epoch 23/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7107 - auc_18: 0.5929 - loss: 0.6001 - val_accuracy: 0.7316 - val_auc_18: 0.7019 - val_loss: 0.5777\n",
            "Epoch 24/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7205 - auc_18: 0.5999 - loss: 0.5968 - val_accuracy: 0.7417 - val_auc_18: 0.7491 - val_loss: 0.5672\n",
            "Epoch 25/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7292 - auc_18: 0.6232 - loss: 0.5848 - val_accuracy: 0.7475 - val_auc_18: 0.6993 - val_loss: 0.5593\n",
            "Epoch 26/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7418 - auc_18: 0.6081 - loss: 0.5754 - val_accuracy: 0.7480 - val_auc_18: 0.7268 - val_loss: 0.5529\n",
            "Epoch 27/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7575 - auc_18: 0.6204 - loss: 0.5578 - val_accuracy: 0.7570 - val_auc_18: 0.7861 - val_loss: 0.5470\n",
            "Epoch 28/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7483 - auc_18: 0.6243 - loss: 0.5667 - val_accuracy: 0.7570 - val_auc_18: 0.7397 - val_loss: 0.5418\n",
            "Epoch 29/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7479 - auc_18: 0.6276 - loss: 0.5634 - val_accuracy: 0.7596 - val_auc_18: 0.7534 - val_loss: 0.5384\n",
            "Epoch 30/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7492 - auc_18: 0.6265 - loss: 0.5604 - val_accuracy: 0.7602 - val_auc_18: 0.7500 - val_loss: 0.5364\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6647 - auc_19: 0.5256 - loss: 0.6341 - val_accuracy: 0.6979 - val_auc_19: 0.5000 - val_loss: 0.6126\n",
            "Epoch 2/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6888 - auc_19: 0.5040 - loss: 0.6320 - val_accuracy: 0.6979 - val_auc_19: 0.5253 - val_loss: 0.6126\n",
            "Epoch 3/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6892 - auc_19: 0.5065 - loss: 0.6291 - val_accuracy: 0.6979 - val_auc_19: 0.5061 - val_loss: 0.6128\n",
            "Epoch 4/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6891 - auc_19: 0.5224 - loss: 0.6237 - val_accuracy: 0.6979 - val_auc_19: 0.5026 - val_loss: 0.6129\n",
            "Epoch 5/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7028 - auc_19: 0.4921 - loss: 0.6175 - val_accuracy: 0.6979 - val_auc_19: 0.5716 - val_loss: 0.6123\n",
            "Epoch 6/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6955 - auc_19: 0.5075 - loss: 0.6225 - val_accuracy: 0.6979 - val_auc_19: 0.5541 - val_loss: 0.6122\n",
            "Epoch 7/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6988 - auc_19: 0.5170 - loss: 0.6175 - val_accuracy: 0.6979 - val_auc_19: 0.5166 - val_loss: 0.6121\n",
            "Epoch 8/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6947 - auc_19: 0.4883 - loss: 0.6250 - val_accuracy: 0.6979 - val_auc_19: 0.6614 - val_loss: 0.6120\n",
            "Epoch 9/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6811 - auc_19: 0.5130 - loss: 0.6307 - val_accuracy: 0.6979 - val_auc_19: 0.5541 - val_loss: 0.6126\n",
            "Epoch 10/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6994 - auc_19: 0.4721 - loss: 0.6237 - val_accuracy: 0.6979 - val_auc_19: 0.6449 - val_loss: 0.6117\n",
            "Epoch 11/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7062 - auc_19: 0.5166 - loss: 0.6104 - val_accuracy: 0.6979 - val_auc_19: 0.5785 - val_loss: 0.6114\n",
            "Epoch 12/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6995 - auc_19: 0.5044 - loss: 0.6162 - val_accuracy: 0.6979 - val_auc_19: 0.5785 - val_loss: 0.6109\n",
            "Epoch 13/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6907 - auc_19: 0.4896 - loss: 0.6251 - val_accuracy: 0.6979 - val_auc_19: 0.5785 - val_loss: 0.6104\n",
            "Epoch 14/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6982 - auc_19: 0.4959 - loss: 0.6202 - val_accuracy: 0.6979 - val_auc_19: 0.6030 - val_loss: 0.6096\n",
            "Epoch 15/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7019 - auc_19: 0.5208 - loss: 0.6114 - val_accuracy: 0.6979 - val_auc_19: 0.6082 - val_loss: 0.6085\n",
            "Epoch 16/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6928 - auc_19: 0.5156 - loss: 0.6194 - val_accuracy: 0.6979 - val_auc_19: 0.6309 - val_loss: 0.6070\n",
            "Epoch 17/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6943 - auc_19: 0.5388 - loss: 0.6137 - val_accuracy: 0.6979 - val_auc_19: 0.6457 - val_loss: 0.6044\n",
            "Epoch 18/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6939 - auc_19: 0.5556 - loss: 0.6120 - val_accuracy: 0.6979 - val_auc_19: 0.6195 - val_loss: 0.6007\n",
            "Epoch 19/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6985 - auc_19: 0.5515 - loss: 0.6085 - val_accuracy: 0.6979 - val_auc_19: 0.6414 - val_loss: 0.5962\n",
            "Epoch 20/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6981 - auc_19: 0.5790 - loss: 0.6026 - val_accuracy: 0.6979 - val_auc_19: 0.6972 - val_loss: 0.5891\n",
            "Epoch 21/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7042 - auc_19: 0.6018 - loss: 0.5997 - val_accuracy: 0.7317 - val_auc_19: 0.6876 - val_loss: 0.5801\n",
            "Epoch 22/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7147 - auc_19: 0.5969 - loss: 0.5957 - val_accuracy: 0.7438 - val_auc_19: 0.6841 - val_loss: 0.5697\n",
            "Epoch 23/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7501 - auc_19: 0.5901 - loss: 0.5730 - val_accuracy: 0.7533 - val_auc_19: 0.7243 - val_loss: 0.5606\n",
            "Epoch 24/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7454 - auc_19: 0.6288 - loss: 0.5719 - val_accuracy: 0.7538 - val_auc_19: 0.7068 - val_loss: 0.5509\n",
            "Epoch 25/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7527 - auc_19: 0.6128 - loss: 0.5656 - val_accuracy: 0.7575 - val_auc_19: 0.7775 - val_loss: 0.5433\n",
            "Epoch 26/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7717 - auc_19: 0.6332 - loss: 0.5404 - val_accuracy: 0.7659 - val_auc_19: 0.7884 - val_loss: 0.5389\n",
            "Epoch 27/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7592 - auc_19: 0.6509 - loss: 0.5470 - val_accuracy: 0.7665 - val_auc_19: 0.7627 - val_loss: 0.5335\n",
            "Epoch 28/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7507 - auc_19: 0.6201 - loss: 0.5604 - val_accuracy: 0.7644 - val_auc_19: 0.7829 - val_loss: 0.5324\n",
            "Epoch 29/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7680 - auc_19: 0.6287 - loss: 0.5435 - val_accuracy: 0.7665 - val_auc_19: 0.7863 - val_loss: 0.5253\n",
            "Epoch 30/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7664 - auc_19: 0.6456 - loss: 0.5393 - val_accuracy: 0.7686 - val_auc_19: 0.7373 - val_loss: 0.5212\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - accuracy: 0.7089 - auc_20: 0.4855 - loss: 0.6173 - val_accuracy: 0.7051 - val_auc_20: 0.5000 - val_loss: 0.6065\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6969 - auc_20: 0.5099 - loss: 0.6193 - val_accuracy: 0.7051 - val_auc_20: 0.5000 - val_loss: 0.6064\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6995 - auc_20: 0.5164 - loss: 0.6162 - val_accuracy: 0.7051 - val_auc_20: 0.5000 - val_loss: 0.6064\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7068 - auc_20: 0.5190 - loss: 0.6103 - val_accuracy: 0.7051 - val_auc_20: 0.5576 - val_loss: 0.6062\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_20: 0.4842 - loss: 0.6219 - val_accuracy: 0.7051 - val_auc_20: 0.5349 - val_loss: 0.6064\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7054 - auc_20: 0.5070 - loss: 0.6130 - val_accuracy: 0.7051 - val_auc_20: 0.5140 - val_loss: 0.6060\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7123 - auc_20: 0.4911 - loss: 0.6091 - val_accuracy: 0.7051 - val_auc_20: 0.5541 - val_loss: 0.6060\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7135 - auc_20: 0.4996 - loss: 0.6047 - val_accuracy: 0.7051 - val_auc_20: 0.6178 - val_loss: 0.6056\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7082 - auc_20: 0.4961 - loss: 0.6108 - val_accuracy: 0.7051 - val_auc_20: 0.5524 - val_loss: 0.6055\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7014 - auc_20: 0.5024 - loss: 0.6156 - val_accuracy: 0.7051 - val_auc_20: 0.6012 - val_loss: 0.6049\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7054 - auc_20: 0.4997 - loss: 0.6116 - val_accuracy: 0.7051 - val_auc_20: 0.5995 - val_loss: 0.6043\n",
            "Epoch 12/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7011 - auc_20: 0.5281 - loss: 0.6105 - val_accuracy: 0.7051 - val_auc_20: 0.5925 - val_loss: 0.6033\n",
            "Epoch 13/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7046 - auc_20: 0.5388 - loss: 0.6057 - val_accuracy: 0.7051 - val_auc_20: 0.6073 - val_loss: 0.6018\n",
            "Epoch 14/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6943 - auc_20: 0.5242 - loss: 0.6176 - val_accuracy: 0.7051 - val_auc_20: 0.6099 - val_loss: 0.5995\n",
            "Epoch 15/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7162 - auc_20: 0.5283 - loss: 0.5959 - val_accuracy: 0.7051 - val_auc_20: 0.7862 - val_loss: 0.5959\n",
            "Epoch 16/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7068 - auc_20: 0.5625 - loss: 0.5995 - val_accuracy: 0.7051 - val_auc_20: 0.6483 - val_loss: 0.5900\n",
            "Epoch 17/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7112 - auc_20: 0.5801 - loss: 0.5916 - val_accuracy: 0.7051 - val_auc_20: 0.6684 - val_loss: 0.5816\n",
            "Epoch 18/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7167 - auc_20: 0.5930 - loss: 0.5904 - val_accuracy: 0.7396 - val_auc_20: 0.7834 - val_loss: 0.5719\n",
            "Epoch 19/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7434 - auc_20: 0.5756 - loss: 0.5718 - val_accuracy: 0.7483 - val_auc_20: 0.6859 - val_loss: 0.5621\n",
            "Epoch 20/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7501 - auc_20: 0.6169 - loss: 0.5690 - val_accuracy: 0.7571 - val_auc_20: 0.7051 - val_loss: 0.5530\n",
            "Epoch 21/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7616 - auc_20: 0.6212 - loss: 0.5571 - val_accuracy: 0.7643 - val_auc_20: 0.7866 - val_loss: 0.5435\n",
            "Epoch 22/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7735 - auc_20: 0.6341 - loss: 0.5454 - val_accuracy: 0.7648 - val_auc_20: 0.7557 - val_loss: 0.5375\n",
            "Epoch 23/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7761 - auc_20: 0.6345 - loss: 0.5368 - val_accuracy: 0.7674 - val_auc_20: 0.7330 - val_loss: 0.5306\n",
            "Epoch 24/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7661 - auc_20: 0.6424 - loss: 0.5448 - val_accuracy: 0.7694 - val_auc_20: 0.7347 - val_loss: 0.5256\n",
            "Epoch 25/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7753 - auc_20: 0.6414 - loss: 0.5361 - val_accuracy: 0.7756 - val_auc_20: 0.7557 - val_loss: 0.5204\n",
            "Epoch 26/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7847 - auc_20: 0.6547 - loss: 0.5215 - val_accuracy: 0.7756 - val_auc_20: 0.7757 - val_loss: 0.5163\n",
            "Epoch 27/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7757 - auc_20: 0.6402 - loss: 0.5355 - val_accuracy: 0.7761 - val_auc_20: 0.7871 - val_loss: 0.5137\n",
            "Epoch 28/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7734 - auc_20: 0.6528 - loss: 0.5288 - val_accuracy: 0.7766 - val_auc_20: 0.7888 - val_loss: 0.5118\n",
            "Epoch 29/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7726 - auc_20: 0.6448 - loss: 0.5313 - val_accuracy: 0.7802 - val_auc_20: 0.7696 - val_loss: 0.5069\n",
            "Epoch 30/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7716 - auc_20: 0.6557 - loss: 0.5318 - val_accuracy: 0.7802 - val_auc_20: 0.7845 - val_loss: 0.5038\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.4046 - auc_21: 0.5095 - loss: 0.8286 - val_accuracy: 0.7031 - val_auc_21: 0.5112 - val_loss: 0.6096\n",
            "Epoch 2/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7134 - auc_21: 0.5030 - loss: 0.6074 - val_accuracy: 0.7031 - val_auc_21: 0.5207 - val_loss: 0.6082\n",
            "Epoch 3/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6880 - auc_21: 0.4949 - loss: 0.6314 - val_accuracy: 0.7031 - val_auc_21: 0.5043 - val_loss: 0.6093\n",
            "Epoch 4/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7046 - auc_21: 0.5155 - loss: 0.6123 - val_accuracy: 0.7031 - val_auc_21: 0.5258 - val_loss: 0.6083\n",
            "Epoch 5/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7026 - auc_21: 0.5015 - loss: 0.6162 - val_accuracy: 0.7031 - val_auc_21: 0.5043 - val_loss: 0.6085\n",
            "Epoch 6/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7076 - auc_21: 0.4883 - loss: 0.6141 - val_accuracy: 0.7031 - val_auc_21: 0.5189 - val_loss: 0.6080\n",
            "Epoch 7/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7027 - auc_21: 0.4953 - loss: 0.6166 - val_accuracy: 0.7031 - val_auc_21: 0.5731 - val_loss: 0.6080\n",
            "Epoch 8/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7027 - auc_21: 0.4833 - loss: 0.6178 - val_accuracy: 0.7031 - val_auc_21: 0.5430 - val_loss: 0.6077\n",
            "Epoch 9/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6985 - auc_21: 0.5386 - loss: 0.6111 - val_accuracy: 0.7031 - val_auc_21: 0.5404 - val_loss: 0.6075\n",
            "Epoch 10/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7071 - auc_21: 0.4759 - loss: 0.6138 - val_accuracy: 0.7031 - val_auc_21: 0.5723 - val_loss: 0.6070\n",
            "Epoch 11/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7011 - auc_21: 0.5137 - loss: 0.6134 - val_accuracy: 0.7031 - val_auc_21: 0.5706 - val_loss: 0.6061\n",
            "Epoch 12/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7186 - auc_21: 0.4986 - loss: 0.5995 - val_accuracy: 0.7031 - val_auc_21: 0.5998 - val_loss: 0.6049\n",
            "Epoch 13/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7007 - auc_21: 0.5478 - loss: 0.6074 - val_accuracy: 0.7031 - val_auc_21: 0.6299 - val_loss: 0.6030\n",
            "Epoch 14/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7114 - auc_21: 0.5556 - loss: 0.5966 - val_accuracy: 0.7031 - val_auc_21: 0.6618 - val_loss: 0.5993\n",
            "Epoch 15/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_21: 0.5369 - loss: 0.6038 - val_accuracy: 0.7031 - val_auc_21: 0.6764 - val_loss: 0.5925\n",
            "Epoch 16/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6973 - auc_21: 0.5868 - loss: 0.6056 - val_accuracy: 0.7205 - val_auc_21: 0.6386 - val_loss: 0.5839\n",
            "Epoch 17/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7295 - auc_21: 0.5692 - loss: 0.5899 - val_accuracy: 0.7414 - val_auc_21: 0.6601 - val_loss: 0.5685\n",
            "Epoch 18/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7451 - auc_21: 0.5845 - loss: 0.5732 - val_accuracy: 0.7496 - val_auc_21: 0.6997 - val_loss: 0.5566\n",
            "Epoch 19/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7558 - auc_21: 0.6224 - loss: 0.5595 - val_accuracy: 0.7568 - val_auc_21: 0.7143 - val_loss: 0.5460\n",
            "Epoch 20/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7646 - auc_21: 0.6392 - loss: 0.5422 - val_accuracy: 0.7573 - val_auc_21: 0.7143 - val_loss: 0.5409\n",
            "Epoch 21/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7655 - auc_21: 0.6494 - loss: 0.5388 - val_accuracy: 0.7583 - val_auc_21: 0.7143 - val_loss: 0.5346\n",
            "Epoch 22/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7729 - auc_21: 0.6409 - loss: 0.5301 - val_accuracy: 0.7624 - val_auc_21: 0.7289 - val_loss: 0.5288\n",
            "Epoch 23/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7651 - auc_21: 0.6417 - loss: 0.5381 - val_accuracy: 0.7624 - val_auc_21: 0.7083 - val_loss: 0.5291\n",
            "Epoch 24/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7817 - auc_21: 0.6636 - loss: 0.5130 - val_accuracy: 0.7639 - val_auc_21: 0.7755 - val_loss: 0.5225\n",
            "Epoch 25/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7696 - auc_21: 0.6460 - loss: 0.5292 - val_accuracy: 0.7629 - val_auc_21: 0.7727 - val_loss: 0.5266\n",
            "Epoch 26/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7644 - auc_21: 0.6606 - loss: 0.5302 - val_accuracy: 0.7660 - val_auc_21: 0.7547 - val_loss: 0.5205\n",
            "Epoch 27/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7735 - auc_21: 0.6700 - loss: 0.5173 - val_accuracy: 0.7680 - val_auc_21: 0.7341 - val_loss: 0.5154\n",
            "Epoch 28/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7798 - auc_21: 0.6595 - loss: 0.5127 - val_accuracy: 0.7741 - val_auc_21: 0.7625 - val_loss: 0.5103\n",
            "Epoch 29/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7709 - auc_21: 0.6328 - loss: 0.5293 - val_accuracy: 0.7757 - val_auc_21: 0.7582 - val_loss: 0.5078\n",
            "Epoch 30/30\n",
            "\u001b[1m457/457\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7747 - auc_21: 0.6650 - loss: 0.5207 - val_accuracy: 0.7752 - val_auc_21: 0.7496 - val_loss: 0.5072\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6479 - auc_22: 0.5108 - loss: 0.6453 - val_accuracy: 0.7001 - val_auc_22: 0.5000 - val_loss: 0.6109\n",
            "Epoch 2/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6881 - auc_22: 0.5175 - loss: 0.6265 - val_accuracy: 0.7001 - val_auc_22: 0.5545 - val_loss: 0.6109\n",
            "Epoch 3/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6932 - auc_22: 0.5053 - loss: 0.6221 - val_accuracy: 0.7001 - val_auc_22: 0.5000 - val_loss: 0.6107\n",
            "Epoch 4/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6960 - auc_22: 0.4984 - loss: 0.6213 - val_accuracy: 0.7001 - val_auc_22: 0.5398 - val_loss: 0.6106\n",
            "Epoch 5/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7038 - auc_22: 0.5015 - loss: 0.6178 - val_accuracy: 0.7001 - val_auc_22: 0.5026 - val_loss: 0.6105\n",
            "Epoch 6/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7091 - auc_22: 0.5003 - loss: 0.6121 - val_accuracy: 0.7001 - val_auc_22: 0.5839 - val_loss: 0.6105\n",
            "Epoch 7/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6982 - auc_22: 0.4928 - loss: 0.6203 - val_accuracy: 0.7001 - val_auc_22: 0.6029 - val_loss: 0.6103\n",
            "Epoch 8/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6883 - auc_22: 0.5063 - loss: 0.6255 - val_accuracy: 0.7001 - val_auc_22: 0.6220 - val_loss: 0.6101\n",
            "Epoch 9/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6897 - auc_22: 0.4846 - loss: 0.6261 - val_accuracy: 0.7001 - val_auc_22: 0.5580 - val_loss: 0.6099\n",
            "Epoch 10/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6972 - auc_22: 0.4985 - loss: 0.6199 - val_accuracy: 0.7001 - val_auc_22: 0.5709 - val_loss: 0.6095\n",
            "Epoch 11/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6920 - auc_22: 0.5007 - loss: 0.6230 - val_accuracy: 0.7001 - val_auc_22: 0.6427 - val_loss: 0.6089\n",
            "Epoch 12/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6950 - auc_22: 0.5180 - loss: 0.6173 - val_accuracy: 0.7001 - val_auc_22: 0.6202 - val_loss: 0.6082\n",
            "Epoch 13/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7074 - auc_22: 0.5030 - loss: 0.6092 - val_accuracy: 0.7001 - val_auc_22: 0.6151 - val_loss: 0.6067\n",
            "Epoch 14/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7015 - auc_22: 0.5119 - loss: 0.6134 - val_accuracy: 0.7001 - val_auc_22: 0.6557 - val_loss: 0.6046\n",
            "Epoch 15/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7000 - auc_22: 0.5157 - loss: 0.6130 - val_accuracy: 0.7001 - val_auc_22: 0.6202 - val_loss: 0.6014\n",
            "Epoch 16/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7011 - auc_22: 0.5608 - loss: 0.6049 - val_accuracy: 0.7001 - val_auc_22: 0.6272 - val_loss: 0.5964\n",
            "Epoch 17/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6982 - auc_22: 0.5451 - loss: 0.6089 - val_accuracy: 0.7001 - val_auc_22: 0.6929 - val_loss: 0.5895\n",
            "Epoch 18/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6959 - auc_22: 0.5945 - loss: 0.6026 - val_accuracy: 0.7208 - val_auc_22: 0.6791 - val_loss: 0.5798\n",
            "Epoch 19/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7285 - auc_22: 0.5905 - loss: 0.5846 - val_accuracy: 0.7426 - val_auc_22: 0.7007 - val_loss: 0.5695\n",
            "Epoch 20/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7337 - auc_22: 0.6209 - loss: 0.5841 - val_accuracy: 0.7540 - val_auc_22: 0.6869 - val_loss: 0.5586\n",
            "Epoch 21/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7457 - auc_22: 0.6195 - loss: 0.5729 - val_accuracy: 0.7582 - val_auc_22: 0.7726 - val_loss: 0.5485\n",
            "Epoch 22/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7636 - auc_22: 0.6417 - loss: 0.5517 - val_accuracy: 0.7618 - val_auc_22: 0.6990 - val_loss: 0.5411\n",
            "Epoch 23/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7693 - auc_22: 0.6464 - loss: 0.5460 - val_accuracy: 0.7670 - val_auc_22: 0.7154 - val_loss: 0.5329\n",
            "Epoch 24/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7568 - auc_22: 0.6509 - loss: 0.5510 - val_accuracy: 0.7665 - val_auc_22: 0.7154 - val_loss: 0.5309\n",
            "Epoch 25/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7759 - auc_22: 0.6562 - loss: 0.5297 - val_accuracy: 0.7706 - val_auc_22: 0.7543 - val_loss: 0.5228\n",
            "Epoch 26/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7721 - auc_22: 0.6377 - loss: 0.5345 - val_accuracy: 0.7701 - val_auc_22: 0.7388 - val_loss: 0.5206\n",
            "Epoch 27/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7812 - auc_22: 0.6714 - loss: 0.5173 - val_accuracy: 0.7722 - val_auc_22: 0.7465 - val_loss: 0.5152\n",
            "Epoch 28/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7690 - auc_22: 0.6398 - loss: 0.5377 - val_accuracy: 0.7706 - val_auc_22: 0.7483 - val_loss: 0.5190\n",
            "Epoch 29/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7856 - auc_22: 0.6643 - loss: 0.5097 - val_accuracy: 0.7727 - val_auc_22: 0.7517 - val_loss: 0.5117\n",
            "Epoch 30/30\n",
            "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7712 - auc_22: 0.6469 - loss: 0.5345 - val_accuracy: 0.7743 - val_auc_22: 0.7656 - val_loss: 0.5080\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6133 - auc_23: 0.4941 - loss: 0.6634 - val_accuracy: 0.7020 - val_auc_23: 0.5043 - val_loss: 0.6095\n",
            "Epoch 2/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6983 - auc_23: 0.5231 - loss: 0.6183 - val_accuracy: 0.7020 - val_auc_23: 0.5043 - val_loss: 0.6092\n",
            "Epoch 3/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6886 - auc_23: 0.5243 - loss: 0.6242 - val_accuracy: 0.7020 - val_auc_23: 0.5121 - val_loss: 0.6091\n",
            "Epoch 4/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6875 - auc_23: 0.4769 - loss: 0.6374 - val_accuracy: 0.7020 - val_auc_23: 0.5251 - val_loss: 0.6089\n",
            "Epoch 5/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7037 - auc_23: 0.4951 - loss: 0.6208 - val_accuracy: 0.7020 - val_auc_23: 0.5043 - val_loss: 0.6094\n",
            "Epoch 6/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_23: 0.5131 - loss: 0.6132 - val_accuracy: 0.7020 - val_auc_23: 0.5251 - val_loss: 0.6087\n",
            "Epoch 7/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6832 - auc_23: 0.4756 - loss: 0.6367 - val_accuracy: 0.7020 - val_auc_23: 0.6412 - val_loss: 0.6086\n",
            "Epoch 8/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6922 - auc_23: 0.4948 - loss: 0.6267 - val_accuracy: 0.7020 - val_auc_23: 0.6603 - val_loss: 0.6089\n",
            "Epoch 9/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6950 - auc_23: 0.5001 - loss: 0.6234 - val_accuracy: 0.7020 - val_auc_23: 0.5598 - val_loss: 0.6085\n",
            "Epoch 10/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7016 - auc_23: 0.5007 - loss: 0.6188 - val_accuracy: 0.7020 - val_auc_23: 0.5953 - val_loss: 0.6076\n",
            "Epoch 11/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6908 - auc_23: 0.4972 - loss: 0.6265 - val_accuracy: 0.7020 - val_auc_23: 0.6161 - val_loss: 0.6079\n",
            "Epoch 12/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7035 - auc_23: 0.5403 - loss: 0.6097 - val_accuracy: 0.7020 - val_auc_23: 0.6023 - val_loss: 0.6055\n",
            "Epoch 13/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7167 - auc_23: 0.5405 - loss: 0.5956 - val_accuracy: 0.7020 - val_auc_23: 0.6118 - val_loss: 0.6033\n",
            "Epoch 14/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7038 - auc_23: 0.5383 - loss: 0.6091 - val_accuracy: 0.7020 - val_auc_23: 0.6984 - val_loss: 0.5996\n",
            "Epoch 15/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6840 - auc_23: 0.5486 - loss: 0.6210 - val_accuracy: 0.7020 - val_auc_23: 0.6941 - val_loss: 0.5937\n",
            "Epoch 16/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7196 - auc_23: 0.5778 - loss: 0.5866 - val_accuracy: 0.7128 - val_auc_23: 0.6681 - val_loss: 0.5832\n",
            "Epoch 17/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7229 - auc_23: 0.6057 - loss: 0.5860 - val_accuracy: 0.7386 - val_auc_23: 0.6958 - val_loss: 0.5716\n",
            "Epoch 18/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7440 - auc_23: 0.6119 - loss: 0.5757 - val_accuracy: 0.7490 - val_auc_23: 0.7808 - val_loss: 0.5583\n",
            "Epoch 19/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7608 - auc_23: 0.6230 - loss: 0.5605 - val_accuracy: 0.7577 - val_auc_23: 0.7002 - val_loss: 0.5473\n",
            "Epoch 20/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7602 - auc_23: 0.6422 - loss: 0.5526 - val_accuracy: 0.7619 - val_auc_23: 0.7062 - val_loss: 0.5383\n",
            "Epoch 21/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7705 - auc_23: 0.6258 - loss: 0.5428 - val_accuracy: 0.7665 - val_auc_23: 0.7478 - val_loss: 0.5310\n",
            "Epoch 22/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7646 - auc_23: 0.6538 - loss: 0.5431 - val_accuracy: 0.7655 - val_auc_23: 0.7875 - val_loss: 0.5333\n",
            "Epoch 23/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7716 - auc_23: 0.6624 - loss: 0.5332 - val_accuracy: 0.7701 - val_auc_23: 0.7487 - val_loss: 0.5212\n",
            "Epoch 24/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7858 - auc_23: 0.6567 - loss: 0.5211 - val_accuracy: 0.7712 - val_auc_23: 0.7747 - val_loss: 0.5175\n",
            "Epoch 25/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7696 - auc_23: 0.6689 - loss: 0.5296 - val_accuracy: 0.7712 - val_auc_23: 0.7652 - val_loss: 0.5157\n",
            "Epoch 26/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7833 - auc_23: 0.6378 - loss: 0.5219 - val_accuracy: 0.7712 - val_auc_23: 0.7908 - val_loss: 0.5150\n",
            "Epoch 27/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7860 - auc_23: 0.6486 - loss: 0.5157 - val_accuracy: 0.7769 - val_auc_23: 0.7799 - val_loss: 0.5094\n",
            "Epoch 28/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7809 - auc_23: 0.6379 - loss: 0.5234 - val_accuracy: 0.7738 - val_auc_23: 0.7582 - val_loss: 0.5080\n",
            "Epoch 29/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7760 - auc_23: 0.6619 - loss: 0.5219 - val_accuracy: 0.7769 - val_auc_23: 0.7808 - val_loss: 0.5041\n",
            "Epoch 30/30\n",
            "\u001b[1m452/452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7812 - auc_23: 0.6697 - loss: 0.5154 - val_accuracy: 0.7769 - val_auc_23: 0.7773 - val_loss: 0.5045\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5798 - auc_24: 0.5125 - loss: 0.6752 - val_accuracy: 0.6999 - val_auc_24: 0.5000 - val_loss: 0.6125\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6910 - auc_24: 0.4948 - loss: 0.6305 - val_accuracy: 0.6999 - val_auc_24: 0.5000 - val_loss: 0.6107\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6962 - auc_24: 0.5076 - loss: 0.6215 - val_accuracy: 0.6999 - val_auc_24: 0.5052 - val_loss: 0.6110\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7035 - auc_24: 0.4854 - loss: 0.6209 - val_accuracy: 0.6999 - val_auc_24: 0.6291 - val_loss: 0.6105\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6898 - auc_24: 0.4840 - loss: 0.6317 - val_accuracy: 0.6999 - val_auc_24: 0.5607 - val_loss: 0.6104\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6997 - auc_24: 0.5126 - loss: 0.6196 - val_accuracy: 0.6999 - val_auc_24: 0.5355 - val_loss: 0.6103\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6919 - auc_24: 0.4913 - loss: 0.6273 - val_accuracy: 0.6999 - val_auc_24: 0.5884 - val_loss: 0.6100\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7070 - auc_24: 0.5023 - loss: 0.6122 - val_accuracy: 0.6999 - val_auc_24: 0.5633 - val_loss: 0.6096\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6902 - auc_24: 0.5099 - loss: 0.6252 - val_accuracy: 0.6999 - val_auc_24: 0.5953 - val_loss: 0.6094\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6967 - auc_24: 0.5059 - loss: 0.6193 - val_accuracy: 0.6999 - val_auc_24: 0.6014 - val_loss: 0.6085\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7157 - auc_24: 0.5038 - loss: 0.6049 - val_accuracy: 0.6999 - val_auc_24: 0.6040 - val_loss: 0.6076\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6968 - auc_24: 0.5192 - loss: 0.6162 - val_accuracy: 0.6999 - val_auc_24: 0.6430 - val_loss: 0.6056\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6914 - auc_24: 0.5426 - loss: 0.6167 - val_accuracy: 0.6999 - val_auc_24: 0.6274 - val_loss: 0.6025\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6918 - auc_24: 0.5375 - loss: 0.6169 - val_accuracy: 0.6999 - val_auc_24: 0.6915 - val_loss: 0.5980\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7087 - auc_24: 0.5841 - loss: 0.5939 - val_accuracy: 0.6999 - val_auc_24: 0.6742 - val_loss: 0.5899\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7147 - auc_24: 0.5847 - loss: 0.5908 - val_accuracy: 0.7301 - val_auc_24: 0.6742 - val_loss: 0.5792\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7344 - auc_24: 0.6001 - loss: 0.5792 - val_accuracy: 0.7462 - val_auc_24: 0.7806 - val_loss: 0.5664\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7414 - auc_24: 0.6061 - loss: 0.5792 - val_accuracy: 0.7551 - val_auc_24: 0.7383 - val_loss: 0.5537\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7578 - auc_24: 0.6363 - loss: 0.5599 - val_accuracy: 0.7629 - val_auc_24: 0.7392 - val_loss: 0.5418\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7640 - auc_24: 0.6257 - loss: 0.5507 - val_accuracy: 0.7665 - val_auc_24: 0.7166 - val_loss: 0.5330\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7637 - auc_24: 0.6338 - loss: 0.5498 - val_accuracy: 0.7712 - val_auc_24: 0.7114 - val_loss: 0.5258\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7695 - auc_24: 0.6433 - loss: 0.5377 - val_accuracy: 0.7748 - val_auc_24: 0.7383 - val_loss: 0.5204\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7645 - auc_24: 0.6428 - loss: 0.5409 - val_accuracy: 0.7748 - val_auc_24: 0.7253 - val_loss: 0.5171\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7772 - auc_24: 0.6703 - loss: 0.5214 - val_accuracy: 0.7759 - val_auc_24: 0.7827 - val_loss: 0.5121\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7692 - auc_24: 0.6670 - loss: 0.5287 - val_accuracy: 0.7790 - val_auc_24: 0.7496 - val_loss: 0.5082\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7732 - auc_24: 0.6772 - loss: 0.5221 - val_accuracy: 0.7785 - val_auc_24: 0.7582 - val_loss: 0.5064\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7924 - auc_24: 0.6447 - loss: 0.5102 - val_accuracy: 0.7790 - val_auc_24: 0.7826 - val_loss: 0.5038\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7747 - auc_24: 0.6514 - loss: 0.5262 - val_accuracy: 0.7795 - val_auc_24: 0.7478 - val_loss: 0.5032\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7707 - auc_24: 0.6699 - loss: 0.5254 - val_accuracy: 0.7795 - val_auc_24: 0.7548 - val_loss: 0.4998\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7837 - auc_24: 0.6659 - loss: 0.5145 - val_accuracy: 0.7826 - val_auc_24: 0.7660 - val_loss: 0.4967\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6926 - auc_25: 0.4894 - loss: 0.6286 - val_accuracy: 0.7010 - val_auc_25: 0.5000 - val_loss: 0.6100\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6829 - auc_25: 0.4855 - loss: 0.6360 - val_accuracy: 0.7010 - val_auc_25: 0.5096 - val_loss: 0.6101\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6919 - auc_25: 0.5043 - loss: 0.6283 - val_accuracy: 0.7010 - val_auc_25: 0.5043 - val_loss: 0.6101\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7018 - auc_25: 0.5101 - loss: 0.6184 - val_accuracy: 0.7010 - val_auc_25: 0.5122 - val_loss: 0.6098\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_25: 0.4934 - loss: 0.6239 - val_accuracy: 0.7010 - val_auc_25: 0.5757 - val_loss: 0.6098\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7023 - auc_25: 0.5021 - loss: 0.6186 - val_accuracy: 0.7010 - val_auc_25: 0.5626 - val_loss: 0.6095\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7049 - auc_25: 0.4981 - loss: 0.6159 - val_accuracy: 0.7010 - val_auc_25: 0.5861 - val_loss: 0.6093\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7143 - auc_25: 0.4945 - loss: 0.6077 - val_accuracy: 0.7010 - val_auc_25: 0.5783 - val_loss: 0.6092\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6968 - auc_25: 0.4981 - loss: 0.6198 - val_accuracy: 0.7010 - val_auc_25: 0.5730 - val_loss: 0.6088\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7047 - auc_25: 0.5061 - loss: 0.6133 - val_accuracy: 0.7010 - val_auc_25: 0.5730 - val_loss: 0.6084\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6995 - auc_25: 0.5128 - loss: 0.6165 - val_accuracy: 0.7010 - val_auc_25: 0.5861 - val_loss: 0.6082\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6973 - auc_25: 0.5174 - loss: 0.6183 - val_accuracy: 0.7010 - val_auc_25: 0.6165 - val_loss: 0.6064\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7028 - auc_25: 0.5187 - loss: 0.6120 - val_accuracy: 0.7010 - val_auc_25: 0.6113 - val_loss: 0.6046\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7019 - auc_25: 0.5330 - loss: 0.6094 - val_accuracy: 0.7010 - val_auc_25: 0.6157 - val_loss: 0.6012\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7017 - auc_25: 0.5572 - loss: 0.6045 - val_accuracy: 0.7010 - val_auc_25: 0.6304 - val_loss: 0.5960\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6930 - auc_25: 0.5817 - loss: 0.6081 - val_accuracy: 0.7010 - val_auc_25: 0.7365 - val_loss: 0.5877\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7039 - auc_25: 0.6164 - loss: 0.5969 - val_accuracy: 0.7353 - val_auc_25: 0.6887 - val_loss: 0.5775\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7244 - auc_25: 0.6186 - loss: 0.5838 - val_accuracy: 0.7462 - val_auc_25: 0.6809 - val_loss: 0.5634\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7584 - auc_25: 0.6153 - loss: 0.5632 - val_accuracy: 0.7592 - val_auc_25: 0.7226 - val_loss: 0.5526\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7705 - auc_25: 0.6217 - loss: 0.5557 - val_accuracy: 0.7598 - val_auc_25: 0.6983 - val_loss: 0.5434\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7725 - auc_25: 0.6508 - loss: 0.5424 - val_accuracy: 0.7650 - val_auc_25: 0.7209 - val_loss: 0.5361\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - auc_25: 0.6572 - loss: 0.5326 - val_accuracy: 0.7686 - val_auc_25: 0.7113 - val_loss: 0.5296\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - auc_25: 0.6372 - loss: 0.5471 - val_accuracy: 0.7676 - val_auc_25: 0.7478 - val_loss: 0.5318\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7718 - auc_25: 0.6423 - loss: 0.5403 - val_accuracy: 0.7686 - val_auc_25: 0.7217 - val_loss: 0.5279\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7847 - auc_25: 0.6499 - loss: 0.5185 - val_accuracy: 0.7707 - val_auc_25: 0.7924 - val_loss: 0.5172\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7733 - auc_25: 0.6395 - loss: 0.5348 - val_accuracy: 0.7717 - val_auc_25: 0.7478 - val_loss: 0.5139\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7849 - auc_25: 0.6567 - loss: 0.5205 - val_accuracy: 0.7717 - val_auc_25: 0.7409 - val_loss: 0.5126\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7858 - auc_25: 0.6919 - loss: 0.5043 - val_accuracy: 0.7717 - val_auc_25: 0.7365 - val_loss: 0.5109\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7894 - auc_25: 0.6768 - loss: 0.5053 - val_accuracy: 0.7811 - val_auc_25: 0.7742 - val_loss: 0.5050\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7739 - auc_25: 0.6674 - loss: 0.5233 - val_accuracy: 0.7785 - val_auc_25: 0.7806 - val_loss: 0.5045\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6383 - auc_26: 0.5062 - loss: 0.6526 - val_accuracy: 0.6995 - val_auc_26: 0.5000 - val_loss: 0.6113\n",
            "Epoch 2/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6984 - auc_26: 0.4968 - loss: 0.6243 - val_accuracy: 0.6995 - val_auc_26: 0.5000 - val_loss: 0.6112\n",
            "Epoch 3/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6812 - auc_26: 0.4811 - loss: 0.6367 - val_accuracy: 0.6995 - val_auc_26: 0.5000 - val_loss: 0.6112\n",
            "Epoch 4/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6893 - auc_26: 0.5109 - loss: 0.6273 - val_accuracy: 0.6995 - val_auc_26: 0.5616 - val_loss: 0.6110\n",
            "Epoch 5/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6838 - auc_26: 0.4973 - loss: 0.6355 - val_accuracy: 0.6995 - val_auc_26: 0.5790 - val_loss: 0.6111\n",
            "Epoch 6/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6912 - auc_26: 0.4931 - loss: 0.6271 - val_accuracy: 0.6995 - val_auc_26: 0.5087 - val_loss: 0.6108\n",
            "Epoch 7/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6829 - auc_26: 0.4962 - loss: 0.6341 - val_accuracy: 0.6995 - val_auc_26: 0.5269 - val_loss: 0.6114\n",
            "Epoch 8/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6961 - auc_26: 0.4916 - loss: 0.6244 - val_accuracy: 0.6995 - val_auc_26: 0.6050 - val_loss: 0.6106\n",
            "Epoch 9/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6915 - auc_26: 0.4860 - loss: 0.6310 - val_accuracy: 0.6995 - val_auc_26: 0.5469 - val_loss: 0.6107\n",
            "Epoch 10/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6973 - auc_26: 0.5125 - loss: 0.6185 - val_accuracy: 0.6995 - val_auc_26: 0.5642 - val_loss: 0.6101\n",
            "Epoch 11/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6983 - auc_26: 0.4899 - loss: 0.6223 - val_accuracy: 0.6995 - val_auc_26: 0.6102 - val_loss: 0.6095\n",
            "Epoch 12/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7038 - auc_26: 0.5195 - loss: 0.6109 - val_accuracy: 0.6995 - val_auc_26: 0.6181 - val_loss: 0.6088\n",
            "Epoch 13/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_26: 0.4977 - loss: 0.6188 - val_accuracy: 0.6995 - val_auc_26: 0.6589 - val_loss: 0.6077\n",
            "Epoch 14/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6909 - auc_26: 0.5152 - loss: 0.6217 - val_accuracy: 0.6995 - val_auc_26: 0.6207 - val_loss: 0.6059\n",
            "Epoch 15/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7097 - auc_26: 0.5230 - loss: 0.6056 - val_accuracy: 0.6995 - val_auc_26: 0.6545 - val_loss: 0.6032\n",
            "Epoch 16/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7142 - auc_26: 0.5231 - loss: 0.6006 - val_accuracy: 0.6995 - val_auc_26: 0.6667 - val_loss: 0.5995\n",
            "Epoch 17/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6992 - auc_26: 0.5773 - loss: 0.6028 - val_accuracy: 0.6995 - val_auc_26: 0.6589 - val_loss: 0.5919\n",
            "Epoch 18/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6944 - auc_26: 0.5573 - loss: 0.6106 - val_accuracy: 0.6995 - val_auc_26: 0.7361 - val_loss: 0.5822\n",
            "Epoch 19/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7150 - auc_26: 0.6121 - loss: 0.5867 - val_accuracy: 0.7480 - val_auc_26: 0.6753 - val_loss: 0.5697\n",
            "Epoch 20/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7461 - auc_26: 0.6151 - loss: 0.5728 - val_accuracy: 0.7626 - val_auc_26: 0.6936 - val_loss: 0.5566\n",
            "Epoch 21/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7600 - auc_26: 0.6325 - loss: 0.5624 - val_accuracy: 0.7663 - val_auc_26: 0.7049 - val_loss: 0.5450\n",
            "Epoch 22/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7622 - auc_26: 0.6195 - loss: 0.5591 - val_accuracy: 0.7679 - val_auc_26: 0.6979 - val_loss: 0.5337\n",
            "Epoch 23/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7651 - auc_26: 0.6351 - loss: 0.5507 - val_accuracy: 0.7720 - val_auc_26: 0.7724 - val_loss: 0.5250\n",
            "Epoch 24/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7717 - auc_26: 0.6438 - loss: 0.5383 - val_accuracy: 0.7741 - val_auc_26: 0.7543 - val_loss: 0.5189\n",
            "Epoch 25/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7746 - auc_26: 0.6520 - loss: 0.5315 - val_accuracy: 0.7757 - val_auc_26: 0.7887 - val_loss: 0.5142\n",
            "Epoch 26/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7694 - auc_26: 0.6479 - loss: 0.5343 - val_accuracy: 0.7783 - val_auc_26: 0.7604 - val_loss: 0.5097\n",
            "Epoch 27/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7667 - auc_26: 0.6704 - loss: 0.5322 - val_accuracy: 0.7783 - val_auc_26: 0.7500 - val_loss: 0.5068\n",
            "Epoch 28/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7838 - auc_26: 0.6653 - loss: 0.5171 - val_accuracy: 0.7788 - val_auc_26: 0.7500 - val_loss: 0.5039\n",
            "Epoch 29/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7785 - auc_26: 0.6602 - loss: 0.5212 - val_accuracy: 0.7799 - val_auc_26: 0.7856 - val_loss: 0.5029\n",
            "Epoch 30/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7725 - auc_26: 0.6600 - loss: 0.5264 - val_accuracy: 0.7793 - val_auc_26: 0.7578 - val_loss: 0.5034\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6906 - auc_27: 0.4831 - loss: 0.6284 - val_accuracy: 0.7035 - val_auc_27: 0.5104 - val_loss: 0.6081\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7034 - auc_27: 0.5145 - loss: 0.6147 - val_accuracy: 0.7035 - val_auc_27: 0.5000 - val_loss: 0.6078\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6967 - auc_27: 0.4748 - loss: 0.6277 - val_accuracy: 0.7035 - val_auc_27: 0.5139 - val_loss: 0.6078\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - auc_27: 0.5054 - loss: 0.6102 - val_accuracy: 0.7035 - val_auc_27: 0.5095 - val_loss: 0.6077\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6961 - auc_27: 0.5104 - loss: 0.6190 - val_accuracy: 0.7035 - val_auc_27: 0.5035 - val_loss: 0.6075\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7104 - auc_27: 0.4963 - loss: 0.6095 - val_accuracy: 0.7035 - val_auc_27: 0.5537 - val_loss: 0.6074\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7050 - auc_27: 0.4979 - loss: 0.6135 - val_accuracy: 0.7035 - val_auc_27: 0.6161 - val_loss: 0.6071\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7225 - auc_27: 0.4761 - loss: 0.6024 - val_accuracy: 0.7035 - val_auc_27: 0.5797 - val_loss: 0.6076\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7044 - auc_27: 0.4983 - loss: 0.6136 - val_accuracy: 0.7035 - val_auc_27: 0.5685 - val_loss: 0.6067\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6915 - auc_27: 0.5287 - loss: 0.6189 - val_accuracy: 0.7035 - val_auc_27: 0.6023 - val_loss: 0.6059\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7065 - auc_27: 0.5420 - loss: 0.6031 - val_accuracy: 0.7035 - val_auc_27: 0.5953 - val_loss: 0.6045\n",
            "Epoch 12/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7155 - auc_27: 0.5095 - loss: 0.6011 - val_accuracy: 0.7035 - val_auc_27: 0.6317 - val_loss: 0.6031\n",
            "Epoch 13/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6972 - auc_27: 0.5119 - loss: 0.6163 - val_accuracy: 0.7035 - val_auc_27: 0.7010 - val_loss: 0.5998\n",
            "Epoch 14/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6989 - auc_27: 0.5498 - loss: 0.6082 - val_accuracy: 0.7035 - val_auc_27: 0.7704 - val_loss: 0.5954\n",
            "Epoch 15/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6993 - auc_27: 0.5811 - loss: 0.6024 - val_accuracy: 0.7035 - val_auc_27: 0.6395 - val_loss: 0.5900\n",
            "Epoch 16/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7060 - auc_27: 0.6165 - loss: 0.5910 - val_accuracy: 0.7035 - val_auc_27: 0.7400 - val_loss: 0.5801\n",
            "Epoch 17/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7154 - auc_27: 0.6466 - loss: 0.5847 - val_accuracy: 0.7410 - val_auc_27: 0.6750 - val_loss: 0.5706\n",
            "Epoch 18/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7315 - auc_27: 0.6246 - loss: 0.5776 - val_accuracy: 0.7533 - val_auc_27: 0.7811 - val_loss: 0.5590\n",
            "Epoch 19/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7613 - auc_27: 0.6363 - loss: 0.5569 - val_accuracy: 0.7595 - val_auc_27: 0.7314 - val_loss: 0.5497\n",
            "Epoch 20/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7663 - auc_27: 0.6434 - loss: 0.5502 - val_accuracy: 0.7631 - val_auc_27: 0.7400 - val_loss: 0.5415\n",
            "Epoch 21/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7674 - auc_27: 0.6346 - loss: 0.5520 - val_accuracy: 0.7641 - val_auc_27: 0.7392 - val_loss: 0.5355\n",
            "Epoch 22/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7787 - auc_27: 0.6603 - loss: 0.5306 - val_accuracy: 0.7662 - val_auc_27: 0.7660 - val_loss: 0.5304\n",
            "Epoch 23/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7751 - auc_27: 0.6285 - loss: 0.5400 - val_accuracy: 0.7662 - val_auc_27: 0.7652 - val_loss: 0.5310\n",
            "Epoch 24/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7796 - auc_27: 0.6603 - loss: 0.5274 - val_accuracy: 0.7682 - val_auc_27: 0.7236 - val_loss: 0.5261\n",
            "Epoch 25/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - auc_27: 0.6379 - loss: 0.5318 - val_accuracy: 0.7724 - val_auc_27: 0.7426 - val_loss: 0.5187\n",
            "Epoch 26/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7771 - auc_27: 0.6511 - loss: 0.5285 - val_accuracy: 0.7718 - val_auc_27: 0.7400 - val_loss: 0.5206\n",
            "Epoch 27/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7896 - auc_27: 0.6687 - loss: 0.5116 - val_accuracy: 0.7724 - val_auc_27: 0.7883 - val_loss: 0.5176\n",
            "Epoch 28/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7770 - auc_27: 0.6575 - loss: 0.5236 - val_accuracy: 0.7739 - val_auc_27: 0.7850 - val_loss: 0.5138\n",
            "Epoch 29/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7817 - auc_27: 0.6652 - loss: 0.5171 - val_accuracy: 0.7744 - val_auc_27: 0.7970 - val_loss: 0.5116\n",
            "Epoch 30/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7907 - auc_27: 0.6777 - loss: 0.5053 - val_accuracy: 0.7765 - val_auc_27: 0.7900 - val_loss: 0.5060\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6131 - auc_28: 0.5041 - loss: 0.6647 - val_accuracy: 0.7043 - val_auc_28: 0.5026 - val_loss: 0.6076\n",
            "Epoch 2/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6974 - auc_28: 0.5205 - loss: 0.6181 - val_accuracy: 0.7043 - val_auc_28: 0.5026 - val_loss: 0.6073\n",
            "Epoch 3/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_28: 0.4847 - loss: 0.6233 - val_accuracy: 0.7043 - val_auc_28: 0.6259 - val_loss: 0.6070\n",
            "Epoch 4/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6981 - auc_28: 0.4935 - loss: 0.6231 - val_accuracy: 0.7043 - val_auc_28: 0.5356 - val_loss: 0.6079\n",
            "Epoch 5/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7052 - auc_28: 0.5036 - loss: 0.6163 - val_accuracy: 0.7043 - val_auc_28: 0.5026 - val_loss: 0.6068\n",
            "Epoch 6/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7115 - auc_28: 0.5001 - loss: 0.6090 - val_accuracy: 0.7043 - val_auc_28: 0.5625 - val_loss: 0.6067\n",
            "Epoch 7/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6942 - auc_28: 0.5085 - loss: 0.6207 - val_accuracy: 0.7043 - val_auc_28: 0.6137 - val_loss: 0.6067\n",
            "Epoch 8/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6976 - auc_28: 0.5251 - loss: 0.6155 - val_accuracy: 0.7043 - val_auc_28: 0.5938 - val_loss: 0.6062\n",
            "Epoch 9/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7008 - auc_28: 0.4987 - loss: 0.6184 - val_accuracy: 0.7043 - val_auc_28: 0.5677 - val_loss: 0.6062\n",
            "Epoch 10/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7119 - auc_28: 0.5188 - loss: 0.6047 - val_accuracy: 0.7043 - val_auc_28: 0.5938 - val_loss: 0.6051\n",
            "Epoch 11/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7141 - auc_28: 0.4923 - loss: 0.6082 - val_accuracy: 0.7043 - val_auc_28: 0.6224 - val_loss: 0.6051\n",
            "Epoch 12/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6974 - auc_28: 0.5178 - loss: 0.6184 - val_accuracy: 0.7043 - val_auc_28: 0.6146 - val_loss: 0.6034\n",
            "Epoch 13/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7187 - auc_28: 0.5353 - loss: 0.5956 - val_accuracy: 0.7043 - val_auc_28: 0.6372 - val_loss: 0.5994\n",
            "Epoch 14/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6979 - auc_28: 0.5528 - loss: 0.6101 - val_accuracy: 0.7043 - val_auc_28: 0.6424 - val_loss: 0.5943\n",
            "Epoch 15/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6958 - auc_28: 0.5767 - loss: 0.6073 - val_accuracy: 0.7043 - val_auc_28: 0.7031 - val_loss: 0.5866\n",
            "Epoch 16/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7098 - auc_28: 0.6047 - loss: 0.5921 - val_accuracy: 0.7248 - val_auc_28: 0.6788 - val_loss: 0.5762\n",
            "Epoch 17/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - auc_28: 0.6060 - loss: 0.5767 - val_accuracy: 0.7500 - val_auc_28: 0.6875 - val_loss: 0.5625\n",
            "Epoch 18/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7447 - auc_28: 0.6250 - loss: 0.5736 - val_accuracy: 0.7562 - val_auc_28: 0.6997 - val_loss: 0.5498\n",
            "Epoch 19/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7671 - auc_28: 0.6357 - loss: 0.5444 - val_accuracy: 0.7659 - val_auc_28: 0.7161 - val_loss: 0.5387\n",
            "Epoch 20/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7626 - auc_28: 0.6181 - loss: 0.5555 - val_accuracy: 0.7639 - val_auc_28: 0.7109 - val_loss: 0.5353\n",
            "Epoch 21/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7739 - auc_28: 0.6318 - loss: 0.5420 - val_accuracy: 0.7710 - val_auc_28: 0.7083 - val_loss: 0.5245\n",
            "Epoch 22/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7730 - auc_28: 0.6468 - loss: 0.5336 - val_accuracy: 0.7721 - val_auc_28: 0.7352 - val_loss: 0.5206\n",
            "Epoch 23/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7786 - auc_28: 0.6217 - loss: 0.5342 - val_accuracy: 0.7721 - val_auc_28: 0.7179 - val_loss: 0.5172\n",
            "Epoch 24/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7706 - auc_28: 0.6620 - loss: 0.5273 - val_accuracy: 0.7736 - val_auc_28: 0.7205 - val_loss: 0.5141\n",
            "Epoch 25/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7769 - auc_28: 0.6577 - loss: 0.5201 - val_accuracy: 0.7767 - val_auc_28: 0.7717 - val_loss: 0.5091\n",
            "Epoch 26/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7722 - auc_28: 0.6633 - loss: 0.5247 - val_accuracy: 0.7767 - val_auc_28: 0.7816 - val_loss: 0.5067\n",
            "Epoch 27/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7920 - auc_28: 0.6637 - loss: 0.5043 - val_accuracy: 0.7772 - val_auc_28: 0.7457 - val_loss: 0.5041\n",
            "Epoch 28/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7877 - auc_28: 0.6642 - loss: 0.5100 - val_accuracy: 0.7782 - val_auc_28: 0.7786 - val_loss: 0.5012\n",
            "Epoch 29/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7874 - auc_28: 0.6585 - loss: 0.5088 - val_accuracy: 0.7808 - val_auc_28: 0.7806 - val_loss: 0.4984\n",
            "Epoch 30/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7833 - auc_28: 0.6714 - loss: 0.5133 - val_accuracy: 0.7782 - val_auc_28: 0.7561 - val_loss: 0.5007\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6766 - auc_29: 0.5062 - loss: 0.6347 - val_accuracy: 0.7010 - val_auc_29: 0.5000 - val_loss: 0.6100\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7000 - auc_29: 0.4855 - loss: 0.6220 - val_accuracy: 0.7010 - val_auc_29: 0.5000 - val_loss: 0.6101\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7045 - auc_29: 0.4944 - loss: 0.6183 - val_accuracy: 0.7010 - val_auc_29: 0.5052 - val_loss: 0.6101\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7012 - auc_29: 0.4905 - loss: 0.6204 - val_accuracy: 0.7010 - val_auc_29: 0.5809 - val_loss: 0.6098\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7058 - auc_29: 0.5069 - loss: 0.6109 - val_accuracy: 0.7010 - val_auc_29: 0.5000 - val_loss: 0.6098\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_29: 0.4917 - loss: 0.6133 - val_accuracy: 0.7010 - val_auc_29: 0.5157 - val_loss: 0.6099\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_29: 0.4950 - loss: 0.6176 - val_accuracy: 0.7010 - val_auc_29: 0.6070 - val_loss: 0.6096\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6917 - auc_29: 0.5047 - loss: 0.6224 - val_accuracy: 0.7010 - val_auc_29: 0.5539 - val_loss: 0.6094\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7038 - auc_29: 0.5116 - loss: 0.6110 - val_accuracy: 0.7010 - val_auc_29: 0.5739 - val_loss: 0.6092\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_29: 0.4897 - loss: 0.6156 - val_accuracy: 0.7010 - val_auc_29: 0.5765 - val_loss: 0.6088\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6954 - auc_29: 0.5339 - loss: 0.6149 - val_accuracy: 0.7010 - val_auc_29: 0.6461 - val_loss: 0.6085\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6976 - auc_29: 0.5263 - loss: 0.6133 - val_accuracy: 0.7010 - val_auc_29: 0.6017 - val_loss: 0.6074\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6986 - auc_29: 0.5296 - loss: 0.6126 - val_accuracy: 0.7010 - val_auc_29: 0.6409 - val_loss: 0.6061\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7023 - auc_29: 0.5473 - loss: 0.6061 - val_accuracy: 0.7010 - val_auc_29: 0.6565 - val_loss: 0.6038\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7027 - auc_29: 0.5385 - loss: 0.6072 - val_accuracy: 0.7010 - val_auc_29: 0.6409 - val_loss: 0.5998\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7119 - auc_29: 0.5066 - loss: 0.6027 - val_accuracy: 0.7010 - val_auc_29: 0.6461 - val_loss: 0.5939\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7039 - auc_29: 0.6027 - loss: 0.5940 - val_accuracy: 0.7010 - val_auc_29: 0.6896 - val_loss: 0.5828\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7206 - auc_29: 0.5997 - loss: 0.5836 - val_accuracy: 0.7493 - val_auc_29: 0.6983 - val_loss: 0.5670\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7479 - auc_29: 0.6322 - loss: 0.5697 - val_accuracy: 0.7577 - val_auc_29: 0.6965 - val_loss: 0.5504\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7601 - auc_29: 0.6343 - loss: 0.5560 - val_accuracy: 0.7665 - val_auc_29: 0.7779 - val_loss: 0.5371\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7669 - auc_29: 0.6365 - loss: 0.5493 - val_accuracy: 0.7696 - val_auc_29: 0.7417 - val_loss: 0.5285\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7599 - auc_29: 0.6318 - loss: 0.5520 - val_accuracy: 0.7717 - val_auc_29: 0.7513 - val_loss: 0.5241\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7804 - auc_29: 0.6679 - loss: 0.5219 - val_accuracy: 0.7738 - val_auc_29: 0.7270 - val_loss: 0.5164\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7742 - auc_29: 0.6590 - loss: 0.5283 - val_accuracy: 0.7738 - val_auc_29: 0.7235 - val_loss: 0.5159\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7782 - auc_29: 0.6627 - loss: 0.5212 - val_accuracy: 0.7759 - val_auc_29: 0.7833 - val_loss: 0.5089\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7803 - auc_29: 0.6450 - loss: 0.5228 - val_accuracy: 0.7774 - val_auc_29: 0.7478 - val_loss: 0.5050\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7749 - auc_29: 0.6708 - loss: 0.5220 - val_accuracy: 0.7800 - val_auc_29: 0.8010 - val_loss: 0.5015\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7901 - auc_29: 0.6619 - loss: 0.5057 - val_accuracy: 0.7790 - val_auc_29: 0.7775 - val_loss: 0.5005\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7711 - auc_29: 0.6496 - loss: 0.5281 - val_accuracy: 0.7821 - val_auc_29: 0.7687 - val_loss: 0.4977\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7832 - auc_29: 0.6755 - loss: 0.5122 - val_accuracy: 0.7868 - val_auc_29: 0.8054 - val_loss: 0.4932\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7003 - auc_30: 0.4921 - loss: 0.6349 - val_accuracy: 0.6993 - val_auc_30: 0.5000 - val_loss: 0.6114\n",
            "Epoch 2/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7012 - auc_30: 0.5087 - loss: 0.6164 - val_accuracy: 0.6993 - val_auc_30: 0.5141 - val_loss: 0.6114\n",
            "Epoch 3/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6952 - auc_30: 0.5038 - loss: 0.6229 - val_accuracy: 0.6993 - val_auc_30: 0.5000 - val_loss: 0.6113\n",
            "Epoch 4/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6944 - auc_30: 0.5055 - loss: 0.6225 - val_accuracy: 0.6993 - val_auc_30: 0.5070 - val_loss: 0.6113\n",
            "Epoch 5/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7119 - auc_30: 0.5119 - loss: 0.6060 - val_accuracy: 0.6993 - val_auc_30: 0.5070 - val_loss: 0.6115\n",
            "Epoch 6/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7103 - auc_30: 0.4986 - loss: 0.6086 - val_accuracy: 0.6993 - val_auc_30: 0.5141 - val_loss: 0.6114\n",
            "Epoch 7/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7059 - auc_30: 0.4970 - loss: 0.6116 - val_accuracy: 0.6993 - val_auc_30: 0.5228 - val_loss: 0.6113\n",
            "Epoch 8/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7047 - auc_30: 0.4953 - loss: 0.6139 - val_accuracy: 0.6993 - val_auc_30: 0.5562 - val_loss: 0.6110\n",
            "Epoch 9/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7011 - auc_30: 0.5103 - loss: 0.6135 - val_accuracy: 0.6993 - val_auc_30: 0.5756 - val_loss: 0.6105\n",
            "Epoch 10/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6819 - auc_30: 0.5027 - loss: 0.6298 - val_accuracy: 0.6993 - val_auc_30: 0.5518 - val_loss: 0.6103\n",
            "Epoch 11/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6938 - auc_30: 0.5054 - loss: 0.6205 - val_accuracy: 0.6993 - val_auc_30: 0.6019 - val_loss: 0.6097\n",
            "Epoch 12/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6989 - auc_30: 0.5081 - loss: 0.6154 - val_accuracy: 0.6993 - val_auc_30: 0.6169 - val_loss: 0.6087\n",
            "Epoch 13/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6989 - auc_30: 0.5232 - loss: 0.6131 - val_accuracy: 0.6993 - val_auc_30: 0.6134 - val_loss: 0.6075\n",
            "Epoch 14/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6968 - auc_30: 0.5172 - loss: 0.6146 - val_accuracy: 0.6993 - val_auc_30: 0.6397 - val_loss: 0.6053\n",
            "Epoch 15/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7070 - auc_30: 0.5472 - loss: 0.6010 - val_accuracy: 0.6993 - val_auc_30: 0.7039 - val_loss: 0.6021\n",
            "Epoch 16/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7063 - auc_30: 0.5749 - loss: 0.5976 - val_accuracy: 0.6993 - val_auc_30: 0.6942 - val_loss: 0.5983\n",
            "Epoch 17/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6995 - auc_30: 0.6084 - loss: 0.5971 - val_accuracy: 0.6993 - val_auc_30: 0.6749 - val_loss: 0.5904\n",
            "Epoch 18/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7066 - auc_30: 0.5707 - loss: 0.5972 - val_accuracy: 0.7246 - val_auc_30: 0.7663 - val_loss: 0.5815\n",
            "Epoch 19/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7273 - auc_30: 0.6257 - loss: 0.5822 - val_accuracy: 0.7368 - val_auc_30: 0.7021 - val_loss: 0.5721\n",
            "Epoch 20/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7585 - auc_30: 0.6305 - loss: 0.5604 - val_accuracy: 0.7500 - val_auc_30: 0.7775 - val_loss: 0.5628\n",
            "Epoch 21/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7565 - auc_30: 0.6281 - loss: 0.5636 - val_accuracy: 0.7516 - val_auc_30: 0.7876 - val_loss: 0.5552\n",
            "Epoch 22/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7684 - auc_30: 0.6279 - loss: 0.5537 - val_accuracy: 0.7611 - val_auc_30: 0.7021 - val_loss: 0.5483\n",
            "Epoch 23/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7675 - auc_30: 0.6293 - loss: 0.5571 - val_accuracy: 0.7622 - val_auc_30: 0.7021 - val_loss: 0.5430\n",
            "Epoch 24/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7684 - auc_30: 0.6561 - loss: 0.5469 - val_accuracy: 0.7637 - val_auc_30: 0.7417 - val_loss: 0.5391\n",
            "Epoch 25/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7712 - auc_30: 0.6605 - loss: 0.5414 - val_accuracy: 0.7669 - val_auc_30: 0.7592 - val_loss: 0.5334\n",
            "Epoch 26/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7737 - auc_30: 0.6548 - loss: 0.5382 - val_accuracy: 0.7674 - val_auc_30: 0.7776 - val_loss: 0.5303\n",
            "Epoch 27/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7835 - auc_30: 0.6796 - loss: 0.5245 - val_accuracy: 0.7696 - val_auc_30: 0.7417 - val_loss: 0.5269\n",
            "Epoch 28/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7783 - auc_30: 0.6624 - loss: 0.5331 - val_accuracy: 0.7701 - val_auc_30: 0.7707 - val_loss: 0.5225\n",
            "Epoch 29/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7735 - auc_30: 0.6559 - loss: 0.5379 - val_accuracy: 0.7706 - val_auc_30: 0.7803 - val_loss: 0.5199\n",
            "Epoch 30/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7736 - auc_30: 0.6796 - loss: 0.5274 - val_accuracy: 0.7706 - val_auc_30: 0.8047 - val_loss: 0.5190\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6989 - auc_31: 0.5044 - loss: 0.6186 - val_accuracy: 0.7062 - val_auc_31: 0.5000 - val_loss: 0.6058\n",
            "Epoch 2/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7100 - auc_31: 0.5278 - loss: 0.6045 - val_accuracy: 0.7062 - val_auc_31: 0.5052 - val_loss: 0.6054\n",
            "Epoch 3/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7063 - auc_31: 0.4967 - loss: 0.6160 - val_accuracy: 0.7062 - val_auc_31: 0.5105 - val_loss: 0.6054\n",
            "Epoch 4/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7197 - auc_31: 0.4913 - loss: 0.6040 - val_accuracy: 0.7062 - val_auc_31: 0.6562 - val_loss: 0.6060\n",
            "Epoch 5/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6999 - auc_31: 0.5013 - loss: 0.6188 - val_accuracy: 0.7062 - val_auc_31: 0.5462 - val_loss: 0.6052\n",
            "Epoch 6/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7004 - auc_31: 0.5194 - loss: 0.6154 - val_accuracy: 0.7062 - val_auc_31: 0.5654 - val_loss: 0.6052\n",
            "Epoch 7/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7083 - auc_31: 0.4818 - loss: 0.6146 - val_accuracy: 0.7062 - val_auc_31: 0.6440 - val_loss: 0.6049\n",
            "Epoch 8/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7138 - auc_31: 0.5047 - loss: 0.6035 - val_accuracy: 0.7062 - val_auc_31: 0.5253 - val_loss: 0.6051\n",
            "Epoch 9/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7174 - auc_31: 0.5128 - loss: 0.5989 - val_accuracy: 0.7062 - val_auc_31: 0.6178 - val_loss: 0.6047\n",
            "Epoch 10/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_31: 0.4949 - loss: 0.6171 - val_accuracy: 0.7062 - val_auc_31: 0.5916 - val_loss: 0.6039\n",
            "Epoch 11/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6965 - auc_31: 0.4941 - loss: 0.6211 - val_accuracy: 0.7062 - val_auc_31: 0.6291 - val_loss: 0.6033\n",
            "Epoch 12/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7137 - auc_31: 0.5390 - loss: 0.5990 - val_accuracy: 0.7062 - val_auc_31: 0.6178 - val_loss: 0.6029\n",
            "Epoch 13/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7135 - auc_31: 0.5187 - loss: 0.6018 - val_accuracy: 0.7062 - val_auc_31: 0.6440 - val_loss: 0.6007\n",
            "Epoch 14/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_31: 0.5142 - loss: 0.6122 - val_accuracy: 0.7062 - val_auc_31: 0.6291 - val_loss: 0.5980\n",
            "Epoch 15/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7046 - auc_31: 0.5455 - loss: 0.6054 - val_accuracy: 0.7062 - val_auc_31: 0.7513 - val_loss: 0.5948\n",
            "Epoch 16/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7112 - auc_31: 0.5654 - loss: 0.5945 - val_accuracy: 0.7062 - val_auc_31: 0.6736 - val_loss: 0.5885\n",
            "Epoch 17/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7052 - auc_31: 0.5843 - loss: 0.5973 - val_accuracy: 0.7062 - val_auc_31: 0.7635 - val_loss: 0.5791\n",
            "Epoch 18/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7161 - auc_31: 0.6239 - loss: 0.5795 - val_accuracy: 0.7441 - val_auc_31: 0.7129 - val_loss: 0.5675\n",
            "Epoch 19/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7370 - auc_31: 0.6285 - loss: 0.5722 - val_accuracy: 0.7559 - val_auc_31: 0.7627 - val_loss: 0.5548\n",
            "Epoch 20/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7527 - auc_31: 0.6221 - loss: 0.5653 - val_accuracy: 0.7667 - val_auc_31: 0.7792 - val_loss: 0.5399\n",
            "Epoch 21/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7627 - auc_31: 0.6341 - loss: 0.5537 - val_accuracy: 0.7697 - val_auc_31: 0.7269 - val_loss: 0.5295\n",
            "Epoch 22/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7770 - auc_31: 0.6548 - loss: 0.5336 - val_accuracy: 0.7754 - val_auc_31: 0.7801 - val_loss: 0.5199\n",
            "Epoch 23/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7731 - auc_31: 0.6317 - loss: 0.5395 - val_accuracy: 0.7821 - val_auc_31: 0.7931 - val_loss: 0.5123\n",
            "Epoch 24/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7860 - auc_31: 0.6588 - loss: 0.5202 - val_accuracy: 0.7821 - val_auc_31: 0.7382 - val_loss: 0.5077\n",
            "Epoch 25/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7816 - auc_31: 0.6461 - loss: 0.5263 - val_accuracy: 0.7851 - val_auc_31: 0.7731 - val_loss: 0.5014\n",
            "Epoch 26/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7740 - auc_31: 0.6386 - loss: 0.5350 - val_accuracy: 0.7872 - val_auc_31: 0.7935 - val_loss: 0.4970\n",
            "Epoch 27/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7796 - auc_31: 0.6469 - loss: 0.5227 - val_accuracy: 0.7872 - val_auc_31: 0.7653 - val_loss: 0.4944\n",
            "Epoch 28/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - auc_31: 0.6815 - loss: 0.5116 - val_accuracy: 0.7887 - val_auc_31: 0.7705 - val_loss: 0.4898\n",
            "Epoch 29/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7861 - auc_31: 0.6640 - loss: 0.5119 - val_accuracy: 0.7903 - val_auc_31: 0.7837 - val_loss: 0.4873\n",
            "Epoch 30/30\n",
            "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7764 - auc_31: 0.6660 - loss: 0.5203 - val_accuracy: 0.7918 - val_auc_31: 0.7975 - val_loss: 0.4837\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6947 - auc_32: 0.5190 - loss: 0.6239 - val_accuracy: 0.7049 - val_auc_32: 0.5000 - val_loss: 0.6067\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6999 - auc_32: 0.4964 - loss: 0.6235 - val_accuracy: 0.7049 - val_auc_32: 0.5000 - val_loss: 0.6066\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7005 - auc_32: 0.5086 - loss: 0.6202 - val_accuracy: 0.7049 - val_auc_32: 0.5000 - val_loss: 0.6067\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7144 - auc_32: 0.4919 - loss: 0.6102 - val_accuracy: 0.7049 - val_auc_32: 0.5000 - val_loss: 0.6066\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7043 - auc_32: 0.4799 - loss: 0.6205 - val_accuracy: 0.7049 - val_auc_32: 0.5636 - val_loss: 0.6064\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7080 - auc_32: 0.5039 - loss: 0.6133 - val_accuracy: 0.7049 - val_auc_32: 0.5314 - val_loss: 0.6063\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7053 - auc_32: 0.5005 - loss: 0.6139 - val_accuracy: 0.7049 - val_auc_32: 0.5296 - val_loss: 0.6060\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7124 - auc_32: 0.5130 - loss: 0.6056 - val_accuracy: 0.7049 - val_auc_32: 0.5462 - val_loss: 0.6059\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7002 - auc_32: 0.4769 - loss: 0.6214 - val_accuracy: 0.7049 - val_auc_32: 0.6106 - val_loss: 0.6054\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7106 - auc_32: 0.5394 - loss: 0.6015 - val_accuracy: 0.7049 - val_auc_32: 0.6167 - val_loss: 0.6051\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7043 - auc_32: 0.5071 - loss: 0.6114 - val_accuracy: 0.7049 - val_auc_32: 0.6254 - val_loss: 0.6040\n",
            "Epoch 12/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6896 - auc_32: 0.5323 - loss: 0.6208 - val_accuracy: 0.7049 - val_auc_32: 0.6080 - val_loss: 0.6032\n",
            "Epoch 13/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7172 - auc_32: 0.5197 - loss: 0.5974 - val_accuracy: 0.7049 - val_auc_32: 0.6498 - val_loss: 0.6003\n",
            "Epoch 14/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7082 - auc_32: 0.5414 - loss: 0.6023 - val_accuracy: 0.7049 - val_auc_32: 0.6786 - val_loss: 0.5959\n",
            "Epoch 15/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7057 - auc_32: 0.5714 - loss: 0.5981 - val_accuracy: 0.7049 - val_auc_32: 0.6742 - val_loss: 0.5890\n",
            "Epoch 16/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7071 - auc_32: 0.5887 - loss: 0.5939 - val_accuracy: 0.7049 - val_auc_32: 0.6821 - val_loss: 0.5790\n",
            "Epoch 17/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7187 - auc_32: 0.5967 - loss: 0.5886 - val_accuracy: 0.7476 - val_auc_32: 0.7570 - val_loss: 0.5663\n",
            "Epoch 18/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7341 - auc_32: 0.6201 - loss: 0.5782 - val_accuracy: 0.7609 - val_auc_32: 0.7317 - val_loss: 0.5530\n",
            "Epoch 19/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7546 - auc_32: 0.6267 - loss: 0.5611 - val_accuracy: 0.7686 - val_auc_32: 0.7718 - val_loss: 0.5406\n",
            "Epoch 20/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7614 - auc_32: 0.6394 - loss: 0.5556 - val_accuracy: 0.7717 - val_auc_32: 0.7030 - val_loss: 0.5329\n",
            "Epoch 21/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7776 - auc_32: 0.6323 - loss: 0.5414 - val_accuracy: 0.7774 - val_auc_32: 0.7677 - val_loss: 0.5237\n",
            "Epoch 22/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7717 - auc_32: 0.6502 - loss: 0.5393 - val_accuracy: 0.7799 - val_auc_32: 0.7774 - val_loss: 0.5169\n",
            "Epoch 23/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7742 - auc_32: 0.6305 - loss: 0.5418 - val_accuracy: 0.7805 - val_auc_32: 0.7570 - val_loss: 0.5118\n",
            "Epoch 24/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7784 - auc_32: 0.6395 - loss: 0.5331 - val_accuracy: 0.7820 - val_auc_32: 0.7300 - val_loss: 0.5076\n",
            "Epoch 25/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7812 - auc_32: 0.6729 - loss: 0.5171 - val_accuracy: 0.7835 - val_auc_32: 0.7763 - val_loss: 0.5025\n",
            "Epoch 26/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7892 - auc_32: 0.6683 - loss: 0.5109 - val_accuracy: 0.7861 - val_auc_32: 0.7552 - val_loss: 0.4982\n",
            "Epoch 27/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7768 - auc_32: 0.6505 - loss: 0.5269 - val_accuracy: 0.7856 - val_auc_32: 0.7795 - val_loss: 0.4957\n",
            "Epoch 28/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7874 - auc_32: 0.6616 - loss: 0.5128 - val_accuracy: 0.7887 - val_auc_32: 0.7681 - val_loss: 0.4926\n",
            "Epoch 29/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7943 - auc_32: 0.6821 - loss: 0.5019 - val_accuracy: 0.7923 - val_auc_32: 0.7622 - val_loss: 0.4898\n",
            "Epoch 30/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7943 - auc_32: 0.6873 - loss: 0.4996 - val_accuracy: 0.7907 - val_auc_32: 0.7683 - val_loss: 0.4882\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.5835 - auc_33: 0.4995 - loss: 0.6812 - val_accuracy: 0.7033 - val_auc_33: 0.5009 - val_loss: 0.6080\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6982 - auc_33: 0.4903 - loss: 0.6220 - val_accuracy: 0.7033 - val_auc_33: 0.5000 - val_loss: 0.6079\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6970 - auc_33: 0.5007 - loss: 0.6232 - val_accuracy: 0.7033 - val_auc_33: 0.5018 - val_loss: 0.6080\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7114 - auc_33: 0.4804 - loss: 0.6136 - val_accuracy: 0.7033 - val_auc_33: 0.5018 - val_loss: 0.6079\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7012 - auc_33: 0.5001 - loss: 0.6179 - val_accuracy: 0.7033 - val_auc_33: 0.5026 - val_loss: 0.6077\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7157 - auc_33: 0.5069 - loss: 0.6046 - val_accuracy: 0.7033 - val_auc_33: 0.5123 - val_loss: 0.6076\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7024 - auc_33: 0.4777 - loss: 0.6206 - val_accuracy: 0.7033 - val_auc_33: 0.5412 - val_loss: 0.6075\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7118 - auc_33: 0.4932 - loss: 0.6081 - val_accuracy: 0.7033 - val_auc_33: 0.5842 - val_loss: 0.6070\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7033 - auc_33: 0.5121 - loss: 0.6128 - val_accuracy: 0.7033 - val_auc_33: 0.6500 - val_loss: 0.6066\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7040 - auc_33: 0.5017 - loss: 0.6145 - val_accuracy: 0.7033 - val_auc_33: 0.6167 - val_loss: 0.6058\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7004 - auc_33: 0.4984 - loss: 0.6178 - val_accuracy: 0.7033 - val_auc_33: 0.6965 - val_loss: 0.6045\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6994 - auc_33: 0.5423 - loss: 0.6099 - val_accuracy: 0.7033 - val_auc_33: 0.6930 - val_loss: 0.6021\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6967 - auc_33: 0.5457 - loss: 0.6110 - val_accuracy: 0.7033 - val_auc_33: 0.6667 - val_loss: 0.5984\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7078 - auc_33: 0.5634 - loss: 0.5993 - val_accuracy: 0.7033 - val_auc_33: 0.6833 - val_loss: 0.5918\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7005 - auc_33: 0.5754 - loss: 0.6021 - val_accuracy: 0.7033 - val_auc_33: 0.6746 - val_loss: 0.5813\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7254 - auc_33: 0.6195 - loss: 0.5806 - val_accuracy: 0.7486 - val_auc_33: 0.6868 - val_loss: 0.5664\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7507 - auc_33: 0.6597 - loss: 0.5600 - val_accuracy: 0.7569 - val_auc_33: 0.6886 - val_loss: 0.5541\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7630 - auc_33: 0.6283 - loss: 0.5572 - val_accuracy: 0.7631 - val_auc_33: 0.7140 - val_loss: 0.5403\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7751 - auc_33: 0.6426 - loss: 0.5389 - val_accuracy: 0.7704 - val_auc_33: 0.7570 - val_loss: 0.5304\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7734 - auc_33: 0.6440 - loss: 0.5389 - val_accuracy: 0.7715 - val_auc_33: 0.7535 - val_loss: 0.5230\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7648 - auc_33: 0.6365 - loss: 0.5445 - val_accuracy: 0.7710 - val_auc_33: 0.7535 - val_loss: 0.5240\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7823 - auc_33: 0.6711 - loss: 0.5176 - val_accuracy: 0.7736 - val_auc_33: 0.7905 - val_loss: 0.5140\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7789 - auc_33: 0.6759 - loss: 0.5189 - val_accuracy: 0.7762 - val_auc_33: 0.7491 - val_loss: 0.5080\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7780 - auc_33: 0.6730 - loss: 0.5192 - val_accuracy: 0.7751 - val_auc_33: 0.7819 - val_loss: 0.5138\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7846 - auc_33: 0.6770 - loss: 0.5097 - val_accuracy: 0.7829 - val_auc_33: 0.7614 - val_loss: 0.5001\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7926 - auc_33: 0.6754 - loss: 0.5031 - val_accuracy: 0.7782 - val_auc_33: 0.7623 - val_loss: 0.5008\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7967 - auc_33: 0.6774 - loss: 0.4928 - val_accuracy: 0.7887 - val_auc_33: 0.7796 - val_loss: 0.4947\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7916 - auc_33: 0.6902 - loss: 0.5001 - val_accuracy: 0.7829 - val_auc_33: 0.7757 - val_loss: 0.4948\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7942 - auc_33: 0.6766 - loss: 0.4984 - val_accuracy: 0.7855 - val_auc_33: 0.7623 - val_loss: 0.4922\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7867 - auc_33: 0.7056 - loss: 0.4965 - val_accuracy: 0.7887 - val_auc_33: 0.8019 - val_loss: 0.4874\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5609 - auc_34: 0.4989 - loss: 0.6854 - val_accuracy: 0.7030 - val_auc_34: 0.5000 - val_loss: 0.6083\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6924 - auc_34: 0.5130 - loss: 0.6260 - val_accuracy: 0.7030 - val_auc_34: 0.5000 - val_loss: 0.6083\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7091 - auc_34: 0.5054 - loss: 0.6104 - val_accuracy: 0.7030 - val_auc_34: 0.5043 - val_loss: 0.6081\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6971 - auc_34: 0.4982 - loss: 0.6240 - val_accuracy: 0.7030 - val_auc_34: 0.5139 - val_loss: 0.6084\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7041 - auc_34: 0.5118 - loss: 0.6138 - val_accuracy: 0.7030 - val_auc_34: 0.5485 - val_loss: 0.6079\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6988 - auc_34: 0.4973 - loss: 0.6204 - val_accuracy: 0.7030 - val_auc_34: 0.5156 - val_loss: 0.6080\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7002 - auc_34: 0.5015 - loss: 0.6179 - val_accuracy: 0.7030 - val_auc_34: 0.5563 - val_loss: 0.6076\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7023 - auc_34: 0.5083 - loss: 0.6148 - val_accuracy: 0.7030 - val_auc_34: 0.5520 - val_loss: 0.6075\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6963 - auc_34: 0.5044 - loss: 0.6198 - val_accuracy: 0.7030 - val_auc_34: 0.5745 - val_loss: 0.6068\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7035 - auc_34: 0.5043 - loss: 0.6126 - val_accuracy: 0.7030 - val_auc_34: 0.5754 - val_loss: 0.6060\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6983 - auc_34: 0.5236 - loss: 0.6131 - val_accuracy: 0.7030 - val_auc_34: 0.6057 - val_loss: 0.6052\n",
            "Epoch 12/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7020 - auc_34: 0.5246 - loss: 0.6112 - val_accuracy: 0.7030 - val_auc_34: 0.6248 - val_loss: 0.6022\n",
            "Epoch 13/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6915 - auc_34: 0.5479 - loss: 0.6147 - val_accuracy: 0.7030 - val_auc_34: 0.6828 - val_loss: 0.5986\n",
            "Epoch 14/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6975 - auc_34: 0.5697 - loss: 0.6053 - val_accuracy: 0.7030 - val_auc_34: 0.6984 - val_loss: 0.5912\n",
            "Epoch 15/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7046 - auc_34: 0.5890 - loss: 0.5962 - val_accuracy: 0.7030 - val_auc_34: 0.7149 - val_loss: 0.5808\n",
            "Epoch 16/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7225 - auc_34: 0.6148 - loss: 0.5864 - val_accuracy: 0.7422 - val_auc_34: 0.6906 - val_loss: 0.5673\n",
            "Epoch 17/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7444 - auc_34: 0.6181 - loss: 0.5732 - val_accuracy: 0.7524 - val_auc_34: 0.7080 - val_loss: 0.5545\n",
            "Epoch 18/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7614 - auc_34: 0.6185 - loss: 0.5573 - val_accuracy: 0.7643 - val_auc_34: 0.7002 - val_loss: 0.5424\n",
            "Epoch 19/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7641 - auc_34: 0.6312 - loss: 0.5510 - val_accuracy: 0.7679 - val_auc_34: 0.7036 - val_loss: 0.5339\n",
            "Epoch 20/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7907 - auc_34: 0.6600 - loss: 0.5165 - val_accuracy: 0.7715 - val_auc_34: 0.7805 - val_loss: 0.5264\n",
            "Epoch 21/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7701 - auc_34: 0.6476 - loss: 0.5368 - val_accuracy: 0.7720 - val_auc_34: 0.7669 - val_loss: 0.5217\n",
            "Epoch 22/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7818 - auc_34: 0.6467 - loss: 0.5250 - val_accuracy: 0.7761 - val_auc_34: 0.7574 - val_loss: 0.5137\n",
            "Epoch 23/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7719 - auc_34: 0.6536 - loss: 0.5311 - val_accuracy: 0.7771 - val_auc_34: 0.7574 - val_loss: 0.5094\n",
            "Epoch 24/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7758 - auc_34: 0.6539 - loss: 0.5292 - val_accuracy: 0.7771 - val_auc_34: 0.7574 - val_loss: 0.5069\n",
            "Epoch 25/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7813 - auc_34: 0.6710 - loss: 0.5139 - val_accuracy: 0.7885 - val_auc_34: 0.7887 - val_loss: 0.5049\n",
            "Epoch 26/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7835 - auc_34: 0.6846 - loss: 0.5110 - val_accuracy: 0.7844 - val_auc_34: 0.7846 - val_loss: 0.4975\n",
            "Epoch 27/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7880 - auc_34: 0.6831 - loss: 0.5057 - val_accuracy: 0.7802 - val_auc_34: 0.7977 - val_loss: 0.4971\n",
            "Epoch 28/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7830 - auc_34: 0.6430 - loss: 0.5179 - val_accuracy: 0.7813 - val_auc_34: 0.7789 - val_loss: 0.4954\n",
            "Epoch 29/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7818 - auc_34: 0.6784 - loss: 0.5104 - val_accuracy: 0.7808 - val_auc_34: 0.7652 - val_loss: 0.4969\n",
            "Epoch 30/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7888 - auc_34: 0.6607 - loss: 0.5049 - val_accuracy: 0.7910 - val_auc_34: 0.7843 - val_loss: 0.4872\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6904 - auc_35: 0.4982 - loss: 0.6251 - val_accuracy: 0.7018 - val_auc_35: 0.5000 - val_loss: 0.6093\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6914 - auc_35: 0.5113 - loss: 0.6257 - val_accuracy: 0.7018 - val_auc_35: 0.5000 - val_loss: 0.6092\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6789 - auc_35: 0.4977 - loss: 0.6372 - val_accuracy: 0.7018 - val_auc_35: 0.5836 - val_loss: 0.6092\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6951 - auc_35: 0.5013 - loss: 0.6255 - val_accuracy: 0.7018 - val_auc_35: 0.5166 - val_loss: 0.6090\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7092 - auc_35: 0.4772 - loss: 0.6165 - val_accuracy: 0.7018 - val_auc_35: 0.5061 - val_loss: 0.6090\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7138 - auc_35: 0.4944 - loss: 0.6080 - val_accuracy: 0.7018 - val_auc_35: 0.5514 - val_loss: 0.6091\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6993 - auc_35: 0.5115 - loss: 0.6159 - val_accuracy: 0.7018 - val_auc_35: 0.5183 - val_loss: 0.6087\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6974 - auc_35: 0.5280 - loss: 0.6146 - val_accuracy: 0.7018 - val_auc_35: 0.5993 - val_loss: 0.6084\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6970 - auc_35: 0.5190 - loss: 0.6158 - val_accuracy: 0.7018 - val_auc_35: 0.5679 - val_loss: 0.6081\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7146 - auc_35: 0.4909 - loss: 0.6076 - val_accuracy: 0.7018 - val_auc_35: 0.5854 - val_loss: 0.6076\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7038 - auc_35: 0.4947 - loss: 0.6143 - val_accuracy: 0.7018 - val_auc_35: 0.5862 - val_loss: 0.6068\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7063 - auc_35: 0.4896 - loss: 0.6121 - val_accuracy: 0.7018 - val_auc_35: 0.7813 - val_loss: 0.6057\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6976 - auc_35: 0.5341 - loss: 0.6119 - val_accuracy: 0.7018 - val_auc_35: 0.6376 - val_loss: 0.6038\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6975 - auc_35: 0.5295 - loss: 0.6134 - val_accuracy: 0.7018 - val_auc_35: 0.6446 - val_loss: 0.6007\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7106 - auc_35: 0.5495 - loss: 0.5984 - val_accuracy: 0.7018 - val_auc_35: 0.6603 - val_loss: 0.5954\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7086 - auc_35: 0.5631 - loss: 0.5970 - val_accuracy: 0.7018 - val_auc_35: 0.7247 - val_loss: 0.5876\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7060 - auc_35: 0.6017 - loss: 0.5919 - val_accuracy: 0.7340 - val_auc_35: 0.6977 - val_loss: 0.5763\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7360 - auc_35: 0.6250 - loss: 0.5765 - val_accuracy: 0.7512 - val_auc_35: 0.7108 - val_loss: 0.5622\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7530 - auc_35: 0.6274 - loss: 0.5635 - val_accuracy: 0.7631 - val_auc_35: 0.7152 - val_loss: 0.5490\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7689 - auc_35: 0.6352 - loss: 0.5482 - val_accuracy: 0.7683 - val_auc_35: 0.7152 - val_loss: 0.5385\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7748 - auc_35: 0.6677 - loss: 0.5393 - val_accuracy: 0.7714 - val_auc_35: 0.7256 - val_loss: 0.5293\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7788 - auc_35: 0.6314 - loss: 0.5349 - val_accuracy: 0.7782 - val_auc_35: 0.7395 - val_loss: 0.5237\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - auc_35: 0.6678 - loss: 0.5292 - val_accuracy: 0.7771 - val_auc_35: 0.7923 - val_loss: 0.5162\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7804 - auc_35: 0.6491 - loss: 0.5293 - val_accuracy: 0.7787 - val_auc_35: 0.7448 - val_loss: 0.5116\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7757 - auc_35: 0.6477 - loss: 0.5299 - val_accuracy: 0.7808 - val_auc_35: 0.8020 - val_loss: 0.5069\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7847 - auc_35: 0.6796 - loss: 0.5159 - val_accuracy: 0.7808 - val_auc_35: 0.7526 - val_loss: 0.5044\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - auc_35: 0.6857 - loss: 0.5098 - val_accuracy: 0.7808 - val_auc_35: 0.7544 - val_loss: 0.5012\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7893 - auc_35: 0.6705 - loss: 0.5109 - val_accuracy: 0.7849 - val_auc_35: 0.8125 - val_loss: 0.4962\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7700 - auc_35: 0.6837 - loss: 0.5217 - val_accuracy: 0.7818 - val_auc_35: 0.7744 - val_loss: 0.4994\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7964 - auc_35: 0.6634 - loss: 0.5001 - val_accuracy: 0.7896 - val_auc_35: 0.7871 - val_loss: 0.4906\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6577 - auc_36: 0.4869 - loss: 0.6443 - val_accuracy: 0.7068 - val_auc_36: 0.5000 - val_loss: 0.6052\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6998 - auc_36: 0.4917 - loss: 0.6234 - val_accuracy: 0.7068 - val_auc_36: 0.5825 - val_loss: 0.6052\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7040 - auc_36: 0.4951 - loss: 0.6197 - val_accuracy: 0.7068 - val_auc_36: 0.5816 - val_loss: 0.6049\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6976 - auc_36: 0.4950 - loss: 0.6250 - val_accuracy: 0.7068 - val_auc_36: 0.5096 - val_loss: 0.6047\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7152 - auc_36: 0.4943 - loss: 0.6076 - val_accuracy: 0.7068 - val_auc_36: 0.5228 - val_loss: 0.6046\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7107 - auc_36: 0.4822 - loss: 0.6137 - val_accuracy: 0.7068 - val_auc_36: 0.5640 - val_loss: 0.6046\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7143 - auc_36: 0.4940 - loss: 0.6078 - val_accuracy: 0.7068 - val_auc_36: 0.5298 - val_loss: 0.6043\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6953 - auc_36: 0.5198 - loss: 0.6170 - val_accuracy: 0.7068 - val_auc_36: 0.5386 - val_loss: 0.6040\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7075 - auc_36: 0.5107 - loss: 0.6105 - val_accuracy: 0.7068 - val_auc_36: 0.6026 - val_loss: 0.6037\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_36: 0.5122 - loss: 0.6137 - val_accuracy: 0.7068 - val_auc_36: 0.6061 - val_loss: 0.6032\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7063 - auc_36: 0.4871 - loss: 0.6147 - val_accuracy: 0.7068 - val_auc_36: 0.5904 - val_loss: 0.6025\n",
            "Epoch 12/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7083 - auc_36: 0.5143 - loss: 0.6063 - val_accuracy: 0.7068 - val_auc_36: 0.7272 - val_loss: 0.6014\n",
            "Epoch 13/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6961 - auc_36: 0.4997 - loss: 0.6196 - val_accuracy: 0.7068 - val_auc_36: 0.6737 - val_loss: 0.5996\n",
            "Epoch 14/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7222 - auc_36: 0.5428 - loss: 0.5885 - val_accuracy: 0.7068 - val_auc_36: 0.6447 - val_loss: 0.5953\n",
            "Epoch 15/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7028 - auc_36: 0.5493 - loss: 0.6062 - val_accuracy: 0.7068 - val_auc_36: 0.6526 - val_loss: 0.5894\n",
            "Epoch 16/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7173 - auc_36: 0.6038 - loss: 0.5834 - val_accuracy: 0.7068 - val_auc_36: 0.7018 - val_loss: 0.5784\n",
            "Epoch 17/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7215 - auc_36: 0.6109 - loss: 0.5805 - val_accuracy: 0.7510 - val_auc_36: 0.7018 - val_loss: 0.5635\n",
            "Epoch 18/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7501 - auc_36: 0.6368 - loss: 0.5624 - val_accuracy: 0.7623 - val_auc_36: 0.7754 - val_loss: 0.5459\n",
            "Epoch 19/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7714 - auc_36: 0.6325 - loss: 0.5496 - val_accuracy: 0.7701 - val_auc_36: 0.7890 - val_loss: 0.5326\n",
            "Epoch 20/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7745 - auc_36: 0.6539 - loss: 0.5388 - val_accuracy: 0.7721 - val_auc_36: 0.7211 - val_loss: 0.5225\n",
            "Epoch 21/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7743 - auc_36: 0.6592 - loss: 0.5355 - val_accuracy: 0.7757 - val_auc_36: 0.7289 - val_loss: 0.5150\n",
            "Epoch 22/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7749 - auc_36: 0.6363 - loss: 0.5337 - val_accuracy: 0.7824 - val_auc_36: 0.7737 - val_loss: 0.5074\n",
            "Epoch 23/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7785 - auc_36: 0.6421 - loss: 0.5308 - val_accuracy: 0.7824 - val_auc_36: 0.7815 - val_loss: 0.5058\n",
            "Epoch 24/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7783 - auc_36: 0.6545 - loss: 0.5233 - val_accuracy: 0.7840 - val_auc_36: 0.7772 - val_loss: 0.5000\n",
            "Epoch 25/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7896 - auc_36: 0.6647 - loss: 0.5096 - val_accuracy: 0.7876 - val_auc_36: 0.7893 - val_loss: 0.4934\n",
            "Epoch 26/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7863 - auc_36: 0.6718 - loss: 0.5067 - val_accuracy: 0.7906 - val_auc_36: 0.7693 - val_loss: 0.4896\n",
            "Epoch 27/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7894 - auc_36: 0.6896 - loss: 0.5040 - val_accuracy: 0.7896 - val_auc_36: 0.7823 - val_loss: 0.4884\n",
            "Epoch 28/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7900 - auc_36: 0.6757 - loss: 0.5072 - val_accuracy: 0.7932 - val_auc_36: 0.7702 - val_loss: 0.4845\n",
            "Epoch 29/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7877 - auc_36: 0.6875 - loss: 0.5026 - val_accuracy: 0.7922 - val_auc_36: 0.7763 - val_loss: 0.4846\n",
            "Epoch 30/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8037 - auc_36: 0.6981 - loss: 0.4805 - val_accuracy: 0.8040 - val_auc_36: 0.7974 - val_loss: 0.4796\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5211 - auc_37: 0.4999 - loss: 0.7148 - val_accuracy: 0.7046 - val_auc_37: 0.5158 - val_loss: 0.6069\n",
            "Epoch 2/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6908 - auc_37: 0.5011 - loss: 0.6268 - val_accuracy: 0.7046 - val_auc_37: 0.5000 - val_loss: 0.6080\n",
            "Epoch 3/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6884 - auc_37: 0.5075 - loss: 0.6297 - val_accuracy: 0.7046 - val_auc_37: 0.5123 - val_loss: 0.6073\n",
            "Epoch 4/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6968 - auc_37: 0.5019 - loss: 0.6250 - val_accuracy: 0.7046 - val_auc_37: 0.5166 - val_loss: 0.6077\n",
            "Epoch 5/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6928 - auc_37: 0.4876 - loss: 0.6295 - val_accuracy: 0.7046 - val_auc_37: 0.5911 - val_loss: 0.6085\n",
            "Epoch 6/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6976 - auc_37: 0.5026 - loss: 0.6221 - val_accuracy: 0.7046 - val_auc_37: 0.5928 - val_loss: 0.6066\n",
            "Epoch 7/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6983 - auc_37: 0.5123 - loss: 0.6180 - val_accuracy: 0.7046 - val_auc_37: 0.5543 - val_loss: 0.6061\n",
            "Epoch 8/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6990 - auc_37: 0.5011 - loss: 0.6193 - val_accuracy: 0.7046 - val_auc_37: 0.6629 - val_loss: 0.6054\n",
            "Epoch 9/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7155 - auc_37: 0.4963 - loss: 0.6079 - val_accuracy: 0.7046 - val_auc_37: 0.5902 - val_loss: 0.6046\n",
            "Epoch 10/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7080 - auc_37: 0.4894 - loss: 0.6149 - val_accuracy: 0.7046 - val_auc_37: 0.6287 - val_loss: 0.6038\n",
            "Epoch 11/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7135 - auc_37: 0.4925 - loss: 0.6103 - val_accuracy: 0.7046 - val_auc_37: 0.6173 - val_loss: 0.6021\n",
            "Epoch 12/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7059 - auc_37: 0.5074 - loss: 0.6130 - val_accuracy: 0.7046 - val_auc_37: 0.6252 - val_loss: 0.5999\n",
            "Epoch 13/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7005 - auc_37: 0.5059 - loss: 0.6165 - val_accuracy: 0.7046 - val_auc_37: 0.6804 - val_loss: 0.5958\n",
            "Epoch 14/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_37: 0.5440 - loss: 0.6087 - val_accuracy: 0.7046 - val_auc_37: 0.6629 - val_loss: 0.5887\n",
            "Epoch 15/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7001 - auc_37: 0.5715 - loss: 0.6043 - val_accuracy: 0.7046 - val_auc_37: 0.6856 - val_loss: 0.5772\n",
            "Epoch 16/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7211 - auc_37: 0.6169 - loss: 0.5838 - val_accuracy: 0.7506 - val_auc_37: 0.7128 - val_loss: 0.5604\n",
            "Epoch 17/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7610 - auc_37: 0.6198 - loss: 0.5596 - val_accuracy: 0.7672 - val_auc_37: 0.7688 - val_loss: 0.5439\n",
            "Epoch 18/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7632 - auc_37: 0.6310 - loss: 0.5534 - val_accuracy: 0.7713 - val_auc_37: 0.7277 - val_loss: 0.5309\n",
            "Epoch 19/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7639 - auc_37: 0.6442 - loss: 0.5497 - val_accuracy: 0.7724 - val_auc_37: 0.7483 - val_loss: 0.5248\n",
            "Epoch 20/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7772 - auc_37: 0.6453 - loss: 0.5290 - val_accuracy: 0.7796 - val_auc_37: 0.7294 - val_loss: 0.5135\n",
            "Epoch 21/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7691 - auc_37: 0.6465 - loss: 0.5350 - val_accuracy: 0.7807 - val_auc_37: 0.7885 - val_loss: 0.5080\n",
            "Epoch 22/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7812 - auc_37: 0.6389 - loss: 0.5252 - val_accuracy: 0.7817 - val_auc_37: 0.7774 - val_loss: 0.5040\n",
            "Epoch 23/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7856 - auc_37: 0.6657 - loss: 0.5136 - val_accuracy: 0.7817 - val_auc_37: 0.7877 - val_loss: 0.4995\n",
            "Epoch 24/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7754 - auc_37: 0.6656 - loss: 0.5224 - val_accuracy: 0.7807 - val_auc_37: 0.7513 - val_loss: 0.5002\n",
            "Epoch 25/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7761 - auc_37: 0.6640 - loss: 0.5197 - val_accuracy: 0.7848 - val_auc_37: 0.7887 - val_loss: 0.4930\n",
            "Epoch 26/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7779 - auc_37: 0.6553 - loss: 0.5228 - val_accuracy: 0.7853 - val_auc_37: 0.7706 - val_loss: 0.4898\n",
            "Epoch 27/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7891 - auc_37: 0.6786 - loss: 0.5032 - val_accuracy: 0.7889 - val_auc_37: 0.7759 - val_loss: 0.4866\n",
            "Epoch 28/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7854 - auc_37: 0.6751 - loss: 0.5079 - val_accuracy: 0.7874 - val_auc_37: 0.7776 - val_loss: 0.4867\n",
            "Epoch 29/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7909 - auc_37: 0.6674 - loss: 0.5048 - val_accuracy: 0.7920 - val_auc_37: 0.7781 - val_loss: 0.4842\n",
            "Epoch 30/30\n",
            "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7997 - auc_37: 0.6926 - loss: 0.4895 - val_accuracy: 0.7946 - val_auc_37: 0.7706 - val_loss: 0.4793\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5680 - auc_38: 0.4917 - loss: 0.6832 - val_accuracy: 0.7017 - val_auc_38: 0.5000 - val_loss: 0.6094\n",
            "Epoch 2/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6970 - auc_38: 0.4865 - loss: 0.6259 - val_accuracy: 0.7017 - val_auc_38: 0.5044 - val_loss: 0.6093\n",
            "Epoch 3/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7022 - auc_38: 0.5371 - loss: 0.6100 - val_accuracy: 0.7017 - val_auc_38: 0.5106 - val_loss: 0.6092\n",
            "Epoch 4/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6878 - auc_38: 0.4970 - loss: 0.6313 - val_accuracy: 0.7017 - val_auc_38: 0.5282 - val_loss: 0.6093\n",
            "Epoch 5/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7002 - auc_38: 0.4873 - loss: 0.6215 - val_accuracy: 0.7017 - val_auc_38: 0.5048 - val_loss: 0.6091\n",
            "Epoch 6/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6978 - auc_38: 0.4810 - loss: 0.6243 - val_accuracy: 0.7017 - val_auc_38: 0.5459 - val_loss: 0.6091\n",
            "Epoch 7/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7048 - auc_38: 0.4959 - loss: 0.6160 - val_accuracy: 0.7017 - val_auc_38: 0.5979 - val_loss: 0.6087\n",
            "Epoch 8/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6796 - auc_38: 0.5074 - loss: 0.6321 - val_accuracy: 0.7017 - val_auc_38: 0.5344 - val_loss: 0.6091\n",
            "Epoch 9/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7027 - auc_38: 0.5325 - loss: 0.6093 - val_accuracy: 0.7017 - val_auc_38: 0.5591 - val_loss: 0.6081\n",
            "Epoch 10/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7040 - auc_38: 0.4867 - loss: 0.6165 - val_accuracy: 0.7017 - val_auc_38: 0.5705 - val_loss: 0.6075\n",
            "Epoch 11/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7043 - auc_38: 0.5081 - loss: 0.6111 - val_accuracy: 0.7017 - val_auc_38: 0.6226 - val_loss: 0.6065\n",
            "Epoch 12/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6976 - auc_38: 0.5210 - loss: 0.6135 - val_accuracy: 0.7017 - val_auc_38: 0.6146 - val_loss: 0.6047\n",
            "Epoch 13/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7007 - auc_38: 0.5209 - loss: 0.6124 - val_accuracy: 0.7017 - val_auc_38: 0.6261 - val_loss: 0.6016\n",
            "Epoch 14/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7027 - auc_38: 0.5690 - loss: 0.6034 - val_accuracy: 0.7017 - val_auc_38: 0.6490 - val_loss: 0.5963\n",
            "Epoch 15/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7065 - auc_38: 0.5663 - loss: 0.5993 - val_accuracy: 0.7017 - val_auc_38: 0.6534 - val_loss: 0.5858\n",
            "Epoch 16/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7131 - auc_38: 0.6065 - loss: 0.5887 - val_accuracy: 0.7417 - val_auc_38: 0.6931 - val_loss: 0.5708\n",
            "Epoch 17/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7416 - auc_38: 0.6406 - loss: 0.5715 - val_accuracy: 0.7585 - val_auc_38: 0.6872 - val_loss: 0.5531\n",
            "Epoch 18/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7619 - auc_38: 0.6487 - loss: 0.5531 - val_accuracy: 0.7659 - val_auc_38: 0.7143 - val_loss: 0.5403\n",
            "Epoch 19/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7672 - auc_38: 0.6429 - loss: 0.5481 - val_accuracy: 0.7701 - val_auc_38: 0.7663 - val_loss: 0.5303\n",
            "Epoch 20/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7709 - auc_38: 0.6887 - loss: 0.5292 - val_accuracy: 0.7722 - val_auc_38: 0.7478 - val_loss: 0.5236\n",
            "Epoch 21/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - auc_38: 0.6778 - loss: 0.5258 - val_accuracy: 0.7749 - val_auc_38: 0.7205 - val_loss: 0.5177\n",
            "Epoch 22/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7790 - auc_38: 0.6612 - loss: 0.5262 - val_accuracy: 0.7749 - val_auc_38: 0.7469 - val_loss: 0.5181\n",
            "Epoch 23/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7815 - auc_38: 0.6621 - loss: 0.5196 - val_accuracy: 0.7775 - val_auc_38: 0.7496 - val_loss: 0.5069\n",
            "Epoch 24/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7811 - auc_38: 0.6717 - loss: 0.5159 - val_accuracy: 0.7775 - val_auc_38: 0.7663 - val_loss: 0.5047\n",
            "Epoch 25/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7864 - auc_38: 0.6616 - loss: 0.5168 - val_accuracy: 0.7775 - val_auc_38: 0.7390 - val_loss: 0.5093\n",
            "Epoch 26/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7956 - auc_38: 0.6993 - loss: 0.4930 - val_accuracy: 0.7785 - val_auc_38: 0.7522 - val_loss: 0.5023\n",
            "Epoch 27/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7857 - auc_38: 0.6718 - loss: 0.5131 - val_accuracy: 0.7806 - val_auc_38: 0.7715 - val_loss: 0.5009\n",
            "Epoch 28/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7858 - auc_38: 0.6812 - loss: 0.5105 - val_accuracy: 0.7891 - val_auc_38: 0.7717 - val_loss: 0.4928\n",
            "Epoch 29/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7910 - auc_38: 0.6932 - loss: 0.4988 - val_accuracy: 0.7901 - val_auc_38: 0.7710 - val_loss: 0.4903\n",
            "Epoch 30/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7887 - auc_38: 0.6813 - loss: 0.5028 - val_accuracy: 0.7906 - val_auc_38: 0.7853 - val_loss: 0.4877\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5131 - auc_39: 0.4840 - loss: 0.7202 - val_accuracy: 0.7064 - val_auc_39: 0.5000 - val_loss: 0.6054\n",
            "Epoch 2/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6919 - auc_39: 0.4900 - loss: 0.6285 - val_accuracy: 0.7064 - val_auc_39: 0.5000 - val_loss: 0.6057\n",
            "Epoch 3/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7003 - auc_39: 0.5024 - loss: 0.6212 - val_accuracy: 0.7064 - val_auc_39: 0.5166 - val_loss: 0.6056\n",
            "Epoch 4/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7006 - auc_39: 0.5010 - loss: 0.6203 - val_accuracy: 0.7064 - val_auc_39: 0.6132 - val_loss: 0.6058\n",
            "Epoch 5/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7018 - auc_39: 0.4961 - loss: 0.6195 - val_accuracy: 0.7064 - val_auc_39: 0.5549 - val_loss: 0.6050\n",
            "Epoch 6/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6905 - auc_39: 0.5028 - loss: 0.6248 - val_accuracy: 0.7064 - val_auc_39: 0.5174 - val_loss: 0.6048\n",
            "Epoch 7/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7053 - auc_39: 0.5139 - loss: 0.6120 - val_accuracy: 0.7064 - val_auc_39: 0.6315 - val_loss: 0.6045\n",
            "Epoch 8/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7227 - auc_39: 0.5070 - loss: 0.5966 - val_accuracy: 0.7064 - val_auc_39: 0.6089 - val_loss: 0.6040\n",
            "Epoch 9/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7166 - auc_39: 0.4744 - loss: 0.6102 - val_accuracy: 0.7064 - val_auc_39: 0.5793 - val_loss: 0.6036\n",
            "Epoch 10/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7057 - auc_39: 0.5193 - loss: 0.6087 - val_accuracy: 0.7064 - val_auc_39: 0.6220 - val_loss: 0.6023\n",
            "Epoch 11/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7091 - auc_39: 0.5420 - loss: 0.6018 - val_accuracy: 0.7064 - val_auc_39: 0.6167 - val_loss: 0.6004\n",
            "Epoch 12/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7116 - auc_39: 0.5662 - loss: 0.5968 - val_accuracy: 0.7064 - val_auc_39: 0.6516 - val_loss: 0.5973\n",
            "Epoch 13/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7183 - auc_39: 0.5656 - loss: 0.5904 - val_accuracy: 0.7064 - val_auc_39: 0.6524 - val_loss: 0.5932\n",
            "Epoch 14/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7029 - auc_39: 0.5778 - loss: 0.6004 - val_accuracy: 0.7064 - val_auc_39: 0.6794 - val_loss: 0.5845\n",
            "Epoch 15/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7048 - auc_39: 0.5841 - loss: 0.5982 - val_accuracy: 0.7100 - val_auc_39: 0.7641 - val_loss: 0.5740\n",
            "Epoch 16/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7300 - auc_39: 0.6014 - loss: 0.5790 - val_accuracy: 0.7483 - val_auc_39: 0.6803 - val_loss: 0.5613\n",
            "Epoch 17/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7495 - auc_39: 0.6184 - loss: 0.5663 - val_accuracy: 0.7627 - val_auc_39: 0.7108 - val_loss: 0.5480\n",
            "Epoch 18/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7579 - auc_39: 0.6385 - loss: 0.5581 - val_accuracy: 0.7693 - val_auc_39: 0.7387 - val_loss: 0.5356\n",
            "Epoch 19/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7763 - auc_39: 0.6438 - loss: 0.5432 - val_accuracy: 0.7724 - val_auc_39: 0.7570 - val_loss: 0.5251\n",
            "Epoch 20/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7852 - auc_39: 0.6513 - loss: 0.5284 - val_accuracy: 0.7775 - val_auc_39: 0.7622 - val_loss: 0.5177\n",
            "Epoch 21/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7767 - auc_39: 0.6490 - loss: 0.5348 - val_accuracy: 0.7765 - val_auc_39: 0.7474 - val_loss: 0.5154\n",
            "Epoch 22/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7661 - auc_39: 0.6487 - loss: 0.5402 - val_accuracy: 0.7780 - val_auc_39: 0.7719 - val_loss: 0.5112\n",
            "Epoch 23/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7905 - auc_39: 0.6796 - loss: 0.5047 - val_accuracy: 0.7801 - val_auc_39: 0.7474 - val_loss: 0.5027\n",
            "Epoch 24/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7909 - auc_39: 0.6674 - loss: 0.5083 - val_accuracy: 0.7816 - val_auc_39: 0.7663 - val_loss: 0.4990\n",
            "Epoch 25/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7877 - auc_39: 0.6697 - loss: 0.5104 - val_accuracy: 0.7811 - val_auc_39: 0.7369 - val_loss: 0.5017\n",
            "Epoch 26/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7891 - auc_39: 0.6723 - loss: 0.5065 - val_accuracy: 0.7831 - val_auc_39: 0.7387 - val_loss: 0.4956\n",
            "Epoch 27/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7871 - auc_39: 0.6621 - loss: 0.5109 - val_accuracy: 0.7847 - val_auc_39: 0.7491 - val_loss: 0.4943\n",
            "Epoch 28/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8027 - auc_39: 0.6975 - loss: 0.4845 - val_accuracy: 0.7954 - val_auc_39: 0.7695 - val_loss: 0.4852\n",
            "Epoch 29/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7929 - auc_39: 0.6896 - loss: 0.4991 - val_accuracy: 0.7964 - val_auc_39: 0.7570 - val_loss: 0.4823\n",
            "Epoch 30/30\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8054 - auc_39: 0.6887 - loss: 0.4876 - val_accuracy: 0.7959 - val_auc_39: 0.7808 - val_loss: 0.4841\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5048 - auc_40: 0.4796 - loss: 0.7211 - val_accuracy: 0.7039 - val_auc_40: 0.5000 - val_loss: 0.6077\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_40: 0.4824 - loss: 0.6175 - val_accuracy: 0.7039 - val_auc_40: 0.5035 - val_loss: 0.6076\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6917 - auc_40: 0.5026 - loss: 0.6250 - val_accuracy: 0.7039 - val_auc_40: 0.5000 - val_loss: 0.6076\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7013 - auc_40: 0.5154 - loss: 0.6152 - val_accuracy: 0.7039 - val_auc_40: 0.5044 - val_loss: 0.6073\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7062 - auc_40: 0.5159 - loss: 0.6100 - val_accuracy: 0.7039 - val_auc_40: 0.5553 - val_loss: 0.6073\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7032 - auc_40: 0.5294 - loss: 0.6099 - val_accuracy: 0.7039 - val_auc_40: 0.5105 - val_loss: 0.6072\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6991 - auc_40: 0.4946 - loss: 0.6194 - val_accuracy: 0.7039 - val_auc_40: 0.5307 - val_loss: 0.6072\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6972 - auc_40: 0.4971 - loss: 0.6201 - val_accuracy: 0.7039 - val_auc_40: 0.5588 - val_loss: 0.6072\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6966 - auc_40: 0.5160 - loss: 0.6174 - val_accuracy: 0.7039 - val_auc_40: 0.6544 - val_loss: 0.6068\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7080 - auc_40: 0.5201 - loss: 0.6067 - val_accuracy: 0.7039 - val_auc_40: 0.5649 - val_loss: 0.6061\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7082 - auc_40: 0.4874 - loss: 0.6117 - val_accuracy: 0.7039 - val_auc_40: 0.5912 - val_loss: 0.6054\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - auc_40: 0.5108 - loss: 0.6065 - val_accuracy: 0.7039 - val_auc_40: 0.6982 - val_loss: 0.6041\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7089 - auc_40: 0.5092 - loss: 0.6066 - val_accuracy: 0.7039 - val_auc_40: 0.6307 - val_loss: 0.6017\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6963 - auc_40: 0.5245 - loss: 0.6144 - val_accuracy: 0.7039 - val_auc_40: 0.6316 - val_loss: 0.5977\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7098 - auc_40: 0.5701 - loss: 0.5960 - val_accuracy: 0.7039 - val_auc_40: 0.6675 - val_loss: 0.5902\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6978 - auc_40: 0.6108 - loss: 0.5983 - val_accuracy: 0.7039 - val_auc_40: 0.7833 - val_loss: 0.5774\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7231 - auc_40: 0.6307 - loss: 0.5796 - val_accuracy: 0.7543 - val_auc_40: 0.7053 - val_loss: 0.5611\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7485 - auc_40: 0.6075 - loss: 0.5723 - val_accuracy: 0.7610 - val_auc_40: 0.7211 - val_loss: 0.5490\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7646 - auc_40: 0.6045 - loss: 0.5578 - val_accuracy: 0.7704 - val_auc_40: 0.7876 - val_loss: 0.5341\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7809 - auc_40: 0.6422 - loss: 0.5329 - val_accuracy: 0.7756 - val_auc_40: 0.7632 - val_loss: 0.5234\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7770 - auc_40: 0.6678 - loss: 0.5297 - val_accuracy: 0.7771 - val_auc_40: 0.7518 - val_loss: 0.5172\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7884 - auc_40: 0.6767 - loss: 0.5157 - val_accuracy: 0.7782 - val_auc_40: 0.7905 - val_loss: 0.5106\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7851 - auc_40: 0.6800 - loss: 0.5143 - val_accuracy: 0.7782 - val_auc_40: 0.7430 - val_loss: 0.5083\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7875 - auc_40: 0.6652 - loss: 0.5151 - val_accuracy: 0.7808 - val_auc_40: 0.7833 - val_loss: 0.5007\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7913 - auc_40: 0.6966 - loss: 0.5003 - val_accuracy: 0.7813 - val_auc_40: 0.7892 - val_loss: 0.4973\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7874 - auc_40: 0.6914 - loss: 0.5092 - val_accuracy: 0.7813 - val_auc_40: 0.7825 - val_loss: 0.4956\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7887 - auc_40: 0.6788 - loss: 0.5094 - val_accuracy: 0.7865 - val_auc_40: 0.7798 - val_loss: 0.4899\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7959 - auc_40: 0.6770 - loss: 0.5008 - val_accuracy: 0.7839 - val_auc_40: 0.7821 - val_loss: 0.4918\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8011 - auc_40: 0.6790 - loss: 0.4942 - val_accuracy: 0.7886 - val_auc_40: 0.7818 - val_loss: 0.4868\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7996 - auc_40: 0.7092 - loss: 0.4866 - val_accuracy: 0.7990 - val_auc_40: 0.7857 - val_loss: 0.4808\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4957 - auc_41: 0.4957 - loss: 0.7407 - val_accuracy: 0.7069 - val_auc_41: 0.5000 - val_loss: 0.6050\n",
            "Epoch 2/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6897 - auc_41: 0.4953 - loss: 0.6331 - val_accuracy: 0.7069 - val_auc_41: 0.5053 - val_loss: 0.6061\n",
            "Epoch 3/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7101 - auc_41: 0.5113 - loss: 0.6113 - val_accuracy: 0.7069 - val_auc_41: 0.5606 - val_loss: 0.6048\n",
            "Epoch 4/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6965 - auc_41: 0.5279 - loss: 0.6169 - val_accuracy: 0.7069 - val_auc_41: 0.5004 - val_loss: 0.6054\n",
            "Epoch 5/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7135 - auc_41: 0.5083 - loss: 0.6099 - val_accuracy: 0.7069 - val_auc_41: 0.5580 - val_loss: 0.6046\n",
            "Epoch 6/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7097 - auc_41: 0.5213 - loss: 0.6103 - val_accuracy: 0.7069 - val_auc_41: 0.6362 - val_loss: 0.6048\n",
            "Epoch 7/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7072 - auc_41: 0.5192 - loss: 0.6101 - val_accuracy: 0.7069 - val_auc_41: 0.5492 - val_loss: 0.6043\n",
            "Epoch 8/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7091 - auc_41: 0.5350 - loss: 0.6030 - val_accuracy: 0.7069 - val_auc_41: 0.5369 - val_loss: 0.6040\n",
            "Epoch 9/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7200 - auc_41: 0.5208 - loss: 0.5971 - val_accuracy: 0.7069 - val_auc_41: 0.5694 - val_loss: 0.6037\n",
            "Epoch 10/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7065 - auc_41: 0.5108 - loss: 0.6122 - val_accuracy: 0.7069 - val_auc_41: 0.6362 - val_loss: 0.6030\n",
            "Epoch 11/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6990 - auc_41: 0.5038 - loss: 0.6194 - val_accuracy: 0.7069 - val_auc_41: 0.5975 - val_loss: 0.6033\n",
            "Epoch 12/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7050 - auc_41: 0.5398 - loss: 0.6065 - val_accuracy: 0.7069 - val_auc_41: 0.6265 - val_loss: 0.6012\n",
            "Epoch 13/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6992 - auc_41: 0.5319 - loss: 0.6126 - val_accuracy: 0.7069 - val_auc_41: 0.6362 - val_loss: 0.5996\n",
            "Epoch 14/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6961 - auc_41: 0.5544 - loss: 0.6120 - val_accuracy: 0.7069 - val_auc_41: 0.7021 - val_loss: 0.5957\n",
            "Epoch 15/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7087 - auc_41: 0.5618 - loss: 0.5982 - val_accuracy: 0.7069 - val_auc_41: 0.7854 - val_loss: 0.5888\n",
            "Epoch 16/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7053 - auc_41: 0.5652 - loss: 0.6008 - val_accuracy: 0.7069 - val_auc_41: 0.6828 - val_loss: 0.5787\n",
            "Epoch 17/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7228 - auc_41: 0.6183 - loss: 0.5781 - val_accuracy: 0.7434 - val_auc_41: 0.7531 - val_loss: 0.5641\n",
            "Epoch 18/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7370 - auc_41: 0.6176 - loss: 0.5768 - val_accuracy: 0.7625 - val_auc_41: 0.7179 - val_loss: 0.5492\n",
            "Epoch 19/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7529 - auc_41: 0.6114 - loss: 0.5658 - val_accuracy: 0.7733 - val_auc_41: 0.7663 - val_loss: 0.5352\n",
            "Epoch 20/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7586 - auc_41: 0.6347 - loss: 0.5586 - val_accuracy: 0.7785 - val_auc_41: 0.7970 - val_loss: 0.5225\n",
            "Epoch 21/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7641 - auc_41: 0.6629 - loss: 0.5397 - val_accuracy: 0.7790 - val_auc_41: 0.7197 - val_loss: 0.5140\n",
            "Epoch 22/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7716 - auc_41: 0.6527 - loss: 0.5380 - val_accuracy: 0.7826 - val_auc_41: 0.7285 - val_loss: 0.5069\n",
            "Epoch 23/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7735 - auc_41: 0.6611 - loss: 0.5306 - val_accuracy: 0.7852 - val_auc_41: 0.7680 - val_loss: 0.4992\n",
            "Epoch 24/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7813 - auc_41: 0.6588 - loss: 0.5210 - val_accuracy: 0.7867 - val_auc_41: 0.7742 - val_loss: 0.4947\n",
            "Epoch 25/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7869 - auc_41: 0.6746 - loss: 0.5124 - val_accuracy: 0.7893 - val_auc_41: 0.8056 - val_loss: 0.4903\n",
            "Epoch 26/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7881 - auc_41: 0.6595 - loss: 0.5134 - val_accuracy: 0.7867 - val_auc_41: 0.7731 - val_loss: 0.4923\n",
            "Epoch 27/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7872 - auc_41: 0.6678 - loss: 0.5096 - val_accuracy: 0.7883 - val_auc_41: 0.7715 - val_loss: 0.4889\n",
            "Epoch 28/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7808 - auc_41: 0.6795 - loss: 0.5143 - val_accuracy: 0.7913 - val_auc_41: 0.7663 - val_loss: 0.4836\n",
            "Epoch 29/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7970 - auc_41: 0.6949 - loss: 0.4890 - val_accuracy: 0.7965 - val_auc_41: 0.7924 - val_loss: 0.4785\n",
            "Epoch 30/30\n",
            "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8055 - auc_41: 0.6915 - loss: 0.4853 - val_accuracy: 0.7970 - val_auc_41: 0.8241 - val_loss: 0.4766\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.7016 - auc_42: 0.4875 - loss: 0.6240 - val_accuracy: 0.7037 - val_auc_42: 0.5000 - val_loss: 0.6076\n",
            "Epoch 2/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7047 - auc_42: 0.4845 - loss: 0.6192 - val_accuracy: 0.7037 - val_auc_42: 0.5069 - val_loss: 0.6076\n",
            "Epoch 3/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7023 - auc_42: 0.5074 - loss: 0.6153 - val_accuracy: 0.7037 - val_auc_42: 0.5095 - val_loss: 0.6075\n",
            "Epoch 4/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7040 - auc_42: 0.5117 - loss: 0.6120 - val_accuracy: 0.7037 - val_auc_42: 0.5009 - val_loss: 0.6074\n",
            "Epoch 5/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7003 - auc_42: 0.5044 - loss: 0.6160 - val_accuracy: 0.7037 - val_auc_42: 0.5790 - val_loss: 0.6073\n",
            "Epoch 6/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7035 - auc_42: 0.4904 - loss: 0.6149 - val_accuracy: 0.7037 - val_auc_42: 0.6328 - val_loss: 0.6072\n",
            "Epoch 7/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7087 - auc_42: 0.5177 - loss: 0.6061 - val_accuracy: 0.7037 - val_auc_42: 0.6797 - val_loss: 0.6071\n",
            "Epoch 8/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7036 - auc_42: 0.4902 - loss: 0.6136 - val_accuracy: 0.7037 - val_auc_42: 0.5538 - val_loss: 0.6068\n",
            "Epoch 9/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6954 - auc_42: 0.5148 - loss: 0.6179 - val_accuracy: 0.7037 - val_auc_42: 0.5859 - val_loss: 0.6064\n",
            "Epoch 10/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6996 - auc_42: 0.5295 - loss: 0.6116 - val_accuracy: 0.7037 - val_auc_42: 0.6398 - val_loss: 0.6058\n",
            "Epoch 11/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7081 - auc_42: 0.5046 - loss: 0.6083 - val_accuracy: 0.7037 - val_auc_42: 0.6276 - val_loss: 0.6046\n",
            "Epoch 12/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7079 - auc_42: 0.5098 - loss: 0.6068 - val_accuracy: 0.7037 - val_auc_42: 0.6276 - val_loss: 0.6029\n",
            "Epoch 13/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6948 - auc_42: 0.5318 - loss: 0.6148 - val_accuracy: 0.7037 - val_auc_42: 0.6745 - val_loss: 0.6000\n",
            "Epoch 14/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6992 - auc_42: 0.5758 - loss: 0.6038 - val_accuracy: 0.7037 - val_auc_42: 0.6806 - val_loss: 0.5954\n",
            "Epoch 15/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7000 - auc_42: 0.5686 - loss: 0.6031 - val_accuracy: 0.7037 - val_auc_42: 0.6953 - val_loss: 0.5880\n",
            "Epoch 16/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7057 - auc_42: 0.5934 - loss: 0.5911 - val_accuracy: 0.7037 - val_auc_42: 0.6875 - val_loss: 0.5784\n",
            "Epoch 17/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7195 - auc_42: 0.6130 - loss: 0.5830 - val_accuracy: 0.7443 - val_auc_42: 0.7153 - val_loss: 0.5670\n",
            "Epoch 18/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7409 - auc_42: 0.6337 - loss: 0.5736 - val_accuracy: 0.7546 - val_auc_42: 0.6953 - val_loss: 0.5558\n",
            "Epoch 19/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7590 - auc_42: 0.6470 - loss: 0.5535 - val_accuracy: 0.7670 - val_auc_42: 0.7135 - val_loss: 0.5446\n",
            "Epoch 20/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7599 - auc_42: 0.6483 - loss: 0.5580 - val_accuracy: 0.7670 - val_auc_42: 0.7057 - val_loss: 0.5371\n",
            "Epoch 21/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7751 - auc_42: 0.6381 - loss: 0.5414 - val_accuracy: 0.7762 - val_auc_42: 0.7517 - val_loss: 0.5285\n",
            "Epoch 22/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7657 - auc_42: 0.6424 - loss: 0.5484 - val_accuracy: 0.7762 - val_auc_42: 0.7170 - val_loss: 0.5227\n",
            "Epoch 23/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7737 - auc_42: 0.6565 - loss: 0.5390 - val_accuracy: 0.7778 - val_auc_42: 0.7283 - val_loss: 0.5189\n",
            "Epoch 24/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7790 - auc_42: 0.6717 - loss: 0.5287 - val_accuracy: 0.7793 - val_auc_42: 0.7625 - val_loss: 0.5119\n",
            "Epoch 25/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - auc_42: 0.6852 - loss: 0.5168 - val_accuracy: 0.7798 - val_auc_42: 0.7587 - val_loss: 0.5087\n",
            "Epoch 26/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - auc_42: 0.6896 - loss: 0.5174 - val_accuracy: 0.7819 - val_auc_42: 0.7871 - val_loss: 0.5068\n",
            "Epoch 27/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7871 - auc_42: 0.6804 - loss: 0.5160 - val_accuracy: 0.7865 - val_auc_42: 0.7509 - val_loss: 0.5011\n",
            "Epoch 28/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7917 - auc_42: 0.7066 - loss: 0.5027 - val_accuracy: 0.7876 - val_auc_42: 0.7587 - val_loss: 0.4980\n",
            "Epoch 29/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7887 - auc_42: 0.6910 - loss: 0.5146 - val_accuracy: 0.7876 - val_auc_42: 0.7561 - val_loss: 0.4979\n",
            "Epoch 30/30\n",
            "\u001b[1m454/454\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7928 - auc_42: 0.6892 - loss: 0.5052 - val_accuracy: 0.7881 - val_auc_42: 0.7585 - val_loss: 0.4951\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6488 - auc_43: 0.4863 - loss: 0.6426 - val_accuracy: 0.7027 - val_auc_43: 0.5000 - val_loss: 0.6085\n",
            "Epoch 2/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6984 - auc_43: 0.5001 - loss: 0.6191 - val_accuracy: 0.7027 - val_auc_43: 0.5000 - val_loss: 0.6084\n",
            "Epoch 3/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7039 - auc_43: 0.5180 - loss: 0.6118 - val_accuracy: 0.7027 - val_auc_43: 0.5000 - val_loss: 0.6084\n",
            "Epoch 4/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6964 - auc_43: 0.5158 - loss: 0.6185 - val_accuracy: 0.7027 - val_auc_43: 0.5123 - val_loss: 0.6084\n",
            "Epoch 5/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7149 - auc_43: 0.5011 - loss: 0.6049 - val_accuracy: 0.7027 - val_auc_43: 0.5132 - val_loss: 0.6081\n",
            "Epoch 6/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7081 - auc_43: 0.5029 - loss: 0.6106 - val_accuracy: 0.7027 - val_auc_43: 0.5596 - val_loss: 0.6079\n",
            "Epoch 7/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7110 - auc_43: 0.4947 - loss: 0.6097 - val_accuracy: 0.7027 - val_auc_43: 0.5614 - val_loss: 0.6076\n",
            "Epoch 8/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6931 - auc_43: 0.4920 - loss: 0.6247 - val_accuracy: 0.7027 - val_auc_43: 0.6149 - val_loss: 0.6072\n",
            "Epoch 9/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6935 - auc_43: 0.5430 - loss: 0.6149 - val_accuracy: 0.7027 - val_auc_43: 0.6351 - val_loss: 0.6065\n",
            "Epoch 10/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7008 - auc_43: 0.4935 - loss: 0.6175 - val_accuracy: 0.7027 - val_auc_43: 0.6500 - val_loss: 0.6057\n",
            "Epoch 11/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6938 - auc_43: 0.5371 - loss: 0.6161 - val_accuracy: 0.7027 - val_auc_43: 0.6272 - val_loss: 0.6040\n",
            "Epoch 12/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_43: 0.5267 - loss: 0.6072 - val_accuracy: 0.7027 - val_auc_43: 0.6482 - val_loss: 0.6012\n",
            "Epoch 13/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6979 - auc_43: 0.5233 - loss: 0.6146 - val_accuracy: 0.7027 - val_auc_43: 0.6640 - val_loss: 0.5968\n",
            "Epoch 14/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6970 - auc_43: 0.5610 - loss: 0.6077 - val_accuracy: 0.7027 - val_auc_43: 0.6500 - val_loss: 0.5901\n",
            "Epoch 15/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7042 - auc_43: 0.5961 - loss: 0.5944 - val_accuracy: 0.7027 - val_auc_43: 0.6912 - val_loss: 0.5777\n",
            "Epoch 16/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7211 - auc_43: 0.6486 - loss: 0.5785 - val_accuracy: 0.7428 - val_auc_43: 0.7202 - val_loss: 0.5648\n",
            "Epoch 17/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7483 - auc_43: 0.6206 - loss: 0.5680 - val_accuracy: 0.7663 - val_auc_43: 0.7053 - val_loss: 0.5479\n",
            "Epoch 18/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7598 - auc_43: 0.6382 - loss: 0.5600 - val_accuracy: 0.7700 - val_auc_43: 0.7061 - val_loss: 0.5366\n",
            "Epoch 19/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7618 - auc_43: 0.6358 - loss: 0.5542 - val_accuracy: 0.7710 - val_auc_43: 0.7395 - val_loss: 0.5286\n",
            "Epoch 20/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7817 - auc_43: 0.6550 - loss: 0.5289 - val_accuracy: 0.7741 - val_auc_43: 0.7307 - val_loss: 0.5208\n",
            "Epoch 21/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7855 - auc_43: 0.6486 - loss: 0.5242 - val_accuracy: 0.7746 - val_auc_43: 0.7167 - val_loss: 0.5186\n",
            "Epoch 22/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7748 - auc_43: 0.6714 - loss: 0.5306 - val_accuracy: 0.7752 - val_auc_43: 0.7781 - val_loss: 0.5121\n",
            "Epoch 23/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7715 - auc_43: 0.6747 - loss: 0.5283 - val_accuracy: 0.7757 - val_auc_43: 0.7779 - val_loss: 0.5089\n",
            "Epoch 24/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7825 - auc_43: 0.6789 - loss: 0.5164 - val_accuracy: 0.7783 - val_auc_43: 0.7535 - val_loss: 0.5047\n",
            "Epoch 25/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7929 - auc_43: 0.7010 - loss: 0.4987 - val_accuracy: 0.7830 - val_auc_43: 0.7579 - val_loss: 0.4997\n",
            "Epoch 26/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7785 - auc_43: 0.6871 - loss: 0.5150 - val_accuracy: 0.7820 - val_auc_43: 0.7767 - val_loss: 0.5003\n",
            "Epoch 27/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7984 - auc_43: 0.6879 - loss: 0.4960 - val_accuracy: 0.7846 - val_auc_43: 0.7719 - val_loss: 0.4962\n",
            "Epoch 28/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8007 - auc_43: 0.7051 - loss: 0.4856 - val_accuracy: 0.7908 - val_auc_43: 0.7946 - val_loss: 0.4908\n",
            "Epoch 29/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7904 - auc_43: 0.6682 - loss: 0.5093 - val_accuracy: 0.7877 - val_auc_43: 0.7719 - val_loss: 0.4949\n",
            "Epoch 30/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7946 - auc_43: 0.6851 - loss: 0.4969 - val_accuracy: 0.7903 - val_auc_43: 0.7649 - val_loss: 0.4927\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6325 - auc_44: 0.4699 - loss: 0.6549 - val_accuracy: 0.7020 - val_auc_44: 0.6272 - val_loss: 0.6091\n",
            "Epoch 2/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7115 - auc_44: 0.5063 - loss: 0.6099 - val_accuracy: 0.7020 - val_auc_44: 0.5000 - val_loss: 0.6092\n",
            "Epoch 3/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7013 - auc_44: 0.5090 - loss: 0.6174 - val_accuracy: 0.7020 - val_auc_44: 0.5070 - val_loss: 0.6090\n",
            "Epoch 4/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6974 - auc_44: 0.4744 - loss: 0.6282 - val_accuracy: 0.7020 - val_auc_44: 0.5079 - val_loss: 0.6089\n",
            "Epoch 5/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6949 - auc_44: 0.4732 - loss: 0.6315 - val_accuracy: 0.7020 - val_auc_44: 0.5640 - val_loss: 0.6095\n",
            "Epoch 6/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7150 - auc_44: 0.5301 - loss: 0.6015 - val_accuracy: 0.7020 - val_auc_44: 0.5640 - val_loss: 0.6087\n",
            "Epoch 7/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6857 - auc_44: 0.4918 - loss: 0.6309 - val_accuracy: 0.7020 - val_auc_44: 0.5325 - val_loss: 0.6093\n",
            "Epoch 8/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7037 - auc_44: 0.5031 - loss: 0.6152 - val_accuracy: 0.7020 - val_auc_44: 0.6219 - val_loss: 0.6081\n",
            "Epoch 9/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_44: 0.4978 - loss: 0.6127 - val_accuracy: 0.7020 - val_auc_44: 0.5807 - val_loss: 0.6078\n",
            "Epoch 10/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6925 - auc_44: 0.4978 - loss: 0.6245 - val_accuracy: 0.7020 - val_auc_44: 0.5833 - val_loss: 0.6077\n",
            "Epoch 11/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7034 - auc_44: 0.5069 - loss: 0.6134 - val_accuracy: 0.7020 - val_auc_44: 0.6158 - val_loss: 0.6063\n",
            "Epoch 12/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7136 - auc_44: 0.5196 - loss: 0.6022 - val_accuracy: 0.7020 - val_auc_44: 0.6439 - val_loss: 0.6050\n",
            "Epoch 13/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7064 - auc_44: 0.5227 - loss: 0.6073 - val_accuracy: 0.7020 - val_auc_44: 0.6167 - val_loss: 0.6028\n",
            "Epoch 14/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7016 - auc_44: 0.5437 - loss: 0.6084 - val_accuracy: 0.7020 - val_auc_44: 0.6219 - val_loss: 0.5998\n",
            "Epoch 15/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6893 - auc_44: 0.5524 - loss: 0.6188 - val_accuracy: 0.7020 - val_auc_44: 0.6719 - val_loss: 0.5930\n",
            "Epoch 16/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7050 - auc_44: 0.5810 - loss: 0.5969 - val_accuracy: 0.7020 - val_auc_44: 0.7596 - val_loss: 0.5832\n",
            "Epoch 17/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7155 - auc_44: 0.6231 - loss: 0.5869 - val_accuracy: 0.7371 - val_auc_44: 0.7509 - val_loss: 0.5713\n",
            "Epoch 18/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7506 - auc_44: 0.6148 - loss: 0.5620 - val_accuracy: 0.7595 - val_auc_44: 0.7263 - val_loss: 0.5550\n",
            "Epoch 19/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7507 - auc_44: 0.6364 - loss: 0.5697 - val_accuracy: 0.7611 - val_auc_44: 0.6921 - val_loss: 0.5437\n",
            "Epoch 20/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7690 - auc_44: 0.6537 - loss: 0.5422 - val_accuracy: 0.7679 - val_auc_44: 0.7000 - val_loss: 0.5331\n",
            "Epoch 21/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7663 - auc_44: 0.6671 - loss: 0.5443 - val_accuracy: 0.7710 - val_auc_44: 0.7687 - val_loss: 0.5230\n",
            "Epoch 22/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7733 - auc_44: 0.6702 - loss: 0.5289 - val_accuracy: 0.7731 - val_auc_44: 0.7333 - val_loss: 0.5188\n",
            "Epoch 23/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - auc_44: 0.6645 - loss: 0.5186 - val_accuracy: 0.7747 - val_auc_44: 0.7834 - val_loss: 0.5139\n",
            "Epoch 24/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7981 - auc_44: 0.6772 - loss: 0.5001 - val_accuracy: 0.7747 - val_auc_44: 0.7333 - val_loss: 0.5137\n",
            "Epoch 25/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7864 - auc_44: 0.6775 - loss: 0.5112 - val_accuracy: 0.7747 - val_auc_44: 0.7756 - val_loss: 0.5097\n",
            "Epoch 26/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8006 - auc_44: 0.6912 - loss: 0.4912 - val_accuracy: 0.7778 - val_auc_44: 0.7518 - val_loss: 0.5008\n",
            "Epoch 27/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7935 - auc_44: 0.6839 - loss: 0.5034 - val_accuracy: 0.7799 - val_auc_44: 0.7500 - val_loss: 0.4992\n",
            "Epoch 28/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7920 - auc_44: 0.6903 - loss: 0.5011 - val_accuracy: 0.7852 - val_auc_44: 0.7671 - val_loss: 0.4953\n",
            "Epoch 29/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7932 - auc_44: 0.6813 - loss: 0.4998 - val_accuracy: 0.7841 - val_auc_44: 0.7643 - val_loss: 0.4972\n",
            "Epoch 30/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8014 - auc_44: 0.7035 - loss: 0.4851 - val_accuracy: 0.7893 - val_auc_44: 0.7898 - val_loss: 0.4900\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.7105 - auc_45: 0.5123 - loss: 0.6380 - val_accuracy: 0.7020 - val_auc_45: 0.5000 - val_loss: 0.6097\n",
            "Epoch 2/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6904 - auc_45: 0.4767 - loss: 0.6321 - val_accuracy: 0.7020 - val_auc_45: 0.5000 - val_loss: 0.6090\n",
            "Epoch 3/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6991 - auc_45: 0.4837 - loss: 0.6228 - val_accuracy: 0.7020 - val_auc_45: 0.5000 - val_loss: 0.6090\n",
            "Epoch 4/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6954 - auc_45: 0.4866 - loss: 0.6251 - val_accuracy: 0.7020 - val_auc_45: 0.6316 - val_loss: 0.6090\n",
            "Epoch 5/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7045 - auc_45: 0.5008 - loss: 0.6139 - val_accuracy: 0.7020 - val_auc_45: 0.5000 - val_loss: 0.6088\n",
            "Epoch 6/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6962 - auc_45: 0.4956 - loss: 0.6235 - val_accuracy: 0.7020 - val_auc_45: 0.5061 - val_loss: 0.6090\n",
            "Epoch 7/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7028 - auc_45: 0.4990 - loss: 0.6166 - val_accuracy: 0.7020 - val_auc_45: 0.5377 - val_loss: 0.6087\n",
            "Epoch 8/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6966 - auc_45: 0.5189 - loss: 0.6167 - val_accuracy: 0.7020 - val_auc_45: 0.5649 - val_loss: 0.6086\n",
            "Epoch 9/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6853 - auc_45: 0.4979 - loss: 0.6295 - val_accuracy: 0.7020 - val_auc_45: 0.5377 - val_loss: 0.6083\n",
            "Epoch 10/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6997 - auc_45: 0.5129 - loss: 0.6143 - val_accuracy: 0.7020 - val_auc_45: 0.5991 - val_loss: 0.6081\n",
            "Epoch 11/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6953 - auc_45: 0.4891 - loss: 0.6221 - val_accuracy: 0.7020 - val_auc_45: 0.5737 - val_loss: 0.6074\n",
            "Epoch 12/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7009 - auc_45: 0.4965 - loss: 0.6174 - val_accuracy: 0.7020 - val_auc_45: 0.6149 - val_loss: 0.6067\n",
            "Epoch 13/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7028 - auc_45: 0.5063 - loss: 0.6124 - val_accuracy: 0.7020 - val_auc_45: 0.6254 - val_loss: 0.6056\n",
            "Epoch 14/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6868 - auc_45: 0.5432 - loss: 0.6201 - val_accuracy: 0.7020 - val_auc_45: 0.6851 - val_loss: 0.6041\n",
            "Epoch 15/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7041 - auc_45: 0.5497 - loss: 0.6046 - val_accuracy: 0.7020 - val_auc_45: 0.7096 - val_loss: 0.5999\n",
            "Epoch 16/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7002 - auc_45: 0.5490 - loss: 0.6076 - val_accuracy: 0.7020 - val_auc_45: 0.6421 - val_loss: 0.5951\n",
            "Epoch 17/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6891 - auc_45: 0.5785 - loss: 0.6096 - val_accuracy: 0.7020 - val_auc_45: 0.7026 - val_loss: 0.5877\n",
            "Epoch 18/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7015 - auc_45: 0.6131 - loss: 0.5939 - val_accuracy: 0.7020 - val_auc_45: 0.7351 - val_loss: 0.5782\n",
            "Epoch 19/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7078 - auc_45: 0.6102 - loss: 0.5924 - val_accuracy: 0.7371 - val_auc_45: 0.6886 - val_loss: 0.5680\n",
            "Epoch 20/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7290 - auc_45: 0.6446 - loss: 0.5736 - val_accuracy: 0.7601 - val_auc_45: 0.6991 - val_loss: 0.5559\n",
            "Epoch 21/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7466 - auc_45: 0.6474 - loss: 0.5667 - val_accuracy: 0.7684 - val_auc_45: 0.7689 - val_loss: 0.5448\n",
            "Epoch 22/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7627 - auc_45: 0.6570 - loss: 0.5500 - val_accuracy: 0.7705 - val_auc_45: 0.7105 - val_loss: 0.5362\n",
            "Epoch 23/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7556 - auc_45: 0.6579 - loss: 0.5598 - val_accuracy: 0.7768 - val_auc_45: 0.7456 - val_loss: 0.5280\n",
            "Epoch 24/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7606 - auc_45: 0.6744 - loss: 0.5512 - val_accuracy: 0.7768 - val_auc_45: 0.7333 - val_loss: 0.5252\n",
            "Epoch 25/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7798 - auc_45: 0.6612 - loss: 0.5279 - val_accuracy: 0.7804 - val_auc_45: 0.7771 - val_loss: 0.5159\n",
            "Epoch 26/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7741 - auc_45: 0.6642 - loss: 0.5381 - val_accuracy: 0.7784 - val_auc_45: 0.7747 - val_loss: 0.5213\n",
            "Epoch 27/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7786 - auc_45: 0.6884 - loss: 0.5255 - val_accuracy: 0.7825 - val_auc_45: 0.7675 - val_loss: 0.5076\n",
            "Epoch 28/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7970 - auc_45: 0.6808 - loss: 0.5104 - val_accuracy: 0.7831 - val_auc_45: 0.7695 - val_loss: 0.5037\n",
            "Epoch 29/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7874 - auc_45: 0.6808 - loss: 0.5163 - val_accuracy: 0.7841 - val_auc_45: 0.7579 - val_loss: 0.5006\n",
            "Epoch 30/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7916 - auc_45: 0.6884 - loss: 0.5091 - val_accuracy: 0.7857 - val_auc_45: 0.7810 - val_loss: 0.4974\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.7188 - auc_46: 0.4974 - loss: 0.6124 - val_accuracy: 0.7072 - val_auc_46: 0.5000 - val_loss: 0.6045\n",
            "Epoch 2/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6871 - auc_46: 0.5229 - loss: 0.6254 - val_accuracy: 0.7072 - val_auc_46: 0.5053 - val_loss: 0.6057\n",
            "Epoch 3/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7113 - auc_46: 0.5048 - loss: 0.6105 - val_accuracy: 0.7072 - val_auc_46: 0.5000 - val_loss: 0.6044\n",
            "Epoch 4/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7045 - auc_46: 0.5180 - loss: 0.6108 - val_accuracy: 0.7072 - val_auc_46: 0.6057 - val_loss: 0.6046\n",
            "Epoch 5/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7077 - auc_46: 0.4935 - loss: 0.6140 - val_accuracy: 0.7072 - val_auc_46: 0.5924 - val_loss: 0.6042\n",
            "Epoch 6/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7021 - auc_46: 0.4811 - loss: 0.6205 - val_accuracy: 0.7072 - val_auc_46: 0.5053 - val_loss: 0.6042\n",
            "Epoch 7/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6956 - auc_46: 0.5060 - loss: 0.6211 - val_accuracy: 0.7072 - val_auc_46: 0.5337 - val_loss: 0.6041\n",
            "Epoch 8/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7023 - auc_46: 0.5083 - loss: 0.6141 - val_accuracy: 0.7072 - val_auc_46: 0.5710 - val_loss: 0.6037\n",
            "Epoch 9/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7120 - auc_46: 0.5010 - loss: 0.6063 - val_accuracy: 0.7072 - val_auc_46: 0.5968 - val_loss: 0.6037\n",
            "Epoch 10/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6963 - auc_46: 0.4666 - loss: 0.6239 - val_accuracy: 0.7072 - val_auc_46: 0.5879 - val_loss: 0.6029\n",
            "Epoch 11/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7112 - auc_46: 0.5192 - loss: 0.6032 - val_accuracy: 0.7072 - val_auc_46: 0.5941 - val_loss: 0.6021\n",
            "Epoch 12/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7147 - auc_46: 0.5327 - loss: 0.5970 - val_accuracy: 0.7072 - val_auc_46: 0.6750 - val_loss: 0.6010\n",
            "Epoch 13/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7077 - auc_46: 0.5092 - loss: 0.6083 - val_accuracy: 0.7072 - val_auc_46: 0.6519 - val_loss: 0.5990\n",
            "Epoch 14/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7068 - auc_46: 0.5050 - loss: 0.6091 - val_accuracy: 0.7072 - val_auc_46: 0.6314 - val_loss: 0.5961\n",
            "Epoch 15/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7072 - auc_46: 0.5444 - loss: 0.6021 - val_accuracy: 0.7072 - val_auc_46: 0.7149 - val_loss: 0.5924\n",
            "Epoch 16/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6968 - auc_46: 0.5594 - loss: 0.6086 - val_accuracy: 0.7072 - val_auc_46: 0.6643 - val_loss: 0.5848\n",
            "Epoch 17/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7178 - auc_46: 0.6068 - loss: 0.5795 - val_accuracy: 0.7072 - val_auc_46: 0.7043 - val_loss: 0.5761\n",
            "Epoch 18/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7225 - auc_46: 0.6235 - loss: 0.5737 - val_accuracy: 0.7478 - val_auc_46: 0.7953 - val_loss: 0.5633\n",
            "Epoch 19/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7343 - auc_46: 0.6584 - loss: 0.5687 - val_accuracy: 0.7655 - val_auc_46: 0.7114 - val_loss: 0.5528\n",
            "Epoch 20/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7647 - auc_46: 0.6311 - loss: 0.5568 - val_accuracy: 0.7670 - val_auc_46: 0.7407 - val_loss: 0.5416\n",
            "Epoch 21/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7674 - auc_46: 0.6634 - loss: 0.5436 - val_accuracy: 0.7743 - val_auc_46: 0.7682 - val_loss: 0.5309\n",
            "Epoch 22/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7773 - auc_46: 0.6462 - loss: 0.5396 - val_accuracy: 0.7764 - val_auc_46: 0.7810 - val_loss: 0.5233\n",
            "Epoch 23/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7932 - auc_46: 0.6812 - loss: 0.5160 - val_accuracy: 0.7785 - val_auc_46: 0.7920 - val_loss: 0.5163\n",
            "Epoch 24/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7885 - auc_46: 0.6780 - loss: 0.5178 - val_accuracy: 0.7800 - val_auc_46: 0.8074 - val_loss: 0.5115\n",
            "Epoch 25/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - auc_46: 0.6910 - loss: 0.5089 - val_accuracy: 0.7816 - val_auc_46: 0.7811 - val_loss: 0.5052\n",
            "Epoch 26/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7950 - auc_46: 0.6784 - loss: 0.5077 - val_accuracy: 0.7847 - val_auc_46: 0.7999 - val_loss: 0.5005\n",
            "Epoch 27/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7941 - auc_46: 0.6882 - loss: 0.5049 - val_accuracy: 0.7852 - val_auc_46: 0.7942 - val_loss: 0.4989\n",
            "Epoch 28/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7839 - auc_46: 0.6801 - loss: 0.5193 - val_accuracy: 0.7904 - val_auc_46: 0.7998 - val_loss: 0.4920\n",
            "Epoch 29/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7917 - auc_46: 0.6652 - loss: 0.5198 - val_accuracy: 0.7904 - val_auc_46: 0.8031 - val_loss: 0.4911\n",
            "Epoch 30/30\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8044 - auc_46: 0.7133 - loss: 0.4877 - val_accuracy: 0.7962 - val_auc_46: 0.8144 - val_loss: 0.4853\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.7078 - auc_47: 0.4929 - loss: 0.6279 - val_accuracy: 0.7076 - val_auc_47: 0.5661 - val_loss: 0.6043\n",
            "Epoch 2/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7054 - auc_47: 0.5230 - loss: 0.6113 - val_accuracy: 0.7076 - val_auc_47: 0.5000 - val_loss: 0.6042\n",
            "Epoch 3/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7078 - auc_47: 0.5045 - loss: 0.6135 - val_accuracy: 0.7076 - val_auc_47: 0.5161 - val_loss: 0.6041\n",
            "Epoch 4/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7048 - auc_47: 0.5101 - loss: 0.6135 - val_accuracy: 0.7076 - val_auc_47: 0.5027 - val_loss: 0.6040\n",
            "Epoch 5/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7148 - auc_47: 0.4965 - loss: 0.6074 - val_accuracy: 0.7076 - val_auc_47: 0.5464 - val_loss: 0.6039\n",
            "Epoch 6/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7216 - auc_47: 0.5284 - loss: 0.5950 - val_accuracy: 0.7076 - val_auc_47: 0.5714 - val_loss: 0.6038\n",
            "Epoch 7/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - auc_47: 0.4973 - loss: 0.6114 - val_accuracy: 0.7076 - val_auc_47: 0.6045 - val_loss: 0.6036\n",
            "Epoch 8/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7158 - auc_47: 0.4890 - loss: 0.6079 - val_accuracy: 0.7076 - val_auc_47: 0.6821 - val_loss: 0.6036\n",
            "Epoch 9/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7089 - auc_47: 0.5207 - loss: 0.6052 - val_accuracy: 0.7076 - val_auc_47: 0.6232 - val_loss: 0.6027\n",
            "Epoch 10/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6982 - auc_47: 0.5107 - loss: 0.6166 - val_accuracy: 0.7076 - val_auc_47: 0.6009 - val_loss: 0.6019\n",
            "Epoch 11/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6984 - auc_47: 0.5136 - loss: 0.6176 - val_accuracy: 0.7076 - val_auc_47: 0.6295 - val_loss: 0.6002\n",
            "Epoch 12/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7056 - auc_47: 0.5177 - loss: 0.6088 - val_accuracy: 0.7076 - val_auc_47: 0.6598 - val_loss: 0.5978\n",
            "Epoch 13/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7179 - auc_47: 0.5164 - loss: 0.5989 - val_accuracy: 0.7076 - val_auc_47: 0.6509 - val_loss: 0.5933\n",
            "Epoch 14/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7150 - auc_47: 0.5806 - loss: 0.5904 - val_accuracy: 0.7076 - val_auc_47: 0.6536 - val_loss: 0.5867\n",
            "Epoch 15/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7111 - auc_47: 0.5940 - loss: 0.5898 - val_accuracy: 0.7076 - val_auc_47: 0.6893 - val_loss: 0.5760\n",
            "Epoch 16/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7119 - auc_47: 0.6072 - loss: 0.5906 - val_accuracy: 0.7436 - val_auc_47: 0.7563 - val_loss: 0.5635\n",
            "Epoch 17/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7405 - auc_47: 0.6155 - loss: 0.5694 - val_accuracy: 0.7671 - val_auc_47: 0.7259 - val_loss: 0.5501\n",
            "Epoch 18/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7556 - auc_47: 0.6259 - loss: 0.5671 - val_accuracy: 0.7681 - val_auc_47: 0.7196 - val_loss: 0.5369\n",
            "Epoch 19/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7661 - auc_47: 0.6267 - loss: 0.5562 - val_accuracy: 0.7775 - val_auc_47: 0.7420 - val_loss: 0.5247\n",
            "Epoch 20/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7773 - auc_47: 0.6774 - loss: 0.5301 - val_accuracy: 0.7833 - val_auc_47: 0.7652 - val_loss: 0.5143\n",
            "Epoch 21/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7823 - auc_47: 0.6650 - loss: 0.5283 - val_accuracy: 0.7885 - val_auc_47: 0.7940 - val_loss: 0.5067\n",
            "Epoch 22/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7838 - auc_47: 0.6764 - loss: 0.5211 - val_accuracy: 0.7885 - val_auc_47: 0.7455 - val_loss: 0.5013\n",
            "Epoch 23/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7870 - auc_47: 0.6726 - loss: 0.5167 - val_accuracy: 0.7896 - val_auc_47: 0.7643 - val_loss: 0.4949\n",
            "Epoch 24/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7924 - auc_47: 0.6740 - loss: 0.5091 - val_accuracy: 0.7890 - val_auc_47: 0.8044 - val_loss: 0.4958\n",
            "Epoch 25/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7911 - auc_47: 0.6999 - loss: 0.5000 - val_accuracy: 0.7916 - val_auc_47: 0.7901 - val_loss: 0.4864\n",
            "Epoch 26/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7963 - auc_47: 0.6864 - loss: 0.5005 - val_accuracy: 0.7916 - val_auc_47: 0.8171 - val_loss: 0.4846\n",
            "Epoch 27/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8025 - auc_47: 0.7045 - loss: 0.4898 - val_accuracy: 0.7943 - val_auc_47: 0.8109 - val_loss: 0.4804\n",
            "Epoch 28/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7945 - auc_47: 0.7125 - loss: 0.4933 - val_accuracy: 0.7932 - val_auc_47: 0.7836 - val_loss: 0.4831\n",
            "Epoch 29/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7964 - auc_47: 0.6812 - loss: 0.5018 - val_accuracy: 0.7953 - val_auc_47: 0.7893 - val_loss: 0.4782\n",
            "Epoch 30/30\n",
            "\u001b[1m447/447\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8034 - auc_47: 0.6987 - loss: 0.4875 - val_accuracy: 0.8005 - val_auc_47: 0.8011 - val_loss: 0.4700\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4686 - auc_48: 0.5165 - loss: 0.7560 - val_accuracy: 0.7000 - val_auc_48: 0.5000 - val_loss: 0.6108\n",
            "Epoch 2/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6838 - auc_48: 0.4938 - loss: 0.6339 - val_accuracy: 0.7000 - val_auc_48: 0.5053 - val_loss: 0.6117\n",
            "Epoch 3/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7059 - auc_48: 0.4904 - loss: 0.6196 - val_accuracy: 0.7000 - val_auc_48: 0.5000 - val_loss: 0.6106\n",
            "Epoch 4/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6973 - auc_48: 0.5064 - loss: 0.6195 - val_accuracy: 0.7000 - val_auc_48: 0.6035 - val_loss: 0.6106\n",
            "Epoch 5/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6881 - auc_48: 0.5094 - loss: 0.6269 - val_accuracy: 0.7000 - val_auc_48: 0.5544 - val_loss: 0.6110\n",
            "Epoch 6/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7003 - auc_48: 0.4915 - loss: 0.6188 - val_accuracy: 0.7000 - val_auc_48: 0.5570 - val_loss: 0.6103\n",
            "Epoch 7/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6904 - auc_48: 0.5130 - loss: 0.6230 - val_accuracy: 0.7000 - val_auc_48: 0.5351 - val_loss: 0.6104\n",
            "Epoch 8/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7009 - auc_48: 0.5096 - loss: 0.6142 - val_accuracy: 0.7000 - val_auc_48: 0.6711 - val_loss: 0.6099\n",
            "Epoch 9/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6983 - auc_48: 0.5007 - loss: 0.6188 - val_accuracy: 0.7000 - val_auc_48: 0.6219 - val_loss: 0.6092\n",
            "Epoch 10/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6954 - auc_48: 0.4930 - loss: 0.6240 - val_accuracy: 0.7000 - val_auc_48: 0.6079 - val_loss: 0.6086\n",
            "Epoch 11/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - auc_48: 0.4945 - loss: 0.6093 - val_accuracy: 0.7000 - val_auc_48: 0.6237 - val_loss: 0.6065\n",
            "Epoch 12/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7041 - auc_48: 0.5201 - loss: 0.6106 - val_accuracy: 0.7000 - val_auc_48: 0.6465 - val_loss: 0.6030\n",
            "Epoch 13/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6989 - auc_48: 0.5455 - loss: 0.6093 - val_accuracy: 0.7000 - val_auc_48: 0.6825 - val_loss: 0.5961\n",
            "Epoch 14/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7041 - auc_48: 0.5678 - loss: 0.6024 - val_accuracy: 0.7000 - val_auc_48: 0.7281 - val_loss: 0.5833\n",
            "Epoch 15/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7064 - auc_48: 0.5700 - loss: 0.6043 - val_accuracy: 0.7463 - val_auc_48: 0.7219 - val_loss: 0.5644\n",
            "Epoch 16/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7519 - auc_48: 0.6121 - loss: 0.5692 - val_accuracy: 0.7679 - val_auc_48: 0.8044 - val_loss: 0.5429\n",
            "Epoch 17/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7533 - auc_48: 0.6312 - loss: 0.5636 - val_accuracy: 0.7705 - val_auc_48: 0.7395 - val_loss: 0.5294\n",
            "Epoch 18/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7703 - auc_48: 0.6249 - loss: 0.5463 - val_accuracy: 0.7811 - val_auc_48: 0.7561 - val_loss: 0.5132\n",
            "Epoch 19/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7809 - auc_48: 0.6521 - loss: 0.5284 - val_accuracy: 0.7868 - val_auc_48: 0.7719 - val_loss: 0.5033\n",
            "Epoch 20/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7790 - auc_48: 0.6409 - loss: 0.5287 - val_accuracy: 0.7879 - val_auc_48: 0.7570 - val_loss: 0.4963\n",
            "Epoch 21/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7765 - auc_48: 0.6673 - loss: 0.5229 - val_accuracy: 0.7895 - val_auc_48: 0.7500 - val_loss: 0.4911\n",
            "Epoch 22/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7851 - auc_48: 0.6517 - loss: 0.5172 - val_accuracy: 0.7900 - val_auc_48: 0.8083 - val_loss: 0.4880\n",
            "Epoch 23/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8001 - auc_48: 0.6754 - loss: 0.4937 - val_accuracy: 0.7958 - val_auc_48: 0.7807 - val_loss: 0.4798\n",
            "Epoch 24/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7873 - auc_48: 0.6661 - loss: 0.5085 - val_accuracy: 0.7947 - val_auc_48: 0.8061 - val_loss: 0.4770\n",
            "Epoch 25/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7720 - auc_48: 0.6614 - loss: 0.5257 - val_accuracy: 0.7979 - val_auc_48: 0.7816 - val_loss: 0.4747\n",
            "Epoch 26/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7934 - auc_48: 0.6961 - loss: 0.4976 - val_accuracy: 0.8000 - val_auc_48: 0.8133 - val_loss: 0.4706\n",
            "Epoch 27/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7838 - auc_48: 0.6832 - loss: 0.5070 - val_accuracy: 0.8016 - val_auc_48: 0.8100 - val_loss: 0.4673\n",
            "Epoch 28/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7900 - auc_48: 0.6915 - loss: 0.4976 - val_accuracy: 0.8021 - val_auc_48: 0.7854 - val_loss: 0.4645\n",
            "Epoch 29/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7919 - auc_48: 0.6908 - loss: 0.4966 - val_accuracy: 0.8047 - val_auc_48: 0.8237 - val_loss: 0.4609\n",
            "Epoch 30/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7987 - auc_48: 0.7075 - loss: 0.4833 - val_accuracy: 0.8105 - val_auc_48: 0.8062 - val_loss: 0.4576\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.5229 - auc_49: 0.4950 - loss: 0.7036 - val_accuracy: 0.7051 - val_auc_49: 0.5000 - val_loss: 0.6066\n",
            "Epoch 2/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7001 - auc_49: 0.4721 - loss: 0.6234 - val_accuracy: 0.7051 - val_auc_49: 0.5027 - val_loss: 0.6066\n",
            "Epoch 3/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7148 - auc_49: 0.4859 - loss: 0.6093 - val_accuracy: 0.7051 - val_auc_49: 0.5009 - val_loss: 0.6065\n",
            "Epoch 4/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6940 - auc_49: 0.4908 - loss: 0.6239 - val_accuracy: 0.7051 - val_auc_49: 0.5036 - val_loss: 0.6065\n",
            "Epoch 5/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6964 - auc_49: 0.4884 - loss: 0.6234 - val_accuracy: 0.7051 - val_auc_49: 0.5027 - val_loss: 0.6063\n",
            "Epoch 6/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6902 - auc_49: 0.5128 - loss: 0.6232 - val_accuracy: 0.7051 - val_auc_49: 0.5497 - val_loss: 0.6062\n",
            "Epoch 7/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7083 - auc_49: 0.5086 - loss: 0.6076 - val_accuracy: 0.7051 - val_auc_49: 0.6190 - val_loss: 0.6058\n",
            "Epoch 8/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7001 - auc_49: 0.4919 - loss: 0.6180 - val_accuracy: 0.7051 - val_auc_49: 0.5586 - val_loss: 0.6058\n",
            "Epoch 9/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7051 - auc_49: 0.5185 - loss: 0.6090 - val_accuracy: 0.7051 - val_auc_49: 0.5915 - val_loss: 0.6050\n",
            "Epoch 10/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6946 - auc_49: 0.5171 - loss: 0.6179 - val_accuracy: 0.7051 - val_auc_49: 0.6101 - val_loss: 0.6041\n",
            "Epoch 11/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7109 - auc_49: 0.5506 - loss: 0.5976 - val_accuracy: 0.7051 - val_auc_49: 0.6199 - val_loss: 0.6025\n",
            "Epoch 12/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7035 - auc_49: 0.5100 - loss: 0.6117 - val_accuracy: 0.7051 - val_auc_49: 0.6288 - val_loss: 0.6002\n",
            "Epoch 13/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7006 - auc_49: 0.5601 - loss: 0.6054 - val_accuracy: 0.7051 - val_auc_49: 0.7069 - val_loss: 0.5947\n",
            "Epoch 14/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7113 - auc_49: 0.5629 - loss: 0.5952 - val_accuracy: 0.7051 - val_auc_49: 0.7202 - val_loss: 0.5849\n",
            "Epoch 15/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7195 - auc_49: 0.6113 - loss: 0.5801 - val_accuracy: 0.7391 - val_auc_49: 0.7291 - val_loss: 0.5688\n",
            "Epoch 16/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7469 - auc_49: 0.6201 - loss: 0.5671 - val_accuracy: 0.7601 - val_auc_49: 0.7407 - val_loss: 0.5505\n",
            "Epoch 17/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7684 - auc_49: 0.6471 - loss: 0.5515 - val_accuracy: 0.7695 - val_auc_49: 0.7247 - val_loss: 0.5336\n",
            "Epoch 18/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - auc_49: 0.6694 - loss: 0.5210 - val_accuracy: 0.7779 - val_auc_49: 0.7460 - val_loss: 0.5214\n",
            "Epoch 19/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7849 - auc_49: 0.6627 - loss: 0.5223 - val_accuracy: 0.7789 - val_auc_49: 0.7433 - val_loss: 0.5139\n",
            "Epoch 20/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7766 - auc_49: 0.6627 - loss: 0.5280 - val_accuracy: 0.7789 - val_auc_49: 0.7353 - val_loss: 0.5106\n",
            "Epoch 21/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7852 - auc_49: 0.6781 - loss: 0.5120 - val_accuracy: 0.7810 - val_auc_49: 0.7407 - val_loss: 0.5047\n",
            "Epoch 22/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7785 - auc_49: 0.6673 - loss: 0.5175 - val_accuracy: 0.7810 - val_auc_49: 0.7531 - val_loss: 0.4979\n",
            "Epoch 23/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7973 - auc_49: 0.6985 - loss: 0.4934 - val_accuracy: 0.7810 - val_auc_49: 0.7655 - val_loss: 0.4980\n",
            "Epoch 24/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7976 - auc_49: 0.7046 - loss: 0.4890 - val_accuracy: 0.7894 - val_auc_49: 0.8022 - val_loss: 0.4884\n",
            "Epoch 25/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7958 - auc_49: 0.6950 - loss: 0.4934 - val_accuracy: 0.7863 - val_auc_49: 0.7691 - val_loss: 0.4861\n",
            "Epoch 26/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7905 - auc_49: 0.6925 - loss: 0.4991 - val_accuracy: 0.7852 - val_auc_49: 0.8019 - val_loss: 0.4888\n",
            "Epoch 27/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8001 - auc_49: 0.6958 - loss: 0.4875 - val_accuracy: 0.7926 - val_auc_49: 0.8115 - val_loss: 0.4800\n",
            "Epoch 28/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8029 - auc_49: 0.6973 - loss: 0.4833 - val_accuracy: 0.7894 - val_auc_49: 0.7792 - val_loss: 0.4827\n",
            "Epoch 29/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8078 - auc_49: 0.6998 - loss: 0.4773 - val_accuracy: 0.7947 - val_auc_49: 0.7788 - val_loss: 0.4769\n",
            "Epoch 30/30\n",
            "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8004 - auc_49: 0.7157 - loss: 0.4816 - val_accuracy: 0.7947 - val_auc_49: 0.7760 - val_loss: 0.4771\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6528 - auc_50: 0.4601 - loss: 0.6486 - val_accuracy: 0.6980 - val_auc_50: 0.5000 - val_loss: 0.6127\n",
            "Epoch 2/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6883 - auc_50: 0.4704 - loss: 0.6364 - val_accuracy: 0.6980 - val_auc_50: 0.5000 - val_loss: 0.6123\n",
            "Epoch 3/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7000 - auc_50: 0.4859 - loss: 0.6260 - val_accuracy: 0.6980 - val_auc_50: 0.5876 - val_loss: 0.6122\n",
            "Epoch 4/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6906 - auc_50: 0.5056 - loss: 0.6271 - val_accuracy: 0.6980 - val_auc_50: 0.5079 - val_loss: 0.6122\n",
            "Epoch 5/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7023 - auc_50: 0.5245 - loss: 0.6108 - val_accuracy: 0.6980 - val_auc_50: 0.5210 - val_loss: 0.6121\n",
            "Epoch 6/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6891 - auc_50: 0.5105 - loss: 0.6250 - val_accuracy: 0.6980 - val_auc_50: 0.5613 - val_loss: 0.6122\n",
            "Epoch 7/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7016 - auc_50: 0.5131 - loss: 0.6167 - val_accuracy: 0.6980 - val_auc_50: 0.5849 - val_loss: 0.6115\n",
            "Epoch 8/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6921 - auc_50: 0.5101 - loss: 0.6220 - val_accuracy: 0.6980 - val_auc_50: 0.5546 - val_loss: 0.6112\n",
            "Epoch 9/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6968 - auc_50: 0.5214 - loss: 0.6158 - val_accuracy: 0.6980 - val_auc_50: 0.5832 - val_loss: 0.6107\n",
            "Epoch 10/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7179 - auc_50: 0.5102 - loss: 0.6004 - val_accuracy: 0.6980 - val_auc_50: 0.6089 - val_loss: 0.6108\n",
            "Epoch 11/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7008 - auc_50: 0.5169 - loss: 0.6133 - val_accuracy: 0.6980 - val_auc_50: 0.6506 - val_loss: 0.6084\n",
            "Epoch 12/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7007 - auc_50: 0.5353 - loss: 0.6109 - val_accuracy: 0.6980 - val_auc_50: 0.6384 - val_loss: 0.6060\n",
            "Epoch 13/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6982 - auc_50: 0.5548 - loss: 0.6080 - val_accuracy: 0.6980 - val_auc_50: 0.6559 - val_loss: 0.6021\n",
            "Epoch 14/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6917 - auc_50: 0.5623 - loss: 0.6114 - val_accuracy: 0.6980 - val_auc_50: 0.6961 - val_loss: 0.5954\n",
            "Epoch 15/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7024 - auc_50: 0.5762 - loss: 0.6005 - val_accuracy: 0.6980 - val_auc_50: 0.6935 - val_loss: 0.5843\n",
            "Epoch 16/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7102 - auc_50: 0.6342 - loss: 0.5917 - val_accuracy: 0.7425 - val_auc_50: 0.6996 - val_loss: 0.5676\n",
            "Epoch 17/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7366 - auc_50: 0.6085 - loss: 0.5802 - val_accuracy: 0.7647 - val_auc_50: 0.7268 - val_loss: 0.5504\n",
            "Epoch 18/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7643 - auc_50: 0.6403 - loss: 0.5543 - val_accuracy: 0.7721 - val_auc_50: 0.7277 - val_loss: 0.5355\n",
            "Epoch 19/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7711 - auc_50: 0.6383 - loss: 0.5507 - val_accuracy: 0.7726 - val_auc_50: 0.7259 - val_loss: 0.5257\n",
            "Epoch 20/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7736 - auc_50: 0.6402 - loss: 0.5397 - val_accuracy: 0.7821 - val_auc_50: 0.7697 - val_loss: 0.5153\n",
            "Epoch 21/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7687 - auc_50: 0.6448 - loss: 0.5431 - val_accuracy: 0.7800 - val_auc_50: 0.7408 - val_loss: 0.5105\n",
            "Epoch 22/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7749 - auc_50: 0.6514 - loss: 0.5378 - val_accuracy: 0.7842 - val_auc_50: 0.7504 - val_loss: 0.5018\n",
            "Epoch 23/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7716 - auc_50: 0.6651 - loss: 0.5299 - val_accuracy: 0.7874 - val_auc_50: 0.7872 - val_loss: 0.4967\n",
            "Epoch 24/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7787 - auc_50: 0.6673 - loss: 0.5228 - val_accuracy: 0.7874 - val_auc_50: 0.8151 - val_loss: 0.4937\n",
            "Epoch 25/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7848 - auc_50: 0.6915 - loss: 0.5098 - val_accuracy: 0.7885 - val_auc_50: 0.8191 - val_loss: 0.4903\n",
            "Epoch 26/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7792 - auc_50: 0.6816 - loss: 0.5161 - val_accuracy: 0.7895 - val_auc_50: 0.7636 - val_loss: 0.4866\n",
            "Epoch 27/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7878 - auc_50: 0.6721 - loss: 0.5094 - val_accuracy: 0.7916 - val_auc_50: 0.7706 - val_loss: 0.4815\n",
            "Epoch 28/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7838 - auc_50: 0.6721 - loss: 0.5152 - val_accuracy: 0.7911 - val_auc_50: 0.8034 - val_loss: 0.4811\n",
            "Epoch 29/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7962 - auc_50: 0.7000 - loss: 0.4949 - val_accuracy: 0.7964 - val_auc_50: 0.7819 - val_loss: 0.4757\n",
            "Epoch 30/30\n",
            "\u001b[1m442/442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7873 - auc_50: 0.6953 - loss: 0.5076 - val_accuracy: 0.8027 - val_auc_50: 0.7874 - val_loss: 0.4730\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5091 - auc_51: 0.4928 - loss: 0.7381 - val_accuracy: 0.6988 - val_auc_51: 0.5044 - val_loss: 0.6118\n",
            "Epoch 2/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6845 - auc_51: 0.5030 - loss: 0.6350 - val_accuracy: 0.6988 - val_auc_51: 0.5911 - val_loss: 0.6126\n",
            "Epoch 3/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6914 - auc_51: 0.4988 - loss: 0.6286 - val_accuracy: 0.6988 - val_auc_51: 0.5044 - val_loss: 0.6117\n",
            "Epoch 4/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7039 - auc_51: 0.5191 - loss: 0.6146 - val_accuracy: 0.6988 - val_auc_51: 0.5911 - val_loss: 0.6113\n",
            "Epoch 5/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6920 - auc_51: 0.4881 - loss: 0.6282 - val_accuracy: 0.6988 - val_auc_51: 0.6349 - val_loss: 0.6113\n",
            "Epoch 6/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7076 - auc_51: 0.4977 - loss: 0.6169 - val_accuracy: 0.6988 - val_auc_51: 0.6016 - val_loss: 0.6107\n",
            "Epoch 7/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7014 - auc_51: 0.5066 - loss: 0.6165 - val_accuracy: 0.6988 - val_auc_51: 0.6173 - val_loss: 0.6101\n",
            "Epoch 8/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6927 - auc_51: 0.5084 - loss: 0.6257 - val_accuracy: 0.6988 - val_auc_51: 0.6077 - val_loss: 0.6091\n",
            "Epoch 9/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7128 - auc_51: 0.5119 - loss: 0.6078 - val_accuracy: 0.6988 - val_auc_51: 0.6182 - val_loss: 0.6079\n",
            "Epoch 10/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6884 - auc_51: 0.5080 - loss: 0.6250 - val_accuracy: 0.6988 - val_auc_51: 0.6567 - val_loss: 0.6050\n",
            "Epoch 11/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7121 - auc_51: 0.5425 - loss: 0.6007 - val_accuracy: 0.6988 - val_auc_51: 0.6673 - val_loss: 0.6002\n",
            "Epoch 12/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6990 - auc_51: 0.5394 - loss: 0.6119 - val_accuracy: 0.6988 - val_auc_51: 0.7032 - val_loss: 0.5921\n",
            "Epoch 13/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7006 - auc_51: 0.5880 - loss: 0.6022 - val_accuracy: 0.6988 - val_auc_51: 0.6839 - val_loss: 0.5795\n",
            "Epoch 14/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7292 - auc_51: 0.5960 - loss: 0.5837 - val_accuracy: 0.7521 - val_auc_51: 0.7320 - val_loss: 0.5629\n",
            "Epoch 15/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7558 - auc_51: 0.6122 - loss: 0.5658 - val_accuracy: 0.7621 - val_auc_51: 0.7329 - val_loss: 0.5448\n",
            "Epoch 16/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7539 - auc_51: 0.6423 - loss: 0.5663 - val_accuracy: 0.7674 - val_auc_51: 0.7277 - val_loss: 0.5316\n",
            "Epoch 17/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7664 - auc_51: 0.6386 - loss: 0.5499 - val_accuracy: 0.7748 - val_auc_51: 0.7399 - val_loss: 0.5196\n",
            "Epoch 18/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7810 - auc_51: 0.6316 - loss: 0.5356 - val_accuracy: 0.7806 - val_auc_51: 0.7723 - val_loss: 0.5105\n",
            "Epoch 19/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7707 - auc_51: 0.6502 - loss: 0.5373 - val_accuracy: 0.7811 - val_auc_51: 0.7399 - val_loss: 0.5057\n",
            "Epoch 20/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7602 - auc_51: 0.6619 - loss: 0.5401 - val_accuracy: 0.7822 - val_auc_51: 0.8030 - val_loss: 0.5026\n",
            "Epoch 21/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7860 - auc_51: 0.6675 - loss: 0.5130 - val_accuracy: 0.7890 - val_auc_51: 0.8032 - val_loss: 0.4909\n",
            "Epoch 22/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7873 - auc_51: 0.6542 - loss: 0.5179 - val_accuracy: 0.7869 - val_auc_51: 0.7583 - val_loss: 0.4938\n",
            "Epoch 23/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7780 - auc_51: 0.6640 - loss: 0.5234 - val_accuracy: 0.7906 - val_auc_51: 0.8171 - val_loss: 0.4846\n",
            "Epoch 24/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7792 - auc_51: 0.6805 - loss: 0.5199 - val_accuracy: 0.7932 - val_auc_51: 0.8048 - val_loss: 0.4798\n",
            "Epoch 25/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7735 - auc_51: 0.6639 - loss: 0.5233 - val_accuracy: 0.7927 - val_auc_51: 0.7758 - val_loss: 0.4796\n",
            "Epoch 26/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - auc_51: 0.6677 - loss: 0.5146 - val_accuracy: 0.7954 - val_auc_51: 0.8073 - val_loss: 0.4761\n",
            "Epoch 27/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7863 - auc_51: 0.6952 - loss: 0.5031 - val_accuracy: 0.7954 - val_auc_51: 0.8156 - val_loss: 0.4760\n",
            "Epoch 28/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7943 - auc_51: 0.6834 - loss: 0.4991 - val_accuracy: 0.8006 - val_auc_51: 0.7991 - val_loss: 0.4683\n",
            "Epoch 29/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7965 - auc_51: 0.6717 - loss: 0.4950 - val_accuracy: 0.8001 - val_auc_51: 0.8202 - val_loss: 0.4691\n",
            "Epoch 30/30\n",
            "\u001b[1m443/443\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7942 - auc_51: 0.6956 - loss: 0.4922 - val_accuracy: 0.8033 - val_auc_51: 0.8160 - val_loss: 0.4636\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6403 - auc_52: 0.4969 - loss: 0.6437 - val_accuracy: 0.7064 - val_auc_52: 0.5000 - val_loss: 0.6053\n",
            "Epoch 2/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7032 - auc_52: 0.4919 - loss: 0.6211 - val_accuracy: 0.7064 - val_auc_52: 0.5000 - val_loss: 0.6054\n",
            "Epoch 3/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7025 - auc_52: 0.4675 - loss: 0.6277 - val_accuracy: 0.7064 - val_auc_52: 0.5000 - val_loss: 0.6051\n",
            "Epoch 4/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6961 - auc_52: 0.5002 - loss: 0.6238 - val_accuracy: 0.7064 - val_auc_52: 0.5036 - val_loss: 0.6050\n",
            "Epoch 5/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7051 - auc_52: 0.5141 - loss: 0.6127 - val_accuracy: 0.7064 - val_auc_52: 0.6199 - val_loss: 0.6049\n",
            "Epoch 6/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7109 - auc_52: 0.4904 - loss: 0.6118 - val_accuracy: 0.7064 - val_auc_52: 0.6360 - val_loss: 0.6048\n",
            "Epoch 7/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7061 - auc_52: 0.4933 - loss: 0.6154 - val_accuracy: 0.7064 - val_auc_52: 0.5948 - val_loss: 0.6047\n",
            "Epoch 8/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7148 - auc_52: 0.4839 - loss: 0.6086 - val_accuracy: 0.7064 - val_auc_52: 0.5644 - val_loss: 0.6045\n",
            "Epoch 9/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6986 - auc_52: 0.4767 - loss: 0.6233 - val_accuracy: 0.7064 - val_auc_52: 0.5859 - val_loss: 0.6041\n",
            "Epoch 10/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6961 - auc_52: 0.5005 - loss: 0.6200 - val_accuracy: 0.7064 - val_auc_52: 0.6020 - val_loss: 0.6037\n",
            "Epoch 11/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7190 - auc_52: 0.5218 - loss: 0.5954 - val_accuracy: 0.7064 - val_auc_52: 0.6091 - val_loss: 0.6020\n",
            "Epoch 12/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6981 - auc_52: 0.5244 - loss: 0.6146 - val_accuracy: 0.7064 - val_auc_52: 0.6449 - val_loss: 0.6002\n",
            "Epoch 13/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7017 - auc_52: 0.5416 - loss: 0.6083 - val_accuracy: 0.7064 - val_auc_52: 0.6852 - val_loss: 0.5962\n",
            "Epoch 14/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7073 - auc_52: 0.5481 - loss: 0.6010 - val_accuracy: 0.7064 - val_auc_52: 0.7138 - val_loss: 0.5888\n",
            "Epoch 15/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7042 - auc_52: 0.5715 - loss: 0.5997 - val_accuracy: 0.7064 - val_auc_52: 0.7853 - val_loss: 0.5762\n",
            "Epoch 16/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7112 - auc_52: 0.6279 - loss: 0.5871 - val_accuracy: 0.7568 - val_auc_52: 0.7683 - val_loss: 0.5579\n",
            "Epoch 17/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7433 - auc_52: 0.6089 - loss: 0.5753 - val_accuracy: 0.7663 - val_auc_52: 0.7218 - val_loss: 0.5422\n",
            "Epoch 18/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7692 - auc_52: 0.6509 - loss: 0.5475 - val_accuracy: 0.7757 - val_auc_52: 0.7818 - val_loss: 0.5263\n",
            "Epoch 19/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7833 - auc_52: 0.6554 - loss: 0.5326 - val_accuracy: 0.7784 - val_auc_52: 0.7487 - val_loss: 0.5157\n",
            "Epoch 20/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7782 - auc_52: 0.6453 - loss: 0.5310 - val_accuracy: 0.7847 - val_auc_52: 0.7683 - val_loss: 0.5064\n",
            "Epoch 21/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7765 - auc_52: 0.6651 - loss: 0.5298 - val_accuracy: 0.7862 - val_auc_52: 0.7585 - val_loss: 0.5007\n",
            "Epoch 22/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7875 - auc_52: 0.6650 - loss: 0.5151 - val_accuracy: 0.7868 - val_auc_52: 0.8043 - val_loss: 0.4976\n",
            "Epoch 23/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7979 - auc_52: 0.6680 - loss: 0.5009 - val_accuracy: 0.7878 - val_auc_52: 0.7898 - val_loss: 0.4918\n",
            "Epoch 24/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7792 - auc_52: 0.6762 - loss: 0.5167 - val_accuracy: 0.7878 - val_auc_52: 0.7683 - val_loss: 0.4886\n",
            "Epoch 25/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7819 - auc_52: 0.6749 - loss: 0.5139 - val_accuracy: 0.7889 - val_auc_52: 0.7683 - val_loss: 0.4846\n",
            "Epoch 26/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7807 - auc_52: 0.6820 - loss: 0.5160 - val_accuracy: 0.7973 - val_auc_52: 0.8250 - val_loss: 0.4769\n",
            "Epoch 27/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8070 - auc_52: 0.7149 - loss: 0.4769 - val_accuracy: 0.8051 - val_auc_52: 0.8144 - val_loss: 0.4712\n",
            "Epoch 28/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7943 - auc_52: 0.6645 - loss: 0.5003 - val_accuracy: 0.8057 - val_auc_52: 0.8071 - val_loss: 0.4685\n",
            "Epoch 29/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7974 - auc_52: 0.6990 - loss: 0.4927 - val_accuracy: 0.8067 - val_auc_52: 0.7889 - val_loss: 0.4656\n",
            "Epoch 30/30\n",
            "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8037 - auc_52: 0.6828 - loss: 0.4907 - val_accuracy: 0.8051 - val_auc_52: 0.7990 - val_loss: 0.4666\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6657 - auc_53: 0.5318 - loss: 0.6342 - val_accuracy: 0.6993 - val_auc_53: 0.5000 - val_loss: 0.6125\n",
            "Epoch 2/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6834 - auc_53: 0.4955 - loss: 0.6353 - val_accuracy: 0.6993 - val_auc_53: 0.5070 - val_loss: 0.6120\n",
            "Epoch 3/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6889 - auc_53: 0.4993 - loss: 0.6288 - val_accuracy: 0.6993 - val_auc_53: 0.5000 - val_loss: 0.6113\n",
            "Epoch 4/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6768 - auc_53: 0.5174 - loss: 0.6329 - val_accuracy: 0.6993 - val_auc_53: 0.5000 - val_loss: 0.6112\n",
            "Epoch 5/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6999 - auc_53: 0.5061 - loss: 0.6196 - val_accuracy: 0.6993 - val_auc_53: 0.5734 - val_loss: 0.6113\n",
            "Epoch 6/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7029 - auc_53: 0.4945 - loss: 0.6172 - val_accuracy: 0.6993 - val_auc_53: 0.5743 - val_loss: 0.6109\n",
            "Epoch 7/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6864 - auc_53: 0.5098 - loss: 0.6313 - val_accuracy: 0.6993 - val_auc_53: 0.6014 - val_loss: 0.6108\n",
            "Epoch 8/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7006 - auc_53: 0.4981 - loss: 0.6204 - val_accuracy: 0.6993 - val_auc_53: 0.6154 - val_loss: 0.6105\n",
            "Epoch 9/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6999 - auc_53: 0.4916 - loss: 0.6219 - val_accuracy: 0.6993 - val_auc_53: 0.6075 - val_loss: 0.6103\n",
            "Epoch 10/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7000 - auc_53: 0.5115 - loss: 0.6183 - val_accuracy: 0.6993 - val_auc_53: 0.5874 - val_loss: 0.6105\n",
            "Epoch 11/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6974 - auc_53: 0.5121 - loss: 0.6181 - val_accuracy: 0.6993 - val_auc_53: 0.6215 - val_loss: 0.6091\n",
            "Epoch 12/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7045 - auc_53: 0.5275 - loss: 0.6113 - val_accuracy: 0.6993 - val_auc_53: 0.6189 - val_loss: 0.6080\n",
            "Epoch 13/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6857 - auc_53: 0.4897 - loss: 0.6316 - val_accuracy: 0.6993 - val_auc_53: 0.6556 - val_loss: 0.6062\n",
            "Epoch 14/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7009 - auc_53: 0.5296 - loss: 0.6122 - val_accuracy: 0.6993 - val_auc_53: 0.6469 - val_loss: 0.6034\n",
            "Epoch 15/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6964 - auc_53: 0.5389 - loss: 0.6142 - val_accuracy: 0.6993 - val_auc_53: 0.6652 - val_loss: 0.5987\n",
            "Epoch 16/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7031 - auc_53: 0.5478 - loss: 0.6064 - val_accuracy: 0.6993 - val_auc_53: 0.6678 - val_loss: 0.5906\n",
            "Epoch 17/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6900 - auc_53: 0.5644 - loss: 0.6143 - val_accuracy: 0.6993 - val_auc_53: 0.6827 - val_loss: 0.5785\n",
            "Epoch 18/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7166 - auc_53: 0.6282 - loss: 0.5856 - val_accuracy: 0.7476 - val_auc_53: 0.7369 - val_loss: 0.5633\n",
            "Epoch 19/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7389 - auc_53: 0.6262 - loss: 0.5732 - val_accuracy: 0.7671 - val_auc_53: 0.7290 - val_loss: 0.5458\n",
            "Epoch 20/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7643 - auc_53: 0.6379 - loss: 0.5527 - val_accuracy: 0.7723 - val_auc_53: 0.7701 - val_loss: 0.5315\n",
            "Epoch 21/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7755 - auc_53: 0.6366 - loss: 0.5461 - val_accuracy: 0.7792 - val_auc_53: 0.8291 - val_loss: 0.5206\n",
            "Epoch 22/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7732 - auc_53: 0.6485 - loss: 0.5408 - val_accuracy: 0.7787 - val_auc_53: 0.7535 - val_loss: 0.5135\n",
            "Epoch 23/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7696 - auc_53: 0.6626 - loss: 0.5365 - val_accuracy: 0.7808 - val_auc_53: 0.7802 - val_loss: 0.5058\n",
            "Epoch 24/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7753 - auc_53: 0.6714 - loss: 0.5272 - val_accuracy: 0.7876 - val_auc_53: 0.7987 - val_loss: 0.4975\n",
            "Epoch 25/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - auc_53: 0.6756 - loss: 0.5200 - val_accuracy: 0.7886 - val_auc_53: 0.7771 - val_loss: 0.4935\n",
            "Epoch 26/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7753 - auc_53: 0.6565 - loss: 0.5325 - val_accuracy: 0.7886 - val_auc_53: 0.8321 - val_loss: 0.4920\n",
            "Epoch 27/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7833 - auc_53: 0.6847 - loss: 0.5134 - val_accuracy: 0.7934 - val_auc_53: 0.7727 - val_loss: 0.4855\n",
            "Epoch 28/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7945 - auc_53: 0.6812 - loss: 0.5023 - val_accuracy: 0.7950 - val_auc_53: 0.7778 - val_loss: 0.4820\n",
            "Epoch 29/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7879 - auc_53: 0.6966 - loss: 0.5030 - val_accuracy: 0.7939 - val_auc_53: 0.7851 - val_loss: 0.4820\n",
            "Epoch 30/30\n",
            "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7959 - auc_53: 0.7059 - loss: 0.4925 - val_accuracy: 0.7976 - val_auc_53: 0.7925 - val_loss: 0.4779\n",
            "✅ Model et history calculés.\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "Epoch 1/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3675 - auc_54: 0.5071 - loss: 1.0330 - val_accuracy: 0.7051 - val_auc_54: 0.5150 - val_loss: 0.6094\n",
            "Epoch 2/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6911 - auc_54: 0.5079 - loss: 0.6254 - val_accuracy: 0.7051 - val_auc_54: 0.5027 - val_loss: 0.6075\n",
            "Epoch 3/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7047 - auc_54: 0.5017 - loss: 0.6214 - val_accuracy: 0.7051 - val_auc_54: 0.5044 - val_loss: 0.6070\n",
            "Epoch 4/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6951 - auc_54: 0.5067 - loss: 0.6207 - val_accuracy: 0.7051 - val_auc_54: 0.5910 - val_loss: 0.6075\n",
            "Epoch 5/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7055 - auc_54: 0.4839 - loss: 0.6180 - val_accuracy: 0.7051 - val_auc_54: 0.5247 - val_loss: 0.6058\n",
            "Epoch 6/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6888 - auc_54: 0.4976 - loss: 0.6273 - val_accuracy: 0.7051 - val_auc_54: 0.5769 - val_loss: 0.6065\n",
            "Epoch 7/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7019 - auc_54: 0.5105 - loss: 0.6172 - val_accuracy: 0.7051 - val_auc_54: 0.5689 - val_loss: 0.6062\n",
            "Epoch 8/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6980 - auc_54: 0.4967 - loss: 0.6199 - val_accuracy: 0.7051 - val_auc_54: 0.7465 - val_loss: 0.6039\n",
            "Epoch 9/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7037 - auc_54: 0.5055 - loss: 0.6147 - val_accuracy: 0.7051 - val_auc_54: 0.6979 - val_loss: 0.6029\n",
            "Epoch 10/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7095 - auc_54: 0.5309 - loss: 0.6052 - val_accuracy: 0.7051 - val_auc_54: 0.6316 - val_loss: 0.5988\n",
            "Epoch 11/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7080 - auc_54: 0.5306 - loss: 0.6051 - val_accuracy: 0.7051 - val_auc_54: 0.6855 - val_loss: 0.5926\n",
            "Epoch 12/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7042 - auc_54: 0.5597 - loss: 0.6033 - val_accuracy: 0.7051 - val_auc_54: 0.6634 - val_loss: 0.5818\n",
            "Epoch 13/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7168 - auc_54: 0.6138 - loss: 0.5881 - val_accuracy: 0.7473 - val_auc_54: 0.6917 - val_loss: 0.5641\n",
            "Epoch 14/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7470 - auc_54: 0.6243 - loss: 0.5728 - val_accuracy: 0.7619 - val_auc_54: 0.7288 - val_loss: 0.5454\n",
            "Epoch 15/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7638 - auc_54: 0.6398 - loss: 0.5514 - val_accuracy: 0.7728 - val_auc_54: 0.7129 - val_loss: 0.5286\n",
            "Epoch 16/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7743 - auc_54: 0.6465 - loss: 0.5407 - val_accuracy: 0.7749 - val_auc_54: 0.7954 - val_loss: 0.5169\n",
            "Epoch 17/30\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7788 - auc_54: 0.6588 - loss: 0.5259 - val_accuracy: 0.7811 - val_auc_54: 0.7571 - val_loss: 0.5079\n",
            "Epoch 18/30\n",
            "\u001b[1m441/448\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7889 - auc_54: 0.6541 - loss: 0.5167"
          ]
        }
      ],
      "source": [
        "model_list=[]\n",
        "history_list=[]\n",
        "for df in df_cleaned_list:\n",
        "      X1=df.drop(columns=['label','Dst IP','time_windows'])\n",
        "      Y1=df['label']\n",
        "      X1_train,X1_test,Y1_train,Y1_test = train_test_split(X1,Y1,test_size=0.3,stratify=Y1)\n",
        "      model,history=build_and_train_binary_classifier(X1_train, Y1_train, X1_test, Y1_test)\n",
        "      model_list.append(model)\n",
        "      history_list.append(history)\n",
        "      print(\"✅ Model et history calculés.\")\n",
        "      # Prédire les probabilités (entre 0 et 1)\n",
        "      y_pred_prob = model.predict(X1_test)\n",
        "      # Convertir les probabilités en classes binaires (0 ou 1)\n",
        "      y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "      # Calcul de la matrice de confusion\n",
        "      cm = confusion_matrix(Y1_test, y_pred)\n",
        "      # Affichage\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "      disp.plot(cmap='Blues')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ADs1e88lReBn",
        "outputId": "7f63c0e5-0218-4d3a-c0c3-ebc85151a1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 25.623950958251953\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 29.704952239990234\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 32.67353820800781\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 34.779632568359375\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 36.55741500854492\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 37.84404373168945\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 38.78063201904297\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 39.6094856262207\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.29451370239258\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 40.92143630981445\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 41.44010543823242\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 41.92028045654297\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 42.345916748046875\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 42.69192123413086\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 43.00799560546875\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 43.34712600708008\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 43.679115295410156\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 43.97254943847656\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 44.25575256347656\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 44.56656265258789\n",
            "✅ Décomposition, projection et résidu calculés.\n",
            "Norme du résidu : 44.802398681640625\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1002.88 MiB is free. Process 28655 has 38.57 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-8966f4d124bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresiduals_test_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfactors_normal_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mresiduals_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_space_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresiduals_test_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresiduals_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-b75e5754189e>\u001b[0m in \u001b[0;36mnormal_space_projection\u001b[0;34m(tensor_input, tensor_ref)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Étape 1 : décomposition CP de tensor_input au même rang que tensor_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcp_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparafac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlow_rank_tensor_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reconstruction low-rank du tenseur input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorly/decomposition/_cp.py\u001b[0m in \u001b[0;36mparafac\u001b[0;34m(tensor, rank, n_iter_max, init, svd, normalize_factors, orthogonalise, tol, random_state, verbose, return_errors, sparsity, l2_reg, mask, cvg_criterion, fixed_modes, svd_mask_repeats, linesearch, callback)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0;34m*\u001b[0m \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             )\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mmttkrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfolding_dot_khatri_rao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             factor = tl.transpose(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorly/backend/__init__.py\u001b[0m in \u001b[0;36mwrapped_backend_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             Returns the queried method from the currently set backend\"\"\"\n\u001b[0;32m--> 202\u001b[0;31m             return getattr(\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_THREAD_LOCAL_DATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"backend\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             )(*args, **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorly/tenalg/core_tenalg/mttkrp.py\u001b[0m in \u001b[0;36munfolding_dot_khatri_rao\u001b[0;34m(tensor, cp_tensor, mode)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m     47\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mkr_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkhatri_rao\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mmttkrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkr_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmttkrp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorly/tenalg/core_tenalg/_khatri_rao.py\u001b[0m in \u001b[0;36mkhatri_rao\u001b[0;34m(matrices, weights, skip_matrix, mask)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 39.56 GiB of which 1002.88 MiB is free. Process 28655 has 38.57 GiB memory in use. Of the allocated memory 28.90 GiB is allocated by PyTorch, and 8.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "residuals_test_list=[]\n",
        "for tensor in factors_normal_list:\n",
        "    residuals_test = normal_space_projection(tensor_test, tensor)\n",
        "    residuals_test_list.append(residuals_test)\n",
        "    print(\"✅ Residual calculé.\")\n",
        "    print(\"✅ Rank :\",tensor[0].shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBKesYhiReBo"
      },
      "outputs": [],
      "source": [
        "mappings_test={'Dst_IP':dst_ip_to_idx_test,'features_names':dict(enumerate(['count','bytes','packets','duration']))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWEvpZU2VQ6P"
      },
      "outputs": [],
      "source": [
        "df_score_test_list=[]\n",
        "for residual in residuals_train_list:\n",
        "    df_scores_train=aggregation_scoring_Source(residual,mappings, df_train, window_size=300)\n",
        "    df_score_list.append(df_scores_train)\n",
        "    print(\"✅ Rank :\",residual[0].shape[0])\n",
        "    print(\"shape=\",df_scores_train.shape)\n",
        "    df_scores_train['label'].value_counts().plot(kind='bar', title='Label Distribution')\n",
        "    plt.show()\n",
        "    print(\"✅ Score calculé.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMOleaBfU_4p"
      },
      "outputs": [],
      "source": [
        "df_cleaned_list=[]\n",
        "features=['time_windows','label','Dst IP']\n",
        "for df in df_score_test_list:\n",
        "    removed=remove_outliers_iqr(df,features)\n",
        "    print(\"✅ Outliers supprimés.\")\n",
        "    df_cleaned=pd.concat([removed,df[df['label']==1]],axis=0)\n",
        "    df_cleaned_list.append(df_cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyv1pCE7VMET"
      },
      "outputs": [],
      "source": [
        "for df in df_cleaned_list:\n",
        "  for model in model_list:\n",
        "      X=df.drop(columns=['label','Dst IP','time_windows'])\n",
        "      Y=df['label']\n",
        "      y_pred_prob = model.predict(X)\n",
        "      # Convertir les probabilités en classes binaires (0 ou 1)\n",
        "      y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "      # Calcul de la matrice de confusion\n",
        "      cm = confusion_matrix(Y, y_pred)\n",
        "      # Affichage\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "      disp.plot(cmap='Blues')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}